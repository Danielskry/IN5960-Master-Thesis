"['Issue 294388: Add support for UI Events |code| attribute to WebKeyboardEvent', 'Change description:\nThe |code| attribute specified in UI Events is intended to accurately identify the physical key associated with a key event. The legacy attribute |keyCode| was previously used by developers for this purpose, but it has problems in that it was never completely specified and thus it is not consistently implemented across browsers.\n\nChanges to API surface:\n- add a new |code| attribute to WebKeyboardEvent\n\nW3C WD is:\nhttp://www.w3.org/TR/uievents/\n\nSupport in other browsers:\nNone', '']",1
"['Issue 367158: Simplify EncryptedMediaIsTypeSupported* tests.', 'Currently we have a lot of duplicate/boilerplate code in this test. We should try to simplify this test so that it\'s easier to maintain and read.\n\nIdeas:\n1) Put combinations of keysystem, container and codec in an array. Then use a for loop to test each.\n2) Construct the CodecVector right before we test IsSupportedKeySystemWithMediaMimeType. Then for each test, we can simply pass in strings (e.g. ""vorbis,vp8"") which is more readable.', '']",1
"['Issue 414319: Network throttling does not throttle uploads', 'UserAgent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2158.0 Safari/537.36\n\nSteps to reproduce the problem:\n1. Turn on network throttling in the dev tools\n2. Use a script that uploads a large file using XHR\n\nWhat is the expected behavior?\nThe upload speed should be throttled.\n\nWhat went wrong?\nThe upload goes as fast as possible.\n\nDid this work before? N/A \n\nChrome version: 39.0.2158.0  Channel: n/a\nOS Version: OS X 10.10.0\nFlash Version: Shockwave Flash 15.0 r0', '']",1
"['Issue 445880: Parallelize test execution to speed up buildbot runs', 'pbos@ has been doing some excellent work on a wrapper script for gtest executables that enables them to run in parallel (available at https://github.com/pbos/gtest-parallel).\n\nAn FYI bot has been running for a while for Linux and is now finally green. \nThis bug tracks deploying parallel test execution on all bots, for all platforms (bare-metal bots excluded, as their tests interact with devices, making them unsuitable to run in parallel).', '']",1
"['Issue 488668: net::Filter: switch to pure pull-based filter API', 'We have a detailed design proposal for how to achieve this. Currently, filters are a mixture of push and pull, which complicates their implementation, and the filter system is both hard to test and bug-prone.', '']",1
"['Issue 490895: Huge animated GIFs can lead to scroll jank', 'UserAgent: Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/45.0.2408.0 Safari/537.36\n\nExample URL:\nhttp://www.pcper.com/news/Graphics-Cards/NVIDIA-Under-Attack-Again-GameWorks-Witcher-3-Wild-Hunt\n\nSteps to reproduce the problem:\n1. Enter the given URL: http://www.pcper.com/news/Graphics-Cards/NVIDIA-Under-Attack-Again-GameWorks-Witcher-3-Wild-Hunt\n2. Initiate an auto scrolling.\n3. When the gif on the page is visible, the scrolling stutters badly.\n\n*Note:\nChrome stable (v 43.0.2357.65) has the same behaviour.\n\nWhat is the expected behavior?\nAuto scrolling stays smooth even when the gif on the page is visible.\n\nWhat went wrong?\nThis particular gif caused Chrome auto scroll stutterly.\n\nDoes it occur on multiple sites: No\n\nIs it a problem with a plugin? No \n\nDid this work before? N/A \n\nDoes this work in other browsers? Yes \n\nChrome version: 45.0.2408.0  Channel: canary\nOS Version: 6.3\nFlash Version: Shockwave Flash 18.0 r0', '']",1
"['Issue 510800: Issues with pdf viewer and iframe', 'UserAgent: Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/43.0.2357.132 Safari/537.36\n\nExample URL:\n\nSteps to reproduce the problem:\n1. Create an html with an iframe and a button and no source\n2. When click the button set a pdf url into the src iframe attribute\n\nWhat is the expected behavior?\nIn some cases, not always. PDF viewer is not showing de pdf correctly. Looks small instead fit into the iframe size-\n\nWhat went wrong?\nPDF viewer is not showing the pdf in iframe or object tag.  \nWorks good on IE and FF since are using acrobat.\n\nDoes it occur on multiple sites: N/A\n\nIs it a problem with a plugin? N/A \n\nDid this work before? N/A \n\nDoes this work in other browsers? N/A \n\nChrome version: 43.0.2357.132  Channel: n/a\nOS Version: 6.1 (Windows 7, Windows Server 2008 R2)\nFlash Version: Shockwave Flash 18.0 r0', '']",1
"['Issue 528680: Chrome hangs when continuously showing notifications', ""UserAgent: Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/45.0.2454.85 Safari/537.36\n\nSteps to reproduce the problem:\nThe following code (extracted from a Chrome extension), used to work in Chrome 44:\n\nchrome.alarms.create('promptRecall', {\n  delayInMinutes: 1,\n  periodInMinutes: 0.1\n});\n\nchrome.alarms.onAlarm.addListener(function (alarm) {\n  if (alarm.name === 'promptRecall') {\n      chrome.notifications.create({\n        type: 'basic',\n        iconUrl: '...',\n        title: 'Please login to iDoRecall!',\n        message: 'Click the IDR icon to the right of the address bar',\n        buttons: [\n          { title: 'Login - TBD' }\n        ]\n      });\n    }\n  }\n});\n\nIn Chrome 45, the browser eats up 25% - 50% of the CPU of a quad-core Intel Core i5. \n\nOf course, the 0.1 value was unintended, and there *was* a message in the console about the alarm frequency being one minute in a .crx, but Chrome 44 didn't hang. Chrome 55 filled its system tray notification area, then became unresponsive. Task managers showed CPU utilization going to 25% then 50%.\n\nWhat is the expected behavior?\nThe browser throttles the notifications, or otherwise doesn't hang.\n\nWhat went wrong?\nChrome 45 hangs.\n\nCrashed report ID: No, the browser hangs (CPU usage goes through the roof)\n\nHow much crashed? Whole browser\n\nIs it a problem with a plugin? No \n\nDid this work before? Yes Chrome 44\n\nChrome version: 45.0.2454.85  Channel: stable\nOS Version: 6.1 (Windows 7, Windows Server 2008 R2)\nFlash Version: Shockwave Flash 18.0 r0"", '']",1
"['Issue 543685: Implement addEventListener(type, listener, EventListenerOptions);', 'Change description:\nAdd the ability to specific a dictionary as the third argument to addEventListeners. This provides us flexibility to customize event listeners based on parameters from the application.\n\nChanges to API surface:\nChange the current 3rd argument into a union (it currently is a boolean).\n\nLinks:\nPublic standards discussion: \n\nSupport in other browsers:\nInternet Explorer: No\nFirefox: No; actually has 4th argument.\nSafari: No', '']",1
"['Issue 551983: Hitting memory limits for required tiles leads to bad state', ""Spin off of bug 546653. Copy/pasting some bits:\n\nOriginal description of the issue:\n> On my test pixel, rotating the display via CrOS display settings will\n> usually (>50% of the time) cause a complete freeze of the display\n> contents mid-animation.\n\n> When it happens, the cursor still updates (incl. changing bitmap via a\n> hover effect) so the GPU IO threads is still making progress. However the\n> main surface never updates again without terminating the GPU process.\n\n\nComment #18:\n> I instrumented AssignGpuMemoryToTiles to print limits.\n> \n> Here's a snippet starting from before I clicked the rotation selector, and ending after it's frozen:\n> \n>      [1:3:1029/151934:ERROR:tile_manager.cc(502)] usage: 20971520 hard: 536870912 soft: 536870912\n>      [1:3:1029/151934:ERROR:tile_manager.cc(502)] usage: 20971520 hard: 536870912 soft: 536870912\n>      [1:3:1029/151936:ERROR:tile_manager.cc(502)] usage: 20971520 hard: 536870912 soft: 536870912\n>      [4592:4592:1029/151936:ERROR:tile_manager.cc(502)] usage: 10551296 hard: 67108864 soft: 67108864\n>      [4592:4592:1029/151936:ERROR:tile_manager.cc(502)] usage: 11190272 hard: 67108864 soft: 67108864\n>      [1:3:1029/151936:ERROR:tile_manager.cc(502)] usage: 20971520 hard: 536870912 soft: 536870912\n>      [1:3:1029/151937:ERROR:tile_manager.cc(502)] usage: 20971520 hard: 536870912 soft: 536870912\n>      [4592:4592:1029/151937:ERROR:tile_manager.cc(502)] usage: 11190272 hard: 67108864 soft: 67108864\n>      [4592:4592:1029/151937:ERROR:tile_manager.cc(502)] usage: 17596416 hard: 67108864 soft: 67108864\n>      [4592:4592:1029/151937:ERROR:tile_manager.cc(502)] usage: 25559040 hard: 67108864 soft: 67108864\n>      [1:3:1029/151937:ERROR:tile_manager.cc(502)] usage: 18874368 hard: 536870912 soft: 536870912\n>      [4592:4592:1029/151937:ERROR:tile_manager.cc(502)] usage: 33947648 hard: 67108864 soft: 67108864\n>      [4592:4592:1029/151937:ERROR:tile_manager.cc(502)] usage: 33685504 hard: 67108864 soft: 67108864\n>      [4592:4592:1029/151937:ERROR:tile_manager.cc(502)] usage: 42074112 hard: 67108864 soft: 67108864\n>      [4592:4592:1029/151937:ERROR:tile_manager.cc(502)] usage: 47579136 hard: 67108864 soft: 67108864\n>      [4592:4592:1029/151937:ERROR:tile_manager.cc(502)] usage: 11190272 hard: 67108864 soft: 67108864\n>      [4592:4592:1029/151937:ERROR:tile_manager.cc(502)] usage: 11190272 hard: 67108864 soft: 67108864\n>      [4592:4592:1029/151937:ERROR:tile_manager.cc(502)] usage: 47579136 hard: 67108864 soft: 67108864\n>      [4592:4592:1029/151937:ERROR:tile_manager.cc(502)] usage: 19578880 hard: 67108864 soft: 67108864\n>      [4592:4592:1029/151937:ERROR:tile_manager.cc(502)] usage: 21676032 hard: 67108864 soft: 67108864\n>      [4592:4592:1029/151937:ERROR:tile_manager.cc(502)] usage: 47579136 hard: 67108864 soft: 67108864\n>      [4592:4592:1029/151937:ERROR:tile_manager.cc(502)] usage: 21676032 hard: 67108864 soft: 67108864\n>      [4592:4592:1029/151937:ERROR:tile_manager.cc(502)] usage: 55967744 hard: 67108864 soft: 67108864\n>      [4592:4592:1029/151937:ERROR:tile_manager.cc(502)] usage: 64356352 hard: 67108864 soft: 67108864\n>      [4592:4592:1029/151937:ERROR:tile_manager.cc(558)] exceeded limit\n>      [4592:4592:1029/151937:ERROR:tile_manager.cc(502)] usage: 66977792 hard: 67108864 soft: 67108864\n>      [4592:4592:1029/151937:ERROR:tile_manager.cc(558)] exceeded limit\n>      [4592:4592:1029/151937:ERROR:tile_manager.cc(502)] usage: 21676032 hard: 67108864 soft: 67108864\n>      [4592:4592:1029/151937:ERROR:tile_manager.cc(502)] usage: 21676032 hard: 67108864 soft: 67108864\n>      [4592:4592:1029/151937:ERROR:tile_manager.cc(502)] usage: 21676032 hard: 67108864 soft: 67108864\n>      [4592:4592:1029/151937:ERROR:tile_manager.cc(502)] usage: 21676032 hard: 67108864 soft: 67108864\n>      [4592:4592:1029/151937:ERROR:tile_manager.cc(502)] usage: 11190272 hard: 67108864 soft: 67108864\n>      [4592:4592:1029/151937:ERROR:tile_manager.cc(502)] usage: 11190272 hard: 67108864 soft: 67108864\n> \n> It does seem we are hitting limits during the animation.\n\nComment #29:\n> Attaching trace (I artificially reduced the memory policy to 16 MB, and used a second screen for tracing).\n> Around 5184 ms is the last frame that we attempt to draw, and never do.\n> At 5,186.498 ms, there is a TileManager::AssignGpuMemoryToTiles that reports:\n> all_tiles_that_need_to_be_rasterized_are_scheduled=false\n> had_enough_memory_to_schedule_tiles_needed_now=false\n> \n> (previous AssignGpuMemoryToTiles reported true to both).\n> \n> We still go and rasterize some tiles, and then at 5,194.553 ms all raster tasks completed, we TileManager::CheckAndIssueSignals, but then it looks like TileManager::IsReadyToDraw returns false and we don't progress to drawing.\n> Right after that, we try TileManager::AssignGpuMemoryToTiles again, but we still report:\n> all_tiles_that_need_to_be_rasterized_are_scheduled=false\n> had_enough_memory_to_schedule_tiles_needed_now=false\n> \n> Nothing happens after that.\n> \n> \n> What it looks like is that we're stuck waiting for being able to raster all tiles before drawing, which never ends up happening because the memory limit doesn't let us allocate all tiles. Because we never draw, we also never commit again, so trying to close windows to lower the memory doesn't help either.\n> \n> \n> It sounds like we need a fallback for when all tiles don't fit in memory (drop quads, checkerboard, use PictureDrawQuad, etc.)\n\n(I reattached the trace in this bug)\n\nrepro steps for the above:\n1- change memory policy to 16MB (I originally did it in LayerTreeSettings, but now you'd have to do it in ui/compositor/compositor.cc)\n2- build linux_chromeos\n3- run normally, create a bunch of windows, observe behavior after a few windows created\n\nTo capture traces:\n3'- run chrome --ash-host-window-bounds='1024x768,1024+0-1024x768'\nThis creates 2 windows, each with a separate compositor, so that when one gets in a bad state, the other one still works (so that you can capture traces etc. in that one).\n\nNote: this is easy to repro with the UI, but I'm not sure there's a strong reason it couldn't happen for the renderer as well, given sufficient number of overlapping layers.\n@vmpstr: are you a good owner for this?"", '']",1
"['Issue 553905: Regression : Weird behavior of blocked plugins is seen after scrolling down action in espn.go.com', 'Chrome Version       : 48.0.2560.0 (Official Build)Revision a86f261491aa0f522c17a1ef30e97d546bcddd8f-refs/heads/master@{#358754} (32/64 bit)\nOS  :Windows (Aero enabled) , Mac\nURL : http://espn.go.com/blog/san-diego-chargers/post/_/id/13707/bears-send-chargers-into-bye-week-with-another-heartbreaking-loss\n\nWhat steps will reproduce the problem?\n1. Launch chrome & navigate to chrome://settings/content,under plugins section select "" Let me choose when to run plugins content "" radio button.\n2. Now navigate to above link & scroll down the page,observe blocked plugins content while scrolling action.\n\nWeird behavior of blocked plugins for the video is observed as after scrolling down action blocked plugins content disappears & only black patch with loading icon is seen.\n\nBlocked plugins content on the page should be seen properly and should not disappear on scrolling action.\n\nThis is a Regression issue broken in M-48.\n\nBelow is the narrow bisect info :\n https://chromium.googlesource.com/chromium/src/+log/260ecd51b9f2090da212f3920f25809b945dd7d3..76c2d557fcab24b4d76659301006d0d8f5e196e8\n\nSuspecting : r358271 ?', '']",1
"['Issue 556533: Compositor uses scale 1 for raster after any scale change. (This only becomes visible on tab switch.)', 'Chrome Version       : Google Chrome 46.0.2490.86 (Official Build) m (32-bit)\nRevision e8926f681fbb840b4f389e7e692343d4505722ce-refs/branch-heads/2490@{#560}\n\nURLs (if applicable) : https://dl.dropboxusercontent.com/u/64801620/hosted/chrome-compositing-bug/index.html\nOther browsers tested:\nAdd OK or FAIL, along with the version, after other browsers where you\nhave tested this issue:\n     iOS Safari: OK\n    Firefox: OK\n         IE: OK\nChrome Android: FAIL\n      Opera: FAIL (same behaviour as chrome)\n\nWhat steps will reproduce the problem?\n1. Open the above link, notice the two large buttons.\n2. switch to another tab\n3. return to the other tab\n\nWhat is the expected result?\n\nThe page should look the same as it did.\n\nWhat happens instead?\n\nThere is now a transparent gradient on the bottom/right of the images.\n\n\nPlease provide any additional information below. Attach a screenshot if\npossible.\n\nThis appears to be a compositor bug.  It looks suspiciously as though the underlying texture atlas has been manipulated as we tabbed away, but has not padded the layer sub textures with border pixels, so now linear texture interpolation into adjacent (transparent) pixels is occurring.\n\nThis is consistent behaviour for this page, across both Windows 10 desktop chrome and Chrome for android, but I cannot seem to trigger it in isolation.', '']",1
"['Issue 565120: Pathological O(n^2) performance when appending nodes that are referenced via <use>', 'Version: 48.0.2564.22\nOS: All\n\nWhat steps will reproduce the problem?\n1. Open the attached testcase, or visit http://jsbin.com/bobofopaxu\n2. Click the box to generate random dots, this should be very fast.\n\nWhat is the expected output? What do you see instead?\nGenerating 250 random dots is incredibly slow and takes over 1 second on a fast machine.\n\nThis is due to O(n^2) behavior in updating the <use> tree. Webkit does not have this behavior so we regressed this at some point. Adding needs-bisect to find out when we regressed.', '']",1
"[""Issue 12066: Match Firefox's per-host connection limit of 15"", 'Chrome limits the number of connections per ""group"" to 6.\n\nThis is particularly bad when using a proxy server, since there can be at \nmost 6 open connections across all tabs. This gets pretty ugly when you are \nusing sites like GMAIL, since they leave connections open (long running \nxmlhttp), and pretty soon you are running on empty and nothing loads.\n\nBrowsing through the mozilla documentation, it appears that Firefox 3 has \nboosted the connections per host to 15 (which is more than twice our \nlimit):\n\nhttp://kb.mozillazine.org/Network.http.max-connections-per-server\n\nWe should at the very least consider this increase for proxy servers, and \npreferably across the board.\n\nNote that this user experience was reported by a gmail engineer, since they  \nkeep multiple gmails open and run into this problem frequently.', '']",1
"['Issue 16787: Java Plugin not working', 'Chrome Version       : 3.0.194.0~svn20090713r20481-0ubuntu1~ucd1~jaunty\nOS + version : Ubuntu 9.04\nCPU architecture (32-bit / 64-bit): 64-bit\nwindow manager : compiz\nURLs (if applicable) : http://www.java.com/en/download/help/testvm.xml\nBehavior in Firefox 3.x (if applicable): works\nBehavior in Chrome for Windows (optional):\n\nWhat steps will reproduce the problem?\n1. Make sure you have 32-bit JVM and plugin installed\n2. Goto any web site using applets, i.e. \nhttp://www.java.com/en/download/help/testvm.xml\n\nWhat is the expected result?\nJava applet works\n\nWhat happens instead?\nJava applet is not shown.\n\nPlease provide any additional information below. Attach a screenshot\nand backtrace if possible.\n\nThe about:plugins does not show any mime type for java plugin:\n\nShockwave Flash\nFile name: libflashplayer.so\nShockwave Flash 10.0 r22\nMIME Type                     Description         Suffixes  Enabled\napplication/x-shockwave-flash Shockwave Flash       swf       Yes\napplication/futuresplash      FutureSplash Player   spl       Yes\n\nFile name: libjavaplugin_oji.so\nMIME Type Description Suffixes Enabled', '']",1
"['Issue 54257: The absence of synchronous message API make impossible to pass options to scripts that are loaded before the page to block content.', 'Chrome Version       :  5, 6, 7\n\n\nWith the current implementation of the message system it is impossible to have an extension that blocks content based on user options/choices because there is no way to either :\n- load options in content script synchronously\n- Ask the background page if it is okay to load the content.\n\nAccordingly there is no way to block/ analyze content before it hit the page, which makes any security /content blocking extension ineffective. On a side it will also affect how to use the experimental Network API because similarly you can\'t use it in conjunction with user options.\n\n\nHere is a description of  two most ""reasonable"" way I came up with and why they are not working\n\nPlan A: Try to use the chrome.extension.sendRequest API to load the options or query the background page. This is done by :\n\n1. Creating an extension that injects a script before the page is loaded by specifying ""run_at"": ""document_start""\n2. Try to have it fetch option from the background page by calling the chrome.extension.sendRequest() API\n3. The callback will be returned during the loading phase, so the first elements are not analyzed.\n\nThis fail because the call is asynchronous.\n\nPlan B: Try to inject programmatically the script at loading time by adding the listener:     chrome.tabs.onUpdated.addListener(function(tabId, changeInfo, tab) \n\nThis is achieve by :\n1. Adding the listener chrome.tabs.onUpdated.addListener to the background page\n2. Use it to inject the script at loading time by checking the status:  if(changeInfo.status == ""loading"") \n3.The script will be executed at the end of the loading (according  to my test on localhost). So the\nevent handler document.addEventListener(""beforeload"",,) is completly useless. \n\nI am not sure why it failed, my guess is because the injection is done asynchronously.\n\nSafari faced the same issue with their plugin API and they decided to solve it by implementing the synchronous method: safari.self.tab.canLoad(event, myMessageData); See http://developer.apple.com/safari/library/documentation/Tools/Conceptual/SafariExtensionGuide/MessagesandProxies/MessagesandProxies.html (section :Blocking Unwanted Content)\n\n\nIt is possible to have the same method or a way to ask for a synchronous message ? Without it there is no way to write an extension that let user tweak the content they want to load.', '']",1
"['Issue 86287: Slow hardware-accelerated canvas rendering', ""Chrome Version       : 14.0.793.0\nOS Version: 6.1 (Windows 7, Windows Server 2008 R2)\nURLs (if applicable) : http://kothic.org/js/\nOther browsers tested:\nAdd OK or FAIL after other browsers where you have tested this issue:\n     Safari 5: OK\n  Firefox 4.x: OK\n        Opera: OK\n\nWhat steps will reproduce the problem?\n1. Go to the page, wait for it to fully render the screen\n2. In debug panel on the right, look at Total time to render a tile\n3.\n\nWhat is the expected result?\n\nTiles are rendered within 1-2 seconds (the faster the better)\n\nWhat happens instead?\n\nTiles are rendered for 27 seconds and more.\n\n\nPlease provide any additional information below. Attach a screenshot if\npossible.\n\nThis is today's canary build on Windows. That didn't happen yesterday's build, but it appears it didn't have fix for Anti-Aliasing (http://code.google.com/p/chromium/issues/detail?id=85762). Today's build has smooth antialiased graphics but slow performance.\n\nUserAgentString: Mozilla/5.0 (Windows NT 6.1) AppleWebKit/535.1 (KHTML, like Gecko) Chrome/14.0.793.0 Safari/535.1"", '']",1
"['Issue 113098: SafeBrowsing uses too much memory', ""Chrome Version (from the about:version page): r119801 built from source\nIs this the most recent version: no\nOS + version: ubuntu 10.04.3\nCPU architecture (32-bit / 64-bit): 64-bit\nWindow manager: icewm\n\nI have a controlled send-email-to-self test for gmail that seems to be demonstrating a leak in SafeBrowsing. Or maybe just data structures that are too big?\n\nI'm using a slightly modified chromium r119801 and can provide full repro instructions... just let me know.\n\nThe basic setup:\n  o A fake gmail backend (built and run inside Google) communicates with my browser.\n  o I start with an empty gmail account and send myself mail 81 times (and also read each message after sending it).\n  o A heap snapshot is taken every 2 minutes or so.\n  o The experiment is repeatable and yields pretty consistent results from run to run.\n\nSnapshots of the C++ heap from about halfway through and from close to the end show quite a bit of growth in the SafeBrowsing data structures: ~12MB to ~29MB. Is this expected? Elapsed time between snapshots was about 80 minutes.\n\nThe attached graphs were created with\n  pprof --pdf --ignore='NewHook|HeapProfile' <path to binary> <path to .heap file>"", '']",1
"['Issue 128506: Random Chinese/Japanese characters are missing in documents printed via the system print dialog on Windows XP SP3', 'Chrome Version       : 19.0.1084.46 & 21.0.1138.0\nOS Version: 5.1 (Windows XP)\nURLs (if applicable) :http://www.ptt.cc/index.html\nOther browsers tested:\nAdd OK or FAIL after other browsers where you have tested this issue:\n  Firefox 4.0.1: OK\n     IE 7/8:  OK/OK/\n\nWhat steps will reproduce the problem?\n1. open URL with traditional Chinese content.\n2. Go to Print screen.\n3. In the print dialog window, select ""Print using system dialog ...""\n4. select printer\n5. print\n\nWhat is the expected result?\nChromePrintDialog_PTT.pdf -> via chrome print dialog\n\nWhat happens instead?\nSystemPrintDialog_PTT.pdf -> via system print dialog\n\nPlease provide any additional information below. Attach a screenshot if possible.\nIn the document via system print dialog, many words were missed.\n\nUserAgentString: Mozilla/5.0 (Windows NT 5.1) AppleWebKit/536.5 (KHTML, like Gecko) Chrome/19.0.1084.46 Safari/536.5', '']",1
"['Issue 131565: response/preview in Network Inspector confused by simultaneous AJAX requests to same URL', 'Chrome Version       : 19.0.1084.52\nOS Version: 6.1 (Windows 7, Windows Server 2008 R2)\nURLs (if applicable) : http://jsfiddle.net/jokeyrhyme/XBSzC/\nOther browsers tested:\nAdd OK or FAIL after other browsers where you have tested this issue:\n     Safari 5: OK (5.1.7)\n  Firefox 4.x: OK (12.0 - 13.0)\n     IE 7/8/9: ? (too hard to figure out how to use)\n\nWhat steps will reproduce the problem?\n1. visit jsfiddle.net demo (http://jsfiddle.net/jokeyrhyme/XBSzC/)\n2. open Inspector and switch to Network view\n3. click the Run button in the jsfiddle\n4. observe 7 AJAX requests to ""echo""\n5. note in the jsfiddle result pane that 7 responses are different\n6. click on one to view request Headers, Preview and Response\n7. note that Form Data (under Headers) is different for each request\n8. note that Preview and Response is same for all requests (this is wrong)\n\nWhat is the expected result?\n8. the Preview and Response should accurately show details specific (and different) for each request\n\nWhat happens instead?\n8. it seems that the Inspector gets confused, maybe it identifies each request by it\'s URL (which is the same for all of my requests) and doesn\'t realise that the POST data is different\n\nPlease provide any additional information below. Attach a screenshot if\npossible.\n\nUserAgentString: Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.5 (KHTML, like Gecko) Chrome/19.0.1084.52 Safari/536.5\n\nAs you can imagine, if you are developing an application and aren\'t using DOM manipulations or Console logging to debug your AJAX requests, then having the Network Inspector display the wrong HTTP responses can be extremely confusing...', '']",1
"['Issue 158910: GWT Animations broke on 24/25', 'Chrome Version       : 25.0.1313.0 canary, also in 24.xxx\nURLs (if applicable) :\nOther browsers tested: All other browsers, including Chrome 22/23 work\nAdd OK or FAIL after other browsers where you have tested this issue:\nSafari 5:\nFirefox 4.x:\nIE 7/8/9:\n\nWhat steps will reproduce the problem?\n1. Some GWT animations fail, looping endlessly\n2.\n3.\n\nWhat is the expected result?\n\nA GWT animation should play once and then end, unless set to loop.\n\nWhat happens instead?\n\nSome animations loop permanently, never returning.\n\nPlease provide any additional information below. Attach a screenshot if possible.\n\nThis looks to be a problem with the com.google.gwt.core.client.Duration class, which makes use of the native Javascript call new Date().getTime().  This looks to be returning incorrect values when animation callbacks are performed.', '']",1
"['Issue 169204: URL hijacking from subframes should work reliably', 'Device name: Nexus 4\n\nFrom ""Settings > About Chrome""\nApplication version: Chrome Beta\nOS: 4.2.1\n\nURLs (if applicable):  http://mailer.fab.com/4f04cdfc5a43876f5c6b0523sv5u.n58/UO134iuoJHFP09W-Cf3c8\n\nSteps to reproduce:\n1. Install the Fab app https://play.google.com/store/apps/details?id=com.fab&feature=nav_result#?t=W251bGwsMSwyLDNd\n2. Have the URL http://mailer.fab.com/4f04cdfc5a43876f5c6b0523sv5u.n58/UO134iuoJHFP09W-Cf3c8 in a Gmail msg\n3. Press on the link from Gmail\n\nExpected result:\nLink opens in Chrome then opens in the Fab app\n\nActual result:\nLink opens in Chrome', '']",1
"['Issue 178281: no touch events from screen when dev tools overlay is shown', 'Chrome Version: beta 25\nChrome OS Version: ? beta 25\nChrome OS Platform: Chromebook Pixel\nNetwork info: <network, encryption type, router model (if known)>\n\nPlease specify Area-* of the system to which this bug/feature applies (add\nthe label below).\n\nSteps To Reproduce:\n1. open dev tools > Overrides \n2. change user agent to iPad - iOS 5\n3. either with or without ""Emulate touch events"", no touch events are registered from the touch screen, though they work fine with the touchpad\n\nExpected Result:\ntouch events on the screen are translated to iOS (safari?) touch events\n\nActual Result:\nno touch events\n\n\nHow frequently does this problem reproduce? (Always, sometimes, hard to\nreproduce?)\nalways\n\nWhat is the impact to the user, and is there a workaround? If so, what is\nit?\nuse touchpad instead of screen', '']",1
"['Issue 215408: ./run_remote_tests.sh should produce better error messages when the PyAutoPerf subtest name is wrong.', 'Chrome Version     :  <From about:version: Google Chrome x.x.x.x>\nOS Version         :  <From about:version: Platform x.x.x.x>\nType of computer   :  <Make/model of computer running Chrome OS>\nNetwork info       :  <network, encryption type, router model (if known)>\n\nPlease specify Area-* of the system to which this bug/feature applies (add\nthe label below).\n\nWhat steps will reproduce the problem?\n1.  ./run_remote_tests.sh --board=lumpy --remote=172.18.111.244 PyAu--args=""--iterations=1 perf.PageCyclerTest.testMoreJSFile""\n\n2.\n3.\n\nWhat is the expected output?\n\nIt should tell me that perf.PageCyclerTest.testMoreJSFile is wrong and perhaps even correct me by saying that the right function is: perf.LiveWebappLoadTest.testNewTabDocs.\n\nWhat do you see instead?\n\nA long-winded error from autotest, that is not human readable at all:\n\n---------------------------------------------------------------\ndesktopui_PyAutoPerfTests/desktopui_PyAutoPerfTests [  FAILED  ]\ndesktopui_PyAutoPerfTests/desktopui_PyAutoPerfTests   FAIL: Pyauto returned error code 1.  This is likely because at least one pyauto test failed.  Refer to the full autotest output in desktopui_PyAutoPerfTests.DEBUG for details.\ndesktopui_PyAutoPerfTests/desktopui_PyAutoPerfTests   08/02 16:14:01 ERROR|base_utils:0113| [stderr] 2012-08-02 16:14:01,308 DEBUG    Loading 1 tests from [\'chromeos_utils.ChromeosUtils.LoginToDefaultAccount\']\ndesktopui_PyAutoPerfTests/desktopui_PyAutoPerfTests   08/02 16:14:01 ERROR|base_utils:0113| [stderr] 2012-08-02 16:14:01,310 DEBUG    Loading pyauto libs from /usr/local/autotest/deps/chrome_test/test_src/out/Release\ndesktopui_PyAutoPerfTests/desktopui_PyAutoPerfTests   08/02 16:14:01 ERROR|base_utils:0113| [stderr] [ RUN        ] chromeos_utils.ChromeosUtils.LoginToDefaultAccount: ""Login to ChromeOS using default testing account.""\ndesktopui_PyAutoPerfTests/desktopui_PyAutoPerfTests   08/02 16:14:07 ERROR|base_utils:0113| [stderr] 2012-08-02 16:14:07,835 INFO     Logged in as performance.test.account@gmail.com.\ndesktopui_PyAutoPerfTests/desktopui_PyAutoPerfTests   08/02 16:14:07 ERROR|base_utils:0113| [stderr] [         OK ] chromeos_utils.ChromeosUtils.LoginToDefaultAccount\ndesktopui_PyAutoPerfTests/desktopui_PyAutoPerfTests   08/02 16:14:07 ERROR|base_utils:0113| [stderr]\ndesktopui_PyAutoPerfTests/desktopui_PyAutoPerfTests   08/02 16:14:07 ERROR|base_utils:0113| [stderr] ----------------------------------------------------------------------\ndesktopui_PyAutoPerfTests/desktopui_PyAutoPerfTests   08/02 16:14:07 ERROR|base_utils:0113| [stderr] Ran 1 test in 6.405s\ndesktopui_PyAutoPerfTests/desktopui_PyAutoPerfTests   08/02 16:14:07 ERROR|base_utils:0113| [stderr]\ndesktopui_PyAutoPerfTests/desktopui_PyAutoPerfTests   08/02 16:14:07 ERROR|base_utils:0113| [stderr] OK\ndesktopui_PyAutoPerfTests/desktopui_PyAutoPerfTests   iterations                                        1\n---------------------------------------------------------------\nTotal PASS: 0/1 (0%)\n\nIn the DEBUG file I see:\n\n08/02 16:14:07 INFO |desktopui_:0095| About to run the pyauto performance tests.\n08/02 16:14:07 INFO |desktopui_:0096| Note: you will see two timestamps for each logging message.\n08/02 16:14:07 INFO |desktopui_:0097|       The outer timestamp occurs when the autotest dumps the\n08/02 16:14:07 INFO |desktopui_:0098|       pyauto output, which only occurs after all tests are\n08/02 16:14:07 INFO |desktopui_:0099|       complete. The inner timestamp is the time at which the\n08/02 16:14:07 INFO |desktopui_:0100|       message was logged by pyauto while the test was actually\n08/02 16:14:07 INFO |desktopui_:0101|       running.\n08/02 16:14:07 DEBUG|base_utils:0081| Running \'DISPLAY=:0 XAUTHORITY=/home/chronos/.Xauthority su chronos -c \'/usr/local/autotest/deps/chrome_test/test_src/chrome/test/functional/pyauto_functional.py --suite=PERFORMANCE perf.PageCyclerTest.testNewTabPage\'\'\n08/02 16:14:08 INFO |base_utils:0113| Traceback (most recent call last):\n08/02 16:14:08 INFO |base_utils:0113|   File ""/usr/local/autotest/deps/chrome_test/test_src/chrome/test/functional/pyauto_functional.py"", line 109, in <module>\n08/02 16:14:08 INFO |base_utils:0113|     Main()\n08/02 16:14:08 INFO |base_utils:0113|   File ""/usr/local/autotest/deps/chrome_test/test_src/chrome/test/functional/pyauto_functional.py"", line 102, in __init__\n08/02 16:14:08 INFO |base_utils:0113|     pyauto.Main.__init__(self)\n08/02 16:14:08 INFO |base_utils:0113|   File ""/usr/local/autotest/deps/chrome_test/test_src/chrome/test/functional/../pyautolib/pyauto.py"", line 6069, in __init__\n08/02 16:14:08 INFO |base_utils:0113|     self._Run()\n08/02 16:14:08 INFO |base_utils:0113|   File ""/usr/local/autotest/deps/chrome_test/test_src/chrome/test/functional/../pyautolib/pyauto.py"", line 6351, in _Run\n08/02 16:14:08 INFO |base_utils:0113|     loaded_tests = unittest.defaultTestLoader.loadTestsFromNames(test_names)\n08/02 16:14:08 INFO |base_utils:0113|   File ""/usr/local/lib64/python2.6/unittest.py"", line 613, in loadTestsFromNames\n08/02 16:14:08 INFO |base_utils:0113|     suites = [self.loadTestsFromName(name, module) for name in names]\n08/02 16:14:08 INFO |base_utils:0113|   File ""/usr/local/lib64/python2.6/unittest.py"", line 584, in loadTestsFromName\n08/02 16:14:08 INFO |base_utils:0113|     parent, obj = obj, getattr(obj, part)\n08/02 16:14:08 INFO |base_utils:0113| AttributeError: type object \'PageCyclerTest\' has no attribute \'testNewTabPage\'\n\n\nHow frequently does this problem reproduce? (Always, sometimes, hard to\nreproduce?)\n\n\nWhat is the impact to the user, and is there a workaround? If so, what is\nit?\n\n\nPlease provide any additional information below.\n\nIdeally there should be a way to list all PyAutoPerfTests.', '']",1
"[""Issue 239693: SyncScheduler's per-DataType throttling may be more severe than expected."", 'In r194766, I changed the per-datatype throttling logic from:\n\nif (job.purpose() == SyncSessionJob::NUDGE &&\n    job.source_info().updates_source == GetUpdatesCallerInfo::LOCAL) {\n\nto:\n\nif (!nudge_tracker_.GetLocallyModifiedTypes().Empty() &&\n    throttled_types.HasAll(nudge_tracker_.GetLocallyModifiedTypes())) {\n\nThis sort of makes sense, but actually breaks things in practice.  The old code relied on the fact that updates_source would be overwritten when an invalidation or refresh request arrived.  Without overwriting, the condition could remain true for a longer time than expected.  \n\nWith the new code, if a type gets throttled and it has a pending local nudge, it will block any sync activity until another, non-throttled type is locally modified.', '']",1
"['Issue 244086: Chrome Toolbox open new tab on enter key stops working', ""Chrome Version       : 28.0.1500.20 beta-m\nURLs (if applicable) : any\nOther browsers tested: N/A\n\n\nWhat steps will reproduce the problem?\n1. Install Chrome Toolbox extension\n2. Instant Enabled OFF (haven't tested with it on)\n3. Type a URL or search query and press enter key\n\n\nWhat is the expected result?\nURL or search opens in new tab\n\nWhat happens instead?\nURL or search opens in existing tab\n\n\nPlease provide any additional information below. Attach a screenshot if\npossible.\n\nI realize this is an extension breaking, not the primary code. I also realize that the Chromium team doesn't want to implement this functionality as an option, despite many people asking for it.\n\nHowever, I report it here because whatever changed in Chromium to make this functionality stop working might make other extensions stop working for no apparent reason, and that's worth looking into. Thanks!"", '']",1
"['Issue 249598: Throw TypeError when null is specified to non-nullable interface parameter', 'Currently, V8 binding generator assumes that all interface types are\nnullable (i.e. writing ""SomeInterface"" is interpreted as\n""SomeInterface?""). When null or incompatible value is passed to an\nargument of non-nullable interface type, we should throw TypeError\nas per WebIDL spec, but the current binding generator does not raise\na TypeError but passes a null pointer to C++ functions, which can only\nthrow a DOMException.\n\nFor example:\n\nIDL definition of Document.createNodeIterator:\nhttp://src.chromium.org/viewvc/blink/trunk/Source/core/dom/Document.idl?revision=152411#l76\n    [RaisesException] NodeIterator createNodeIterator(Node root,\n                                                      optional unsigned long whatToShow,\n                                                      optional NodeFilter filter,\n                                                      optional boolean expandEntityReferences);\n\nC++ Implementation:\nhttp://src.chromium.org/viewvc/blink/trunk/Source/core/dom/Document.cpp?revision=152411#l1538\n    PassRefPtr<NodeIterator> Document::createNodeIterator(Node* root, ExceptionCode& ec)\n    {\n        // FIXME: Probably this should be handled within the bindings layer and TypeError should be thrown.\n        if (!root) {\n            ec = NOT_SUPPORTED_ERR;\n            return 0;\n        }\n        return NodeIterator::create(root, NodeFilter::SHOW_ALL, PassRefPtr<NodeFilter>());\n    }\n\nThe FIXME above well explains the issue.\n\nExisting C++ code throws various kinds of DOMExceptions when a null pointer\nis passed to such an argument, like NOT_FOUND_ERR or NOT_SUPPORTED_ERR.\n\nUsers might not care much about the type of raised exceptions, but\nthis seems like a big hole in terms of the standard conformance.', '']",1
"[""Issue 302078: PNaCl translator apps shouldn't require SRPC"", 'The current PNaCl translator apps assume SRPC communication with the NaCl plugin. This makes it harder to refactor the trusted NaCl plugin since it forces us to use SRPC on the host side.\n\nThis bug is to modify the translators and Chrome to communicate without using SRPC.', '']",1
"['Issue 341032: DOM wrappers should not leak between content scripts', 'For security reasons, no JavaScript objects should leak among content scripts of Chrome extensions. However, the current V8 binding architecture for content scripts is fragile and has a lot of potential bugs that might lead to breaking the security model. We should fix them.\n\nThe goal is to guarantee that DOM wrappers never leak between isolated worlds.\n\nA design document is here: https://docs.google.com/a/google.com/document/d/1AtnKpzQaSY3Mo1qTm68mt_3DkcZzrp_jcGS92a3a1UU/edit', '']",1
"['Issue 345580: Promises swallow exceptions if no catch', 'Google Chrome 34.0.1847.3 (Official Build 252028) dev\nOS Mac OS X \nBlink 537.36 (@167396)\n\nvar p = new Promise(function(fulfill, reject) {\n  setTimeout(function() { fulfill(); });\n});\np.then(function() { throw new Error(""error!""); }, function(e) {  });\n\nNothing is logged to the console, no indication that something has gone wrong is given anywhere. The exception should definitely be logged, and the window onerror handler should probably run too otherwise error reporting systems won\'t work properly.\n\nThis makes using promises super frustrating since if you mess up you get no output at all. :(', '']",1
"['Issue 358278: AU: SystemState and subclasses need to be refactored', ""I'm seeing some strange effects when trying to use MockSystemState for unit testing a module that depends on SystemState.\n\n* An expectation set on one of the sub-mocks (mock_update_attmpter_) are not fulfilled but gmock doesn't call out the error.\n\n* Some members are never deleted upon destruction, because they're plain pointers. Wrapping them in scoped_ptr does not work because we're using forward declarations for many of these members' types, whereas scoped_ptr requires complete types.\n\n* SystemState declares a pure interface, although much of the behavior of its subclasses (RealSystemState and MockSystemState) is shared: it's merely an aggregator of global objects whose main purpose is to return these various members upon request.\n\nThis is blocking some work on the PolicyManager so I'd like to pursue it at high priority."", '']",1
"['Issue 378998: Enable tegra DRM', ""The title says it all, let's enable the tegra drm."", '']",1
"['Issue 389439: Tripadvisor uses 100% CPU', 'Google Chrome 36.0.1985.98 (Official Build 279612) beta\nPlatform 5841.55.0 (Official Build) beta-channel link\nBlink 537.36 (@176821)\nJavaScript V8 3.26.31.8\nFlash 14.0.0.136-r1\n\nWhat steps will reproduce the problem?\n1. Go to http://www.tripadvisor.com/Attractions-g1798615-Activities-South_Lake_Tahoe_Lake_Tahoe_California_California.html\n\nResult:\n1.1 The tab uses CPU 100% constantly. The memory usage goes up to 1.1 GB from 250 MB in repetitive cycle.\n\n100% reproducible on Pixel.', '']",1
"['Issue 410766: Rewrite MetadataCache.', 'The current MetadataCache design is very complicated. Eg. filesystem metadata may be delivered by two different providers (DriveProvider and FileSystemProvider). Metadata for images can be provided in two different categories of properties (""drive"" and ""media""). Transformation in ""drive"" is of different format than in ""media"".\n\nWhen fetching metadata, maybe instead of requesting categories, we should request for exact properties? Eg.\n\nmetadataCache.get([entry], [\'/media/imageWidth\', \'/media/imageHeight\'], ...);\n\nThe MetadataCache should device whether fetch these data from Drive metadata or from contents.\n\nCurrently we have to do stuff like:\nmetadataCache.get([\'entry\'], \'drive|media\', function(properties) { ... }), and then check for both - properties.drive and properties.media.\n\nThis is how it looks like:\nhttps://code.google.com/p/chromium/codesearch#chromium/src/ui/file_manager/gallery/js/image_editor/image_view.js&l=286\n\nSimilarly size and modificationTime can be provided by two different providers.\nTo get size and modification time faster, for drive files, we have to explicitly ask for drive metadata when calling get(). However, metadata providers are skipped when they can\'t handle some entries (MetadataProvider::supportsEntry()), so we should basically always call metadataCache.get(\'filesystem|drive\') when we call metadataCache.get(\'filesystem\').\n\nBesides, MetadataCache is a constant place for regressions. Maybe it\'s time to redesign it?', '']",1
"['Issue 439548: Issues playing Non 30fps video in Chrome, especially 60fps video', 'Chrome is unable to handle non 30fps playback properly. \n\n@strobe has a ton of examples calling this out where video (VP9) works fine in Firefox, but not in Chrome.', '']",1
"['Issue 448399: Unbundle memory_inspector and make it a chrome app', ""The plan is to make memory_inspector unbundled (w.r.t dependencies in the chromium tree) so we can easily pack it in a Chrome App and redistribute without requiring a chrome tree.\n\nThe following steps are necessary:\n\n1. Remove the dependency from pylib, which in turns depends on testrunner and adb_interface and interface directly with the adb daemon using TCP (we might reuse some library for this, let's check).\nCon:\n - The user has now to start the adb server manually before using MI.\nPro:\n - MI can be run in a sandboxed chrome app.\n - MI will not cause restarts of the ADB server if something else (e.g. testrunner, instrumentation tests) is already running with using a different adb server binary.\nAt the end of this step we'll end up with an adb.py in backends/android\n\n2. Rewrite the code in android_backend.py to leverage the library of step 1.\n\n3. Remove the accidental dependency from dateutil in www_server.py (2 call sites).\n\n4. Remove all references to multiprocessing and switch to thread (actually it's just background_tasks.py). multiprocessing is not supported in naclports yet.\n\n5. Move the bits required to create the packaged app inside a folder (e.g., src/tools/memory_inspector/chrome_app) and write a script to generate the final .zip"", '']",1
"['Issue 463597: [MemoryPressure] Move the tab discarder logic from ChromeOS to Chrome', 'There are several parts of the discarding logic:\n\n1 The trigger (in this case the MemoryPressureObserver)\n2 the data collector (which tab can get discarded)\n3 the tab discarder itself\n\nAll we need to handle is the part 2 which can be found in:\n\nchrome/browser/chromeos/memory/oom_priority_manager.[cc/h]\n\nThis file is mostly OS agnostic, but has some OS specials.\n\nSo...\n- an OS agnostic base class would need to be created in a different place.\n- its initialization would need to get moved from ChromeOS\'s BrowserProcessPlatformPart to a more general part of initialization, add OS dependent delegates (e.g. make them available through file dependencies like oom_priority_manager_delegate_chromeos.cc).\n- OS dependent things would be:\n  - At the moment we have a an alternate (but old) LowMemoryObserver for ChromeOS which could either be entirely removed - or - would need to be initialized in an OS specific implementation (see line 186 ""GetMemoryPressureObserver()"" for an example).\n  - Functions like RecordDiscardStatistics, AdjustFocusedTabScoreOnFileThread would need to be refactored to be called from the OS dependent portion.\n\nI hope I have covered everything.', '']",1
"['Issue 478744: Lots of FunctionTemplateInfos allocated in inbox', 'If I take a heap snapshot for inbox, I see thousands of distinct FunctionTemplateInfo objects that also end up in the function_cache. There might be something wrong. yukishiino@ / haraken@, could you please take a look?', '']",1
"['Issue 481122: Allow the page to render before <link> tags in body', 'Chrome http://www.webpagetest.org/video/compare.php?tests=150424_57_12PJ-r:1-c:0\nFirefox http://www.webpagetest.org/video/compare.php?tests=150424_MS_1297-r:1-c:0\nIE http://www.webpagetest.org/video/compare.php?tests=150424_NH_12XE-r:1-c:0\n\nIn the test above, the page has inline CSS, \'defer\'d javascript, then the HTML for the top toolbar. After the toolbar, there\'s a <link> for some CSS (load.php in the waterfall), followed by the article content.\n\nWe block rendering the entire page until the CSS has loaded. IE will allow content before the <link> to render, and block afterwards. Firefox is similar to IE, but overshoots slightly (the ""Hulk Hogan"" heading is after the <link>) revealing unstyled content.\n\nIE is winning this one, can we copy them?\n\nDevelopers are currently having to hack around our behaviour here, eg https://github.com/filamentgroup/loadCSS', '']",1
"['Issue 489744: VideoFrame cleanup', 'VideoFrame [1] is right now an eclectic mixture of:\n\n- generic metadata and accesors.\n- a series of factory methods, some of them platform\nspecific.\n- storage-specific operations, such as shared memory \nhandle accessor or texture mailbox holding.\n\nVideoFrame::Format [2] mixes pixel formats and\ncolor spaces.\n\nThis bug tracks clean up/refactor activities addressing \nthese issues.\n\n\n\n[1] https://code.google.com/p/chromium/codesearch#chromium/src/media/base/video_frame.h&sq=package:chromium&type=cs&q=videoframe&l=27\n[2] https://code.google.com/p/chromium/codesearch#chromium/src/media/base/video_frame.h&sq=package:chromium&type=cs&q=videoframe&l=50', '']",1
"['Issue 511425: HTML5 video seek issue', ""Chrome Version       : 43.0.2357.134 (64-bit)\nOther browsers tested:\nAdd OK or FAIL after other browsers where you have tested this issue:\n     Safari 6: OK\n  Firefox 20: OK\n\nWhat steps will reproduce the problem?\n1. Post any mp4 video on the page using the native video tag\n2. Use Scrub to slowly seek video from beginning to end\n3. Use javascript to update video currentTime. \n4. Use javascript to update video currentTime using an interval to jump to incrementally higher currentTime\n\nWhat is the expected result? Video should seek to correct frame\n\nWhat happens instead? Video jumps randomly, to random frames.\n\nThis bug occurs when you're scrubbing the controls from one end of the video to the other. The video can sometimes jump to a random frame earlier in the video. Likewise, if you use javascript to set an interval and update the currentTime by an increment, ex.. += .5, the video should jump from 0, .5, 1, 1.5, 2, 2.5, 3, etc. Instead, the video will jump to a random frame, typically back, before correcting itself and jumping to the right frame. \n\nI've provided a video to demonstrate. \n\nhttp://screencast.com/t/VBIUwnAJo\n\nIn the video I play the video through once, then drag the scrub so you can see the frames randomly jump backwards. This happens when using the video API video.currentTime as well."", '']",1
"['Issue 522567: Constant crashes in SoundHound on FATAL:render_frame_impl.cc(4829) Check failed: false. Invalid URL passed about:blank', ""Device name: OnePlus\nAndroid version: 5.0.2\nWebView version (from system settings -> Apps -> Android System WebView): 45.0.2454.37\nApplication: SoundHound\nApplication version: 6.8.2\n\n\nSteps to reproduce:\n1. Open the app.\n2. While it's loading hit the Home button.\n3. Crash.\n\nExpected result:\nShould not crash.\n\nActual result:\nCrash, happens every time."", '']",1
"['Issue 524578: fallback fonts on linux create multiple sktypeface streams', ""The Skia infra team creates captures of Chrome pages like this one on Ubuntu:\n\n(internal Google address)\n/bigstore/cluster-telemetry/skps/All/d806fd9-d1c6b7c/slave2/http___www_moeerolibrary_com.skp\n\nThis skp contains 125 copies of the fallback font Kochi Gothic, ballooning the file size to over 1 gig.\n\nIt looks like the fallback font creates a new SkTypeface most times it is referenced. The downside is that Skia won't reuse the font cache for many characters in the fallback fonts.\n\nThis is a regression, but it is unclear when this behavior started.\n\nEmil, please add whoever knows this code best."", '']",1
"['Issue 529859: Investigating using a standard type for DisplayItems in DisplayItemList', ""We currently use a SidecarListContainer to store DisplayItems in a display item list. This works fine, but it's difficult for devs not familiar with the code to work with it, since it's not immediately clear what the performance characteristics are like.\n\nMaybe it's possible to replace this with something like a vector or a deque, and keep similar performance. This bug is to track the performance changes that might result from switching SidecarListContainer to be a deque in DisplayItemList."", '']",1
"['Issue 551609: APIs can also be enabled with matching runtime feature', 'As a fallback, the framework will also check for an existing runtime enabled feature.\n\nAssume an experimental API has a dedicated runtime enabled feature (e.g. ""FooFeature""). The API implementation can integrate with the Experimental Framework, using the same name as the API name. Thus, by turning on the runtime feature, the API will be enabled by the framework, even if a valid API key is missing (or the framework is itself disabled).', '']",1
"['Issue 556861: update chromeos-3.18 rhashtable', ""rhashtable.c in chromeos-3.18 branch is roughly 85 patches behind mainline. This won't work for USE=wireless42 builds.\n\nI've created a sandbox with 106 patches:\n    UPSTREAM for rhashtable.[ch] plus UPSTREAM patches to netlink, net filter, and net link).\n\nTo inspect this branch:\ncd ~/trunk/src/third_party/kernel/v3.18\ngit checkout -b update_rhashtable --track remotes/cros/chromeos-3.18\ngit fetch cros refs/sandbox/grundler/update_rhashtable-3.18\ngit rebase FETCH_HEAD\n\n\ngit diff remotes/cros/chromeos-3.18.. --stat\n\n fs/nfsd/nfs4state.c                     |    6 +-\n include/linux/list_nulls.h              |    4 +-\n include/linux/netlink.h                 |    4 +-\n include/linux/rhashtable.h              |  824 +++++++++++++++++++++++++++++++++++++++++++++++++++++++++---------\n include/net/genetlink.h                 |    5 +\n include/wireless-4.2/linux/rhashtable.h |  822 -----------------------------------------------------------------\n kernel/audit.c                          |    2 +-\n lib/Kconfig.debug                       |    2 +-\n lib/Makefile                            |    5 +-\n lib/rhashtable.c                        | 1126 +++++++++++++++++++++++++++++++++++++++++++++++-------------------------------------------\n lib/test_rhashtable.c                   |  202 ++++++++++++++++\n net/core/net_namespace.c                |    1 +\n net/netfilter/nfnetlink.c               |    2 +-\n net/netfilter/nft_hash.c                |  102 ++++-----\n net/netlink/af_netlink.c                |  178 +++++++++------\n net/netlink/af_netlink.h                |    9 +-\n net/netlink/diag.c                      |   12 +-\n net/netlink/genetlink.c                 |   61 +++++\n net/openvswitch/flow_table.c            |    4 +-\n net/wireless/nl80211.c                  |   18 +-\n 20 files changed, 1760 insertions(+), 1629 deletions(-)\n\nI've attached sduvvuri's python script (modified version) to help compare with the original UPSTREAM patches."", '']",1
"['Issue 558054: Remove support for Win8 Metro mode', ""(Apologies if this bug already exists, I couldn't find it)\n\nJustin says we can remove support for metro mode, aka Windows ash shell. The only thing we're blocked on right now is the engineering effort required. This would be good because:\n\n- [the part most relevant to estade] it would simplify NativeTheme-ing (always use NativeThemeWin, never NativeThemeAura on Windows)\n- we could close a ton of metro mode bugs on this issue tracker\n- I'm sure a lot more parts of the codebase would get simpler"", '']",1
"['Issue 567781: SyzyAsan interfacing with chrome', 'chrisha:\n\nJust to give a more compete picture of how we interact with crash processors.\n\nThe SyzyASAN runtime library interfaces with the crash processor by looking at the exports provided by chrome.exe. The presence of certain exports tells it Kasko is available (ReportCrashWith*). Otherwise it looks for Breakpad\'s crash function, CrashForException. If neither of these are present it falls back to its own crash handling.\n\nSyzyASAN ""crashes"" in one of two ways. The first is via its own instrumentation, when a memory error is detected. It will directly call its preferred crash handler in this case. The second is via any other crash. The RTL always installs an unhandled exception filter, with the expectation being that it will get in after the crash handler, thus will get a chance to examine the crash first. It will do some additional analysis, add some metadata and defer to its preferred crash handler if possible. If not it doesn\'t handle the error and passes it to the next handler in the chain. You can see the various logic in runtime.cc:\nhttps://github.com/google/syzygy/blob/30514796814b22d7e058231c8b1cb1c324b4a6eb/syzygy/agent/asan/runtime.cc#L87\n\nKasko doesn\'t try to cover all of the surface area that Breakpad does. For the most part, it is only meant to be invoked directly by the RTL, allowing us to add extra metadata. As such it replaces the minidump generation and upload portion of the Breakpad, but not *all* of its insertion and generic crash handling points. This means that even when Kasko is activated, some crashes fall through to the underlying crash processor, be it Crashpad or Breakpad. In an attempt to still play nice with the underlying crash processor we use *its* crash keys mechanism. In the Breakpad world, this was provided by SetCrashKeyValueImpl, and formerly SetCrashKeyValuePair. (We support both, as we try to make the runtime library work with any version of Chrome, regardless of the crash processor available.) When Kasko handles a crash it copies the crash keys over from the underlying crash processor.\n\nFrom a glance at the code it looks like SyzyASAN is now the only user of SetCrashKeyValueImpl, and that Crashpad has moved on to reimplementing base::debug::SetCrashKeyValue. It used to be that this delegated to the Breakpad export in chrome.exe, but this is no longer the case.\n\nIn my mind you\'ve broken two things here:\n\n1) Any users of SetCrashKeyValueImpl are now left hanging (maybe only SyzyASAN?), as these crash keys now go nowhere. I think it would be perfectly fine for Crashpad to provide the implementation of this, and have them talk directly to Crashpad\'s crash key mechanism. It\'s either that, or we teach the SyzyASAN RTL about yet another crash key mechanism, and detect Crashpad at runtime.\n2) Kasko can no longer scrape crash keys from the underlying crash handler. It would be nice to have this reimplemented to play nice with Crashpad as well. There\'s really not a long going on here, about 20 lines of code in GetKaskoCrashKeys in kasko_client.cc:\nhttps://code.google.com/p/chromium/codesearch#chromium/src/chrome/app/kasko_client.cc&q=kasko%20crashkeys&sq=package:chromium&l=28\n\nThe other option would be to do what Siggi suggests, which is to initialize both the Crashpad and Breakpad crash key mechanisms, have base::debug set both of them, and continue to support SetCrashKeyValueImpl as it is currently implemented. I\'m not overly partial to one solution or the other.\n\nHopefully this makes it a little more clear what exactly we need to keep running.', '']",1
"['Issue 570532: See if we can speed up dma-mapping allocations', 'As part of bug #481462 / bug #570480 it looks like __iommu_alloc_buffer() is very slow.\n\nCan we speed it up at all?\n\n---\n\nStarted this at <https://chromium-review.googlesource.com/#/c/317976/> but need to prove that it helps.', '']",1
"['Issue 580584: Chr-48 regression, w bisect: Object.defineProperty broken for window.localStorage, sessionStorage, etc', ""UserAgent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/48.0.2564.82 Safari/537.36\n\nSteps to reproduce the problem:\nObject.defineProperty can be used to override window.localStorage, sessionStorage etc for javascript mocking/monitoring purposes. As of Chrome 48, this approach is no longer working: Object.defineProperty runs, but the localStorage property is not being correctly overridden. Overridding also seems to be broken for other window properties, including sessionStorage, indexedDB and others.\n\nI've attached a test-case-webpage for window.localStorage. Bisect output also below. The test-case overrides localStorage, 'nulling' setItem, and making getItem return a fixed value. Post-override, we would expect setItem to have no effect, and getItem to return the fixed value.\n\nTo run the test-case:\n1. Open test-definedproperty.html in Chrome \n2. View the console output\n\nWhat is the expected behavior?\nConsole shows override worked:\nExpected: [fixed-value], actual: [fixed-value]: pass\nThis was the output in 47.0.2526.111\n\nWhat went wrong?\nConsole shows override failed:\nExpected: [fixed-value], actual: [updated-value]: fail\nThis is the output in 48.0.2564.82\n\nDid this work before? Yes 47.0.2526.111\n\nChrome version: 48.0.2564.82  Channel: stable\nOS Version: OS X 10.11.2\nFlash Version: Shockwave Flash 20.0 r0\n\nI ran a bisect between 47.0.2526.111 and 48.0.2564.82. Output below:\n\npython bisect-builds.py -a mac -g 352221 -b 359700 --use-local-cache -- file:///.../test-defineproperty.html\nDownloading list of known revisions...\nLoaded revisions 15734-370962 from /.../.bisect-builds-cache.json\nDownloading revision 355537...\nReceived 67184690 of 67184690 bytes, 100.00%\nBisecting range [352221 (good), 359700 (bad)].\nTrying revision 355537...\nRevision 355537 is [(g)ood/(b)ad/(r)etry/(u)nknown/(s)tdout/(q)uit]: g\nDownloading revision 357801...\nReceived 66959035 of 66959035 bytes, 100.00%\nBisecting range [355537 (good), 359700 (bad)].\nTrying revision 357801...\nRevision 357801 is [(g)ood/(b)ad/(r)etry/(u)nknown/(s)tdout/(q)uit]: b\nDownloading revision 356754...\nReceived 66819298 of 66819298 bytes, 100.00%\nBisecting range [355537 (good), 357801 (bad)].\nTrying revision 356754...\nRevision 356754 is [(g)ood/(b)ad/(r)etry/(u)nknown/(s)tdout/(q)uit]: b\nDownloading revision 355969...\nReceived 66755963 of 66755963 bytes, 100.00%\nBisecting range [355537 (good), 356754 (bad)].\nTrying revision 355969...\nRevision 355969 is [(g)ood/(b)ad/(r)etry/(u)nknown/(s)tdout/(q)uit]: g\nDownloading revision 356305...\nReceived 66741245 of 66741245 bytes, 100.00%\nBisecting range [355969 (good), 356754 (bad)].\nTrying revision 356305...\nRevision 356305 is [(g)ood/(b)ad/(r)etry/(u)nknown/(s)tdout/(q)uit]: g\nDownloading revision 356526...\nReceived 66771530 of 66771530 bytes, 100.00%\nBisecting range [356305 (good), 356754 (bad)].\nTrying revision 356526...\nRevision 356526 is [(g)ood/(b)ad/(r)etry/(u)nknown/(s)tdout/(q)uit]: b\nDownloading revision 356476...\nReceived 66766040 of 66766040 bytes, 100.00%\nBisecting range [356305 (good), 356526 (bad)].\nTrying revision 356476...\nRevision 356476 is [(g)ood/(b)ad/(r)etry/(u)nknown/(s)tdout/(q)uit]: b\nDownloading revision 356382...\nReceived 66755554 of 66755554 bytes, 100.00%\nBisecting range [356305 (good), 356476 (bad)].\nTrying revision 356382...\nRevision 356382 is [(g)ood/(b)ad/(r)etry/(u)nknown/(s)tdout/(q)uit]: b\nDownloading revision 356326...\nReceived 66745064 of 66745064 bytes, 100.00%\nBisecting range [356305 (good), 356382 (bad)].\nTrying revision 356326...\nRevision 356326 is [(g)ood/(b)ad/(r)etry/(u)nknown/(s)tdout/(q)uit]: b\nDownloading revision 356311...\nReceived 66746675 of 66746675 bytes, 100.00%\nBisecting range [356305 (good), 356326 (bad)].\nTrying revision 356311...\nRevision 356311 is [(g)ood/(b)ad/(r)etry/(u)nknown/(s)tdout/(q)uit]: b\nYou are probably looking for a change made after 356305 (known good), but no later than 356311 (first known bad).\nCHANGELOG URL:\n  https://chromium.googlesource.com/chromium/src/+log/5c265faa70626b7754e8b62300f65771dae2adbf..7c8b944be33ee7feadf71c631a8cc6c2d58bf2ea"", '']",1
"['Issue 19470: Linux support for OSS 4 or option to build with no sound', 'Chrome Version       : All\nURLs (if applicable) :\nOther browsers tested: All\nAdd OK or FAIL after other browsers where you have tested this issue:\nSafari 4:\nFirefox 3.x:\nIE 7:\nIE 8:\n\nWhat steps will reproduce the problem?\n1. download latest chromium on an OSSv4 system\n2. Complains about missing asound2 libs.\n3.\n\nWhat is the expected result?\n\n\nWhat happens instead?\n\n\nPlease provide any additional information below. Attach a screenshot if\npossible.', '']",1
"['Issue 43219: Password not remembered when login form uses XHR or equivalent', ""Chrome's password autofill code only recognizes logins that are made through a normal form \nsubmit. If the site uses an onSubmit handler to abort the normal submit (by returning false) and \nhandles the login itself using an XHR or something equivalent, Chrome won't think there was a login \nand won't offer to save the password.\n\nHulu.com is a major site that's known to do this (at this writing.)\n\nThis is a spin-off of issue 28910."", '']",1
"['Issue 64846: document.hasFocus() always returns true', 'Chrome Version       : 8.0.552.210 (Official Build 66730) beta\nURLs (if applicable) :\nOther browsers tested:\nAdd OK or FAIL after other browsers where you have tested this issue:\n     Safari 5: OK\n  Firefox 3.x: OK\n       IE 7/8: OK\n\nWhat steps will reproduce the problem?\n\n1. Create an HTML document with the following code:\n<script>\nsetTimeout( function(){ document.write( document.hasFocus()); }, 1000 );\n</script>\n\n2. Open document in Chrome - after 1 second, it will write ""true"" to the page, as it should.\n\n3. Refresh document, and change to another tab before 1 second has elapsed. After a few seconds, change back to this tab. It will still have output ""true"".\n\n\nWhat is the expected result?\nIt should output ""false"" if the current document does not have focus (e.g. when another tab is being viewed, or when the Chrome application does not have focus in the OS).\n\n\nWhat happens instead?\ndocument.hasFocus() always returns ""true"", even if the tab or the Chrome application is in the background.\n\n\nPlease provide any additional information below. Attach a screenshot if\npossible.\n\nFirefox 3+, IE7+, and Safari 5 all behave as expected. Opera 10.63 (latest stable) does not support this function yet. But since Chrome *does* support it, it should work as it\'s supposed to - only returning ""true"" when the current document is truly ""in focus"".', '']",1
"[""Issue 96351: Browser side thumbnailing doesn't work on composited pages"", ""The browser-side thumbnail generator currently relies on reading the browser-side backing store, which doesn't exist for GPU composited pages.  This is unfortunate since the browser-side thumbnailer is significantly better than the renderer-side thumbnailer in many ways, so we'd like to switch over when possible.\n\nThe first open issue is whether the thumbnailing can be made asynchronous from the browser's point of view.  One potentially problematic caller is the Aero Peek code - from a quick glance at http://google.com/codesearch#OAMlx_jo-ck/src/chrome/browser/aeropeek_manager.h&type=cs I'm not sure if it's OK to wait for another process when getting thumbnails for Aero Peek.  We can probably change all other thumbnail users (like the NNNTP) to be async.\n\nThere are a few ways we could get a thumbnail from the browser process for a composited tab.  One option is to send an IPC to the renderer and ask the renderer side compositor to produce a new frame (possibly downscaled), read it back, and send it to the browser process.  This would be a relatively small amount of code, but since the render process can be arbitrarily blocked the browser process can't do a blocking IPC.\n\nAnother option that may be lower latency is doing the readback from the GPU process, assuming that we can get access to the most recently composited content on that side.  We probably still couldn't do a blocking IPC from the browser side, since the GPU process itself might be slow, but this would have the advantage of not requiring any new texture uploads or the like from the renderer side.\n\n\nGetting the thumbnailer right has historically been tricky, there are subtle design considerations to take into account to get a robust system."", '']",1
"['Issue 103307: DirectoryBackingStore open failure not handled properly', ""The DirectoryBackingStore and DirectoryManager classes use the DirOpenResult enum to report errors encountered while loading local sync data from the sqlite database.  The Directory::Open() function flattens this enum to a single boolean return value indicating success or failure.  \n\nThe enum is defined as follows:\nenum DirOpenResult { OPENED,   // success.\n                     FAILED_NEWER_VERSION,  // DB version is too new.\n                     FAILED_MAKE_REPOSITORY,  // Couldn't create subdir.\n                     FAILED_OPEN_DATABASE,  // sqlite_open() failed.\n                     FAILED_DISK_FULL,  // The disk is full.\n                     FAILED_DATABASE_CORRUPT,  // Something is wrong with the DB\n\nThe actions taken when we encounter one of these errors are entirely unrelated to the cause of these errors.  \n\nIn SyncManager::SyncInternal::OpenDirectory(), we DCHECK that the request to open returned success (result == OPENED).  This prevents us from testing this (legitimate) error path on debug builds.  \n\nIn a release build SyncManager::SyncInternal::OpenDirectory() would return false and propagate the error back through SyncManager::SyncInternal::SignIn() to SyncManager::SyncInternal::Init().  The SyncManager would inform its observers of the failure with a call to OnInitializeComplete().  \n\nSyncBackendHost will receive this callback and inform the PSS of the failure with a posted task.  It also schedules a call to SyncBackendHost::StartSavingChanges() on the syncer thread, a call which would fail if it ever won the race condition and ended up being invoked.  \n\nThe PSS responds to the error by shutting down the sync backend.  It will not delete the sync DB which caused the error.  \n\nThe shutdown path for the backend is not fully prepared for the fact that the database has not been initialized, and in release mode it will skip over some DCHECKs and do wrong things while trying to shut down.  See SyncManager::SyncInternal::ShutdownOnSyncThread(), where we call GetUserShare() without checking to see if it was properly intialized first."", '']",1
"['Issue 146077: New DesktopNativeWidgetAura and DesktopRootWindowHost[Win|Linux]', 'For win/linux-aura, we need a few new classes:\n\nDesktopNativeWidgetAura, a new NativeWidgetPrivate implementation that talks through a\n\nDesktopRootWindowHost interface to one of the following platform-specific implementations:\n\nDesktopRootWindowHostWin (a RootWindowHost implementation that wraps a HWND on the windows desktop) and,\n\nDesktopRootWindowHostLinux (likewise, for linux).', '']",1
"['Issue 166642: Refactor SSL client certificate handling for all platforms', 'As discussed on https://chromiumcodereview.appspot.com/11458012/, the way client certificates are managed in Chromium must be modified to accomodate platforms like Android.\n\nThis bug is to track the issue, and to explain the approach being considered. I plan to work on this with ppi@ so this will server as\nour reference design proposal too :)\n\n\nI. Current behaviour:\n---------------------\n\n  The following describes my understanding of the current behaviour.\n  For simplicity reasons, a few layers, which might implement caching\n  have been ignored here (feel free to correct / add information):\n\n  1/ SSLClientSocket::Connect() is called on the I/O thread to connect\n     to an SSL server.\n\n  2/ The server sends its ""Hello Server"" + ""Server Certificate"" messages,\n     as well as a ""Certificate Request"", the latter asking for a client\n     certificate that matches various criteria which are:\n\n         - a list of valid certificate signing key types.\n         - a list of valid certificate authorities (issuers).\n         - (since TLS 1.2) a list of signature algorithms.\n\n  3/ The SSLClientSocket implementation uses a platform-specific API\n     to query a list of compatible installed client certificates.\n\n     [NOTE: This call is actually blocking the I/O thread, tracked\n            by http://code.google.com/p/chromium/issues/detail?id=90277 ]\n\n  4/ The SSLClientSocket::Connect() method returns with ERR_CLIENT_AUTHENTICATION_NEEDED\n\n  5/ The caller calls SSLClientSocket::GetSSLCertRequestInfo() to retrieve\n     details about the client certificate request. This retrieves a\n     net::SSLCertRequestInfo object which only contains a |client_certs|\n     list of X509Certificate objects, created in step 3.\n\n  6/ The caller uses this list to prompt the user to select an appropriate\n     certificate. This typically involves posting a task on the UI thread\n     in the browser layer.\n\n  7/ When a certificate is selected, its pointer is stored into the\n     |client_cert| member of the net::SSLConfig object associated with\n     the current SSL connection (and |send_client_cert| is set to \'true\')\n\n     Then SSLClientSocket::Connect() is called again.\n\n  8/ ::Connect() will pick up the client certificate, and will use it\n     in the ""Client Certificate"" message sent back to the server.\n\n  9/ ::Connect() also uses the client certificate to retrieve the\n     corresponding private key from the system, and use it to sign\n     the ""Verify Certificate"" that is sent next to the server.\n\n     [NOTE: The private key bytes don\'t need to be directly accessible,\n            only the ability to sign a message with the private key\n            of a known installed certificate. The signing itself is\n            typically done by a platform API].\n\nII. Problem with current behaviour:\n-----------------------------------\n\nOn Android, there is no platform API that can perform the client\ncertificate selection required by step 3. More precisely, no API\nthat can do it silently. There is an API, that must be called from\nthe UI thread, that will directly prompt the user to select a\ncertificate. This API takes a list of certificate key types and\nissuers as its parameters though:\n\n  http://developer.android.com/reference/android/security/KeyChain.html#choosePrivateKeyAlias(android.app.Activity, android.security.KeyChainAliasCallback, java.lang.String[], java.security.Principal[], java.lang.String, int, java.lang.String)\n\nThe only way to use this is thus to expose the certificate request\nparameters (i.e. lists of key types / issuers / signature algorithms)\nin step 5.\n\nAnother issue is that there is no native Android API to sign a message\nfrom a given a client certificate\'s private key.\n\nMore precisely, choosePrivateKeyAlias() returns a string, called a\n""private key alias"", that can later used with KeyChain.getPrivateKey(alias).\n\nAnd there is no API like KeyChain.getPrivateKeyForCert(certificate),\nwhich is the kind of stuff the current net code relies on for other\nplatforms.\n\nIII. Proposed solution:\n-----------------------\n\nHere\'s the description of a tentative way to refactor this client\ncertificate handling to make it work on Android, while preserving\na uniform net API accross all platforms:\n\n  A/ Modify SSLCertRequestInfo to return the actual request\n     parameters, instead of a filtered |client_certs| list.\n\n  B/ Provide a new NET_EXPORT API used to filter client certificates\n     based on SSLCertRequestInfo parameters. This essentially exposes\n     what is currently being done under the hood by existing\n     SSLClientSocket implementations.\n\n     Of course, the Android-specific implementation would return \n     with an error, since it can\'t be implemented on this platform.\n\n     Example declaration:\n\n     net/base/client_cert_store.h:\n\n        class ClientCertStore {\n        public:\n           // Retrieve a list of installed client certificates\n           // that match a given SSL client certificate request.\n           // |cert_request_info| are the request parameters from\n           // the SSL server.\n           // |out| will receive the list of compatible certificates\n           // on success. An empty list means there are no compatible\n           // certificates.\n           // Returns true on success, or false on error.\n           bool GetCompatibleClientCerts(\n               const SSLCertRequestInfo& cert_request_info,\n               std::vector<X509Certificate*>* out);\n        };\n\n   C/ Modify existing client code to use the new SSLCertRequestInfo\n      + net::ClientCertStore::GetCompatibleClientCerts().\n\n      This will probably touch net/http_request, the content layer,\n      and some unit tests.\n\n   D/ For Android, a new NET_EXPORT API is needed to store the\n      association between a client certificate, and its private key\n      object handle (a JNI global reference really).\n\n        net::android::StoreClientCertKey(const net::X509Certificate& cert,\n                                         jobject privateKeyRef);\n\n      This will be called after KeyChain.choosePrivateKeyAlias(),\n      KeyChain.getCertificateChain() and KeyChain.getPrivateKey() are\n      called to retrieve the appropriate data from the platform\n      (e.g. on the UI thread).\n\n      The point of this function is to later allow the Android-specific\n      SSLClientSocket() implementation to sign the ""Verify Certificate""\n      with the right private key, given that it will only have a pointer\n      to the certificate object (passed from SSLConfig.client_cert).\n\n      I.e. this is used to route around the fact that the ""private key\n      alias"" string cannot be passed back to SSLClientSocket() through\n      a SSLConfig member. An alternative would be to store the string\n      or the private key handle in SSLConfig, but this seems an\n      undesirable platform-specific change.\n\n   E/ There are still no proper SSL client-certificate unit tests,\n      even on other platforms. It might be useful to add a\n      net::TestClientCerts class mirroring net::TestRootCerts, which\n      would allow a unit test to register temporary\n      (certificate,private_key) pairs to be at test time.\n\n      Also, what is the best way to store client certificate request\n      data in files that can be loaded during unit-tests (or shall\n      we just hard-code these in the tests instead?).\n\nIV: Questions:\n--------------\n\n  Some of the SSL configuration / parameters can be cached at various\n  levels. This may introduce changes in the proposal above. Your expert\n  opinion on the topic is welcome.\n\n  Any problem to foresee to make the ClientCertStore::GetCompatibleCerts()\n  API asynchronous? The proposal above assumes this can be fixed without\n  impacting this work, but this may be wrong.\n\n  For unit testing, shall we hard-code the certificate request parameters\n  to be tested in the tests themselves, or is there a PKCS file format\n  that could be used to store them with the rest of the test certificate\n  data?', '']",1
"['Issue 174237: Make the whole Drive system work with Drive API under a flag', 'So far, hidehiko@ implemented most of the operations on top of Drive API. We should start integration so the whole Drive system work with Drive API.', '']",1
"['Issue 231005: Taller omnibox and asset change', ""We're currently working on a taller omnibox experimentation for Chrome (Win and Cros for now).\nTo keep the asset consistency between windows and Cros, we had to create a totally new set of assets for the omnibox. \n\nIt will now be cut in 2 groups of 9-box assets. One group being the border, the only one windows will use, and the other one being the filling that will be used in Chrome OS.\n\nCut preview + assets for 100 and 200 attached to this thread."", '']",1
"['Issue 236255: GWT Animation broken with 26 on WinXP (ok on Win7)', 'UserAgent: Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.31 (KHTML, like Gecko) Chrome/26.0.1410.64 Safari/537.31\n\nSteps to reproduce the problem:\n1. Goto http://www.sencha.com/examples/#ExamplePlace:advancedtabs\n2. Click on the add tab button until tabs need to scroll to show new tabs\n3. Tabs scroll to the left, then right, then left etc (i.e. ""bounce"") for the duration of the animation\n\nWhat is the expected behavior?\nThe tabs should just scroll to the right.\n\nWhat went wrong?\nThe GWT (2.4) animate method should return a progress value between 0.0 and 1.0 that increases each time. Instead the value gets bigger and smaller causing the tabs to scroll left and right repetitively instead of just to the left once.\n\nThis appears to be very similar to ""Issue 158910: GWT Animations broke on 24/25"" but only affects Chrome on XP (SP3) and is still present in 26.0.1410.64. \n\nDid this work before? N/A \n\nChrome version: 26.0.1410.64  Channel: stable\nOS Version: 5.1 (Windows XP)\n\nI will try to upgrade to 2.5 or apply a different GWT binding as suggested in issue 158910.', '']",1
"['Issue 318509: RemoveSessionCookies called overzealously', ""We should call removeSessionCookies() once per application creation.  It's complicated by the fact that Main only calls the function when it is starting from a cold start (e.g. when Android kills it in the background).\n\nWhen multiple Activities are in play, e.g. WebappActivities, the code currently calls removeSessionCookies() once every time an Activity.onCreate() function is called.\n\nThis call should be moved up to ChromeMobileApplication, but we should clarify exactly when the cookies _should_ be deleted."", '']",1
"['Issue 331530: base::GetHomeDir() does the wrong thing on Chrome OS', ""As mentioned in 331529, it seems that this call is hard-coded to return /home/chronos/user on Chrome OS at all times. In a multiprofile world, this makes no sense -- in fact, since /home/chronos/user has long been deprecated, it's definitely the case that this path should no longer be used at all. It should probably return the appropriate home directory for the profile that's currently active? The callsites should be audited to figure out what the code there actually wants...is it trying to find a stable per-install storage location? Per-user?"", '']",1
"['Issue 371185: FAFT rework', 'FAFT consists of 2 main parts, a library of helper functions and a framework which governs how tests must be written.\n\nWe have made significant changes to FAFT to improve stability and maintainability. This included organizing its classes/modules/packages and rewriting a number of subsystems like device config.\n\nWe are now opening it up to development, partner eng and external partner teams.\n\nThe framework component has been helpful, but gathered complexity over the years, and adds a layer of friction for anyone wanting to contribute tests. \n\nDevelopers are reluctant to debug or add tests because of the learning curve necessary to write the simplest firmware test. Given our limited resources and future scaling needs I believe the time has come to pay the debt and remove the test framework complexity. This will enable developers to more easily contribute and fix tests.\n\nIt will also make it easier to maintain and debug FAFT functionality and tests. While coverting firmware_ECWriteProtect, it uncovered a possible bug  in the test (https://code.google.com/p/chrome-os-partner/issues/detail?id=28105). The tests would also benefit from a second look as they are being migrated to the new system.\n\nA more detailed plan is laid out in: https://docs.google.com/a/google.com/document/d/165l6qiE6tY7p9ph_QRDHmo_acg7aMBqiNyHnad1otZY/edit#', '']",1
"['Issue 398361: webRTC communication and Camera loopback broken', 'Steps to reproduce the problem:\n1. Visit https://apprtc.appspot.com/ or https://talky.io or https://airwave.io with 2 users\n2. Allow camera\n3. See what happens\n\nWhat is the expected behavior?\nSmooth camera loopback, smooth remote stream.\n\nWhat went wrong?\nOn the galaxy S4 the remote stream show up black. Sound works but no video.\nOn the Z2 tablet, the video loopback is jerky and misses frames. the remote stream which is generated is also jerky and misses frames\n\nDid this work before? Yes In the previous version before chrome M36\n\nChrome version: 36.0.1985.125  Channel: stable\nOS Version: 6.3\nFlash Version: \n\nPlease make this a high priority issue as chrome and chrome beta are now unusable for in-browser webRTC video communication', '']",1
"['Issue 437277: Push notification grace/user-visible requirements', 'This bug is to track the implementation of forcing a notification if the site has requested user-visible-only push but doesn\'t show a notification (subject to a small grace).\n\nBackground: We will allow developers to commit to causing a user-visible change (essentially a notification right now) when they receive a push message. If they commit to this we will show a less scary permission request than we would for full push. They will still be allowed to infrequently deliver a push that doesn\'t cause a notification to allow for known cases where enforcing the requirement would be bad for the user (e.g. device lost internet connection after receiving the push so it can\'t download resources required in the notification).\n\nI\'ve tried to capture this intention precisely as follows (note variable names are illustrative, not actual suggestions for variable names): \n\n- For each origin record totalPushMessages, the total number of push messages ever received by the origin, and totalPushMessagesWithNotification, the total number of push messages ever received by the site that either triggered a notification or occurred while the site was in focus.\n- Each time a worker is finished receiving a push message and totalPushMessages and totalPushMessagesWithNotification have been updated:\n  - Calculate ratio = totalPushMessagesWithNotification/totalPushMessages. If ratio < 0.9 and totalPushMessages > 2 then:\n     - Show a notification (with the same actions and origin info as we would show on any notification sent from the site) saying ""%AppName has updates for you.""\n\ntotalPushMessages and totalPushMessagesWithNotification should be reset to 0 if the user clears their data for the site. We could also reset these if the user revokes or regrants the permission but I don\'t think it\'s important.\n\nI think that captures the specific detail, let me know if there are any open questions remaining.', '']",1
"['Issue 474718: Long-lived connection messaging Port object not properly disposed on disconnect', ""UserAgent: Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/44.0.2358.0 Safari/537.36\n\nSteps to reproduce the problem:\n1. unzip sender.zip and load as extension\n2. unzip listener.zip, update the extension ID parameter in the connect function to match the ID of the sender extension and load as extension\n\nWhat is the expected behavior?\nThe sender extension's used heap should return to baseline\n\nWhat went wrong?\ninspect background page's timeline tab of the sender extension, note the that the used heap never returns to base line\n\nthis is detailed in the attached memory leaking chrome messaging.pdf on pages 1-3\n\nWebStore page: \n\nDid this work before? N/A \n\nChrome version: 44.0.2358.0  Channel: n/a\nOS Version: 6.3\nFlash Version: Shockwave Flash 17.0 r0\n\nWhen the sender extension starts, it sends a message to the listener extension. When the listener extension receives a message, it posts a message back and disconnects. When the sender extension onDisconnect listener receives the event, it reconnects a new port and sends another message, restarting the process.\n\nIf the listener extension's Port object is never disconnected and messages are simply sent from the sender extension to the listener extension, the sender extension's used heap does return to baseline. See pages 4 & 5 in the attached memory leaking chrome messaging.pdf\n\nThis issue could be related to https://code.google.com/p/chromium/issues/detail?id=320723"", '']",1
"['Issue 538142: Commit KASAN patches to Chromium OS 3.14 kernel', 'We need to land the KASan patches to third_party/kernel/v3.14 to ease the building and testing process.', '']",1
"['Issue 6961: Support app menu/close on single-/double-click of upper left corner', 'Chrome Version       : 2.0.158.0\nOS                   : Windows Server 2008 (x64) == same as Vista x64.\n                       Not tested but assumed to also happen on XP.\nURLs (if applicable) :\nOther browsers tested:\nAdd OK or FAIL after other browsers where you have tested this issue:\n     Safari 3: ? untested\n    Firefox 3: OK\n         IE 7: OK\n\nWhat steps will reproduce the problem?\nDouble clicking the top left of a window in a Windows environment closes \nthe window. Most programs do this through their icon, however, applications \nsuch as Explorer, which do not have an icon, still support closing when the \ntop left of the ""frame"" is double clicked.\n\nWhat is the expected result?\nThe window should close when the top left is double clicked (in normal mode \nand maximised mode)\n\nWhat happens instead?\nChrome maximizes the window if it is in normal mode when the top left is \ndouble clicked. In maximized mode, nothing happens.\n\nTo fit in better with the windows environment, Chrome should follow the \nnormal window rules such as closing when the top left of the window (on the \nframe) is double clicked.', '']",1
"['Issue 31262: window.onunload fires at wrong time for popups', ""There is currently no way to figure out when the browser action popup was \nclosed as window.unonload is immediately triggered when the popup finished \nloading, not when it's closed. This may actually be a bug."", '']",1
"['Issue 37246: ffmpeg fails to build with -fPIC on ia32', ""I am building with the following Gyp options on ia32:\n  -Dlibrary=shared_library\n  -Dlinux_fpic=1\n\nI'm using -Dlibrary=shared_library to get faster builds.  On ia32 this does not imply -fPIC by \ndefault, but -fPIC is normal practice to avoid TEXTRELs and hence allow libraries to share memory, so \nI'm adding -Dlinux_fpic=1.\n\nI get the following build error as a result:\n\nthird_party/ffmpeg/source/patched-ffmpeg-mt/libavcodec/x86/h264dsp_mmx.c: In function \nput_h264_qpel4_h_lowpass_3dnow:\nthird_party/ffmpeg/source/patched-ffmpeg-mt/libavcodec/x86/h264dsp_mmx.c:2079: error: can't find a \nregister in class GENERAL_REGS while reloading asm\nthird_party/ffmpeg/source/patched-ffmpeg-mt/libavcodec/x86/h264dsp_mmx.c:2079: error: asm operand \nhas impossible constraints"", '']",1
"['Issue 47327: Allow extensions/apps to sync their own settings', ""ENVIRONMENT\nGoogle Chrome 6.0.445.0 (Official Build 50456) dev\nWebKit 534.1\nV8 2.2.18\nUser Agent Mozilla/5.0 (X11; U; Linux x86_64; en-US) AppleWebKit/534.1 (KHTML, like Gecko) Chrome/6.0.445.0 Safari/534.1\nCommand Line  /opt/google/chrome/google-chrome\n\nREPRO STEPS\n0. Two machines A and B, with the latest Chrome build installed, both \nclients online and connected to sync server with the same account;\n1. On client A: Navigate to Wrench -> Extensions; \n2. A: install a random extension that is known to have extension specific options (e.g. Google Translate);\n3. A: Click on 'Options' and customize;\n4. B: Navigate to Wrench -> Extensions and click on 'Options' for the extension from step 2.\n\nACTUAL RESULTS\nExtension is synced properly, however the Options are not.\n\nEXPECTED RESULTS\nExpected that all extension related options will be synced as well. \n\nADDITIONAL INFORMATION\n'Allow in incongito' is synced."", '']",1
"[""Issue 131023: strings are garbled in flash animations using 'the legacy' way of character represenation"", ""Moved from chromium-os:2804 ( http://crosbug.com/2804 ) \n\nHow to reproduce:\n\n1. Change the UI language to Korean (on ChromeOS)\n2. Go to http://openimage.interpark.com/_nip/flash/nwel/spotlight/ticket_spot3.swf?xml_url=http://ticket.interpark.com/Community/WelcomeSpot/WelcomeSpot.xml\n\nWhat's expected:\n\nKorean characters are shown in the flash animation\n\nActual: Garbled (non-sense) sequences of Latin letters are shown\n\nAdditional info: do the same on Windows/Mac/Linux with UI language of the OS set to Korean and you don't have this problem. \n\n\nThe issue here is that the flash animation does not use Unicode but uses a locale-specific legacy character encoding. They can get away with this because the majority of people visiting their site have their OS UI language set in such a way that the legacy character encoding used by Flash matches the default legacy encoding in that UI language. \n\nWhat we can do:\n\nWe can at least match the Windows behavior. Flash can assume the legacy \ncodepage/encoding corresponding to the current UI language of ChromeOS. \n\nKorean => windows-949\nJapanese => windows-936\nSimp Chinese => windows-932\nTrad. Chinese => windows-950\nThai => Windows-874\nRussian => Windows-1251\nArabic => Windows-1256\nHebrew => Windows-1255 \n.....\n\n\n@brettw: I thought that you had implemented this, but I still this problem in M20. \n\n\nSee http://crosbug.com/2804 for more details."", '']",1
"[""Issue 139019: Expired certificates don't trigger an authority error with NSS"", ""Below is a certificate that's obviously very expired (and its private key if you want to play.) (Sorry about the MD5, I was experimenting and it's not important here.)\n\nIf you present this to Chrome Linux for https://www.facebook.com it says that the certificate has expired, *not* that it's an invalid authority. If you present it for https://facebook.com, you get a name mismatch *not* an authority error.\n\nThe certificate must have expired for this to occur. Otherwise you get the authority error as expected.\n\nI'll take a look at this, but it's towards the end of the day and I wanted to file this so that I don't forget.\n\nCertificate:\n    Data:\n        Version: 3 (0x2)\n        Serial Number: 1 (0x1)\n        Signature Algorithm: md5WithRSAEncryption\n        Issuer: CN=www.facebook.com\n        Validity\n            Not Before: Jan  1 00:16:40 1970\n            Not After : Jan  2 03:46:40 1970\n        Subject: CN=www.facebook.com\n        Subject Public Key Info:\n            Public Key Algorithm: rsaEncryption\n            RSA Public Key: (1024 bit)\n                Modulus (1024 bit):\n                    00:ad:78:81:0a:28:6a:06:28:c2:2a:1e:09:de:fa:\n                    72:08:b7:d3:48:84:4c:d0:ab:b2:f7:bc:d8:ca:e3:\n                    a5:04:0a:e3:53:0c:a3:fa:31:5e:87:36:96:48:7b:\n                    01:38:65:ce:38:1d:74:31:bf:9e:ca:5f:c2:0d:0e:\n                    08:99:55:70:4e:ce:b6:9c:e4:b1:1b:92:29:1f:04:\n                    b1:79:c4:a9:54:9e:17:0a:29:94:d3:40:52:48:41:\n                    3a:ef:dc:f5:4f:a4:66:0c:26:80:e3:c6:70:bd:d2:\n                    4f:39:22:d5:f6:00:b0:cf:7e:a4:f9:af:40:7c:c6:\n                    3a:97:f9:39:70:e1:c6:a6:6b\n                Exponent: 65537 (0x10001)\n        X509v3 extensions:\n            X509v3 Key Usage: critical\n                Key Encipherment, Certificate Sign\n            X509v3 Basic Constraints: critical\n                CA:FALSE\n    Signature Algorithm: md5WithRSAEncryption\n        9a:19:88:b6:2d:1a:3f:1d:8e:9e:d7:e9:83:5d:da:0c:b9:7f:\n        2f:f6:9f:e2:29:a5:9a:d2:6f:7d:85:d4:9c:c5:cf:4b:52:36:\n        8a:98:c3:1b:23:55:94:a4:65:cf:28:f6:3f:29:91:5b:e0:95:\n        5e:e0:08:1e:75:84:cd:90:30:3f:56:a8:e0:64:dd:dd:9b:86:\n        ef:cf:4f:25:dd:20:79:f8:23:11:74:38:c5:49:a5:17:d9:1a:\n        0c:35:29:53:70:e8:9d:31:60:cc:2f:ea:79:48:60:5d:4e:9b:\n        5a:1b:3c:66:65:fe:73:9b:9d:82:ff:7b:f5:ec:9c:65:43:7b:\n        fb:ca\n-----BEGIN CERTIFICATE-----\nMIIBzjCCATmgAwIBAgIBATALBgkqhkiG9w0BAQQwGzEZMBcGA1UEAxMQd3d3LmZh\nY2Vib29rLmNvbTAmFxE3MDAxMDEwMDE2NDAtMDUwMBcRNzAwMTAyMDM0NjQwLTA1\nMDAwGzEZMBcGA1UEAxMQd3d3LmZhY2Vib29rLmNvbTCBnTALBgkqhkiG9w0BAQED\ngY0AMIGJAoGBAK14gQooagYowioeCd76cgi300iETNCrsve82MrjpQQK41MMo/ox\nXoc2lkh7AThlzjgddDG/nspfwg0OCJlVcE7OtpzksRuSKR8EsXnEqVSeFwoplNNA\nUkhBOu/c9U+kZgwmgOPGcL3STzki1fYAsM9+pPmvQHzGOpf5OXDhxqZrAgMBAAGj\nIDAeMA4GA1UdDwEB/wQEAwIAJDAMBgNVHRMBAf8EAjAAMAsGCSqGSIb3DQEBBAOB\ngQCaGYi2LRo/HY6e1+mDXdoMuX8v9p/iKaWa0m99hdScxc9LUjaKmMMbI1WUpGXP\nKPY/KZFb4JVe4AgedYTNkDA/VqjgZN3dm4bvz08l3SB5+CMRdDjFSaUX2RoMNSlT\ncOidMWDML+p5SGBdTptaGzxmZf5zm52C/3v17JxlQ3v7yg==\n-----END CERTIFICATE-----\n\n-----BEGIN RSA PRIVATE KEY-----\nMIICXQIBAAKBgQCteIEKKGoGKMIqHgne+nIIt9NIhEzQq7L3vNjK46UECuNTDKP6\nMV6HNpZIewE4Zc44HXQxv57KX8INDgiZVXBOzrac5LEbkikfBLF5xKlUnhcKKZTT\nQFJIQTrv3PVPpGYMJoDjxnC90k85ItX2ALDPfqT5r0B8xjqX+Tlw4camawIDAQAB\nAoGAb3riyqlgQacN6M03IMIoaKviL1c+mlfNguItHG4hjTCGGMgl1VLG4fRVrizG\ngv0CAxQCqTnxDTNu3L7pDclXi26Qz2hdNchLxLvjNMYEA7Km0nIhHDe5tlUd+EgZ\n6W4vINLVjN4h8yZ64rmOwpasutiQZ1sJ4NtWgPpzwopVXJkCQQDHks3Y5K7zY5jP\n1FQEK3ZqhhnvA5o5EVrxyr0FVDsofp7u2zDtr+2QBNcXzEmFOWvF4/+k4BWbKfaH\niRqoX5WFAkEA3oRf/o/zSb6xKfpcoz6A3XCCkgMx6WERl750UT+1WhMo9U5tmTYw\noLwsd1s4K9g+gi5nqonbkQOiIAjRmeJXLwJBAIoN5HWQI/HbyL6ju4ay5hRkNZZg\nYJPvjIDMZRtFnDKz/I9wcxVI6MYCgyREPet5wDLBOHu+Q1P1oEM7tYQZst0CQQDK\nqjJsPlvNrNrbauX44LKp/RFPP420C+7kEFkMr0PTeGPzmK0FwG9l1j2BsBlnBZtZ\nIj7U+p56Y57EIoQU7iuNAkBdtnttnLyBn3rlAnP5IXR5K6HYH88IVHJQUlMziSS0\n54/9vaKGI2KF81IeAnTDdnn1SEy2D1o9E9gP5LcfG6ZN\n-----END RSA PRIVATE KEY-----"", '']",1
"['Issue 153568: Bad UX in apps if user has non-default zoom level in Chrome', 'What steps will reproduce the problem?\n1. Set the default page zoom to 200%\n2. Open an ""apps v2"" demo app\n3. Try to interact with the app\n\nWhat is the expected output?\nI expect that either it ignores page zoom, or it zooms the whole app container, or it lets me scroll. Ideally there\'d be a way to control the zoom.\n\nWhat do you see instead?\nThe content is zoomed, but the container remains small, so some of the content is outside the window.\n\nNote that there are some users who have their default page zoom to set to something other than 100%. As a quick solution, maybe ignore page zoom. Better would be to actually resize the app container and/or provide a way to change the zoom level.', '']",1
"[""Issue 205636: The recovery kernel shouldn't fiddle with stateful_partition/.developer_mode"", 'Chrome OS Version  :  N/A\nChrome Version     :  N/A\nType of computer   :  any\nNetwork info       :  any\n\nWhat steps will reproduce the problem?\n1.  Read the code in src/platform/initramfs/recovery_init.sh\n\nWhat is the expected output?\nThe code should have minimal expectations regarding\nthe layout of partitions and file systems on the installation\ntarget device.  Dependencies on the behavior of the installed\nsoftware should also be restricted.\n\nWhat do you see instead?\nThe code has an awkward dependency on the contents\nof the file system as installed, and also on expectations\nregarding the behavior of the installed software:\n\n  touch_developer_mode_file() {\n    is_developer_mode || return 1\n    mount -n -o rw -t ext3 ""$DST_DEV_BASE""1 ""$STATEFUL_MNT"" || return 1\n    touch ""$STATEFUL_MNT/.developer_mode"" || return 1\n    umount ""$STATEFUL_MNT"" || return 1\n    return 0\n  }\n\nThe code is invoked to prevent the installed software from wiping the stateful\npartition immediately after recovery on a system in developer mode.  That\nbehavior is highly desirably (arguably mandatory), however, putting the code\nhere means that the recovery kernel is assuming that the software just installed\nwas some version of Chrome OS *and* it assumes that a file named\n"".developer_mode"" will cause that version of Chrome OS to behave specially.\n\nNeither of those assumptions ought to be considered sacred:  The software\nbeing installed should be able make up its own mind regarding whether these\nassumptions are or should be true.\n\nHow frequently does this problem reproduce? (Always, sometimes, hard to\nreproduce?)\nAlways.\n\nWhat is the impact to the user, and is there a workaround? If so, what is\nit?\nUsers who want to install a custom OS with a custom disk layout will discover\nthat the recovery kernel populates their installation with a useless turd.\n\nChrome OS can\'t change in a way that it fails to honor the .developer_mode\nflag file.  The file can\'t even be renamed without changing the recovery\nkernel.\n\nAs it happens, the recovery installer is now able to distinguish recovery\nfrom other install use cases:  Recovery is invoked as\n/usr/sbin/chromeos-recovery.  That means it\'s possible for\nchromeos-install to know that the installation is for recovery, and\nhandle developer mode installations on its own.  The function of\n""touch_developer_mode_file"" can safely be moved to chromeos-install.', '']",1
"['Issue 209321: Integrate memtest into chromeos build system', 'It is needed for HW debugging/diags/troubleshooting', '']",1
"['Issue 214886: Roll laptop-mode-tools into power_manager', 'I have discussed with olofj and arscott about simplifying our power management infrastructure. Specifically what was envisioned was having a script for for each power transitions (init, battery->AC, AC->battery, low battery, etc) that the system can go through, which contains all of the functionality we used laptop-mode for. powerd calls the scripts at the appropriate times, since it already knows about the various power mode transitions. This would allow us to remove the laptop-mode-tools package and have more of the power behaviour localized to the power_manager package.', '']",1
"['Issue 227454: Implement DOM3 wheel event', ""UserAgent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_8_3) AppleWebKit/537.31 (KHTML, like Gecko) Chrome/26.0.1410.43 Safari/537.31\n\nSteps to reproduce the problem:\nBoth Firefox and IE>=9 support the standardized DOM3 `wheel` event. WebKit (and now Blink) are the inly significant engines that haven't adopted it yet, forcing web developers to use polyfills utilizing the non-standard `mousewheel` event.\n\nThe problem is, the `wheel` event has different semantics from `mousewheel`, it supports various `deltaMode`s which influence its `deltaX`, `deltaY` and `deltaZ` fields. `mousewheel` has `wheelDelta`, `wheelDeltaX` & `wheelDeltaY`.\n\nThis issue was originally reported to WebKit: https://bugs.webkit.org/show_bug.cgi?id=94081\n\nWhat is the expected behavior?\n\nWhat went wrong?\nThe `wheel` event is not supported.\n\nDid this work before? No \n\nChrome version: 28.0.1468.0  Channel: canary\nOS Version: OS X 10.8.3"", '']",1
"['Issue 234422: Replace MemoryImplementation with something using < 1.2MB of binary size', ""Replace MemoryImplementation with something using < 1.2MB of binary size\n\nwebkit.org claims to have reduced binary size by 1.2MB by removing MemoryImplementation.  Obviously we don't want to do that.  But that seems like too high a price to pay for this feature.  We need to investigate how much this is costing us, and if it's really 1.2MB find ways to make it smaller.\n\nhttp://trac.webkit.org/changeset/148921"", '']",1
"[""Issue 281523: Clipboard 'copy' event is suppressed if a hidden password field previously had the input focus."", 'This bug is the underlying cause of the Chromoting clipboard-handling issue 266514, but I\'ve constructed a simplified test-case that does not involve Chromoting at all.\n\nWhat steps will reproduce the problem?\n1. Unpack the attached file and load it as an unpacked Chrome extension.\n2. There should be a textbox and a ""Copy to clipboard"" button. Type something into the textbox, then press the button.\n3. Wait two seconds, then look at the JS console log.\n\nWhat is the expected output? What do you see instead?\nShould see ""*** PASS! ***\' in the log. If you comment out the indicated line that hides the textbox, the test performs as expected.\n\nPlease use labels and text to provide additional information.\nWhen ""document.execCommand(\'copy\')"" is run, Blink should generate a clipboard \'copy\' event on the window object. When you handle this event, you get a clipboard event passed to you, which lets you set the clipboard contents.\n\nIf a password field currently has the input focus, Blink will refuse to generate the \'copy\' event. That seems reasonable to avoid accidentally leaking a password to the clipboard.\n\nIf you shift the focus away from the password field before running ""document.execCommand(\'copy\')"", then Blink generates the \'copy\' event as you\'d expect, since the password field is no longer active.\n\nBut if you hide the password field before shifting focus away from it, Blink fails to generate the \'copy\' event. This is the bug - the password field no longer has the focus, but Blink wrongly believes it is somehow ""active"" and refuses to generate the \'copy\' event.', '']",1
"['Issue 327172: Add a way to watch for all D-Bus connection changes', 'powerd currently watches for all NameOwnerChanged D-Bus signals from org.freedesktop.DBus. Other clients can register ""suspend delays"" to give them a chance to do last-minute work before the system suspends. If a client exits without deregistering itself, powerd is still able to remove the client\'s suspend delay after it sees a NameOwnerChanged signal about the client\'s connection name becoming unowned.\n\nI\'m having a difficult time finding a way to do this with Chrome\'s D-Bus bindings, which I\'m trying to switch powerd to for issue 320340.\n\nI don\'t think I can create an ObjectProxy for each client that registers a suspend delay and then use ObjectProxy::SetNameOwnerChangedCallback(), since its constructor requires both a service name and path.\n\nI tried making powerd create a proxy for org.freedesktop.DBus and listen for NameOwnerChanged signals directly. This gets me all of the signals, but I think that it breaks ObjectProxy, since the org.freedesktop.DBus proxy\'s HandleMessage() method can return DBUS_HANDLER_RESULT_HANDLED before the actual client\'s proxy HandleNameOwnerChanged() method runs and gets a chance to update its |service_name_owner_| field.', '']",1
"['Issue 350197: Runtime video codec feature discovery', 'Currently we use a static GetSupportedProfiles() for each VEA impl to get a vector of profiles they support. Those lists are hardcoded for now.\n\nWe should be detecting this dynamically in runtime instead. This would also allow us to get rid of --enable-webrtc-hw-vp8-encoding flag for example.', '']",1
"['Issue 361528: Breakage in semantics/implementation of UserManager::GetProfileByUser.', 'Hi,\n\n(I\'ve cc\'ed everyone who I could see to touch this code.)\n\nAs far as I can understand, there\'s some breakage in/around UserManager::GetProfileByUser().\n\n1.  Please take a look at (copied below):\n\nhttps://code.google.com/p/chromium/codesearch#chromium/src/chrome/browser/chromeos/login/user_manager_impl.cc&q=getprofilebyuser&sq=package:chromium&type=cs&l=710\n\n  if (IsMultipleProfilesAllowed() && user->is_profile_created())\n    profile = ProfileHelper::GetProfileByUserIdHash(user->username_hash());\n  else\n    profile = ProfileManager::GetActiveUserProfile();\n\nThe ""&& user->is_profile_created()"" seems to be out of place.  Whether the Profile is obtained through GetProfileByUserIdHash() or through GetActiveUserProfile() should not depend on is_profile_created(), right?  Otherwise, it is possible for the wrong profile to be returned when requesting the profile of a non-active user in multi-profile-mode.\n\n2.  I\'ve tried to fix this by changing to:\n\n  if (!user->is_profile_created())\n    return NULL;\n\n  if (IsMultipleProfilesAllowed())\n    profile = ProfileHelper::GetProfileByUserIdHash(user->username_hash());\n  else\n    profile = ProfileManager::GetActiveUserProfile();\n\nHowever this leads to crashes, probably because callers don\'t expect GetProfileByUser() to return NULL.  It seems that the semantics ""Returns NULL if profile for user is not found or is not fully loaded."" is not properly supported in all call sites.\n\nCould you please provide some input on how to proceed?  I\'d assume that we rather fix the call sites than changing the semantics (not permit GetProfileByUser() to return NULL)?  Or have I missed something and all of this works as intended?\n\nThank you!\nThiemo', '']",1
"['Issue 377301: Rewrite session_manager_setup.sh in C++ and make it usable outside Chrome OS', '/sbin/session_manager_setup.sh is a large shell script installed by the chromeos-login package. It\'s executed by the ""ui"" Upstart job to start the X server, export some environment variables, and construct and execute a command to start session_manager. That command includes all of the arguments that session_manager should use when running Chrome.\n\nSome of the arguments passed to Chrome are applicable to other Chromium-derived binaries, such as app_shell and content_shell (for example, compositing-related flags). Others are specific to Chrome. Starting the X server is also applicable to app_shell.\n\nI started splitting out a shell library that could be used by non-Chrome-OS builds (https://chromium-review.googlesource.com/#/c/200776/), but the argument has been put forth that session_manager_setup.sh is pretty unmaintainable in its present form. I agree -- the script doesn\'t have any tests and it\'s not too far-fetched to imagine future changes (or my refactoring of it) accidentally breaking it. The Bourne-shell-based approach is also ugly because some Chrome arguments contain spaces, requiring tricky and potentially dangerous quote-and-eval magic.\n\nI\'ve started working on a rewrite in C++. Right now, this is taking the form of a ChromiumCommandBuilder class that knows about shared environment variables and flags and provides methods that a caller can use to add additional variables and flags before calling methods that return the resulting command line.\n\nOne downside of the C++ approach is that it\'d be tougher to make changes to development devices -- instead of being able to edit the script directly, one would need to emerge and push the chromeos-login package. Mike suggested making the C++ implementation also use developer-supplied arguments from a text file located on the read-only partition. (Note that that won\'t help when modifying already-set flags, though.)\n\nThe current implementation is also dependent on being able to source .info files describing Pepper plugins, but I\'m working on cleaning those up so they\'ll be parseable from C++.\n\nChris, what are your thoughts about how the C++ implementation should tie in with session_manager? I think that we probably wouldn\'t want to make session_manager use ChromiumCommandBuilder directly; right now, session_manager_setup.sh starts the X server asynchronously and then does the work to construct the session_manager command line (which requires disk access). Does creating a new ""run_session_manager"" binary that links against ChromiumCommandBuilder and starts X in the background seem like a reasonable approach?\n\nI\'m also looking for suggestions for where this code should live -- it needs to be accessible to both Chrome OS and e.g. app_shell overlays, which rules out the chromeos-login package. ChromiumCommandBuilder could live in (ugh) libchromeos, but note that there\'s other related code that\'s also needed, like the xstart.sh script and the cros-xauth helper. Both of those things could probably also become part of ChromiumCommandBulder, though (in which case it should maybe be renamed to something like ChromiumRunner).', '']",1
"['Issue 425229: MacViews: Get views based chrome browser building and running on the Mac', 'Incrementally port more code in chrome/browser/ui/views to build on the Mac with toolkit_views=1 use_aura=0.', '']",1
"['Issue 433554: SQLitePersistentCookieStore causes CPU and disk contention during startup.', ""The first time that the SQLitePersistentCookieStore is created, it reads the entire persistent DB, one domain at a time. On my personal profile, it accesses the DB 1517 times on a thread that isn't the FILE thread, using 163ms of CPU time."", '']",1
"['Issue 467677: Unable to use new chrome.sockets.tcp.secure API due to setPause not taking immediate effect', ""UserAgent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.125 Safari/537.36\n\nSteps to reproduce the problem:\nI am trying to use the new chrome.sockets.tcp.secure API, added in https://chromiumcodereview.appspot.com/76403004/ (currently on Canary v38) to upgrade an existing socket to a secure TLS connection.  However the new secure API is failing with error code -4 (ERR_INVALID_ARGUMENT) due to the socket currently reading data.\n\nTo replicate, try this JavaScript:\nchrome.sockets.tcp.create({}, function (createInfo) {\n  var socketId = createInfo.socketId;\n  chrome.sockets.tcp.connect(socketId, 'www.google.com', 443, function (connectResult) {\n    if (connectResult !== 0) {\n      return;\n    }\n    chrome.sockets.tcp.setPaused(socketId, true, function(pauseResult) {\n      chrome.sockets.tcp.secure(socketId, {}, function(secureResult) {\n      });\n    });\n  });\n});\n\nWhat is the expected behavior?\n.secure should successfully change the socket to a TLS connection\n\nWhat went wrong?\nMy understanding of this problem is that when we call .secure, there is currently an outstanding read call (similar to the old chrome.socket.read API), and we are unable to successfully call .secure before this .read call completes.  Even though I am calling chrome.sockets.tcp.setPaused(..., true, ...), it appears that this call doesn't actually stop a read that's in progress, but rather waits for the current read to complete and then no longer calls read again (also described in https://code.google.com/p/chromium/issues/detail?id=360026).  I have made some test projects where I can verify that if I call setPause on an insecure socket, then wait for data to be read on that socket (onReceive is still fired even though setPause was called), then call secure, the call to secure succeeds.  However in some cases we need to upgrade a socket to be secure right away and may not be able to wait for incoming data.\n\nDid this work before? N/A \n\nChrome version: 38.0.2093.0  Channel: canary\nOS Version: \nFlash Version: Shockwave Flash 14.0 r0"", '']",1
"['Issue 486917: Remove image scaling from remoting::VideoDecoder implementations.', ""Currently remoting::VideoDecoder implementations must be able to scale images they generate.\n\nCurrently CRD client can render using the 3 following methods:\n1. PepperVideoRender3D: video is decoded, scaled and rendered using Pepper APIs (the actual operation partly happens on GPU, depending on HW configuration). VideoDecoder is not used in this case.\n2. PepperVideoRender2D, which uses SoftwareVideoRenderer internally: video is decoded and scaled in software. This is necessary only for systems that don't support Graphics3D interface.\n3. SoftwareVideoRenderer on Android and iOS: the image is returned by the decoder 1:1 and then OS-specific rendering code scales and renders it on the screen.\n\nSo (2) is the only case when scaling is useful in remoting::VideoDecoder, and that's a corner case, so it's not critical for performance. Also it's not clear how much performance benefit video scaling in VideoDecoder provides - it might be that letting Chrome scale the image in (2) would result in better overall performance. Removing video scaling logic from remoting::VideoDecoder would  simplify implementations."", '']",1
"[""Issue 100380: [Extensions] Should launch container add a 'popup' type?"", ""Launch container currently supports two types: 'tab' and 'panel'. Most apps using type 'panel' appear to do so for the primary reason of opening in a smaller window than the browser window. The apps are not actually requesting panel features, such as always on top or automatic window management of panels (e.g. along bottom edge of screen). These apps are not designed with the smaller panel window in mind and cover up too much of the screen when opened always on top.\n\nThe addition of a 'popup' launch container type would address this problem, allowing extension app developers to ask for a smaller window without all the other Panel features, providing an added distinction of the desired UI for apps."", '']",1
"['Issue 100545: History page should support search exact match on full domain or URL', ""Currently, the search feature on chrome://history only searches the text content of pages, and the not the domain and URL. This is a limitation of the history backend.\n\nWe should add the ability to search the URL, and add the ability to search for a specific domain using syntax like 'site:google.com' in the history search box."", '']",1
"['Issue 100613: Icons in bookmark manager are inconsistent on TOUCH_UI', 'Goto on TOUCH_UI\n\nWrench Menu > Bookmark Manager\nNotice that the bookmark for about:settings is much larger than that for google.com.', '']",1
"['Issue 100703: shadowBlur is applied incorrectly to transparent images', ""Chrome Version       : 15.0.874.92\nOS Version: 6.1 (Windows 7, Windows Server 2008 R2)\n\nOther browsers tested:\n    Safari 5: OK\n    Firefox 7.0.1: OK\n    IE 9: OK\n    Opera 11.51: OK\n    OSX - Chrome 14.0.835.202: OK\n\nWhat steps will reproduce the problem?\n1. Set shadowBlur 10\n2. Draw a transparent png onto the canvas\n\nWhat is the expected result?\nThe edge of the image that are not transparent should have a drop shadow with a blur of 10\n\nWhat happens instead?\nThe bounding box of the image has a shadow with a blur of 10\n\nAdditional info:\nThis seems to only happen in windows and not on OSX.\nAttached is a screenshot of how it appears in Chrome compared to IE, Firefox, and Opera.\n\nI've also included a test case that demonstrates this issue."", '']",1
"['Issue 73062: Allow choice of sample-rate in AudioContext constructor', ""Currently the AudioContext has a fixed sample-rate which can't be chosen by the developer.  A new sample-rate constructor argument could be added to AudioContext."", '']",1
"['Issue 468375: WebRTC base should not depend on chromium base', ""Third party code (from chromium's point of view) should not depend directly on src\\base."", '']",1
"['Issue 323854: Disable multiprofile sessions that use ONC pushed certificates', ""1. if a profile uses ONC-pushed certificates then disallow adding more profiles to the session\n\n2. if a multiprofile session is ongoing then don't install ONC-pushed certificates for the session if the ONC policy updates mid-session, or if a 2nd/3rd/etc profile has certs in the ONC policy"", '']",1
"['Issue 312380: Replace the setuid sandbox with unprivileged namespaces.', 'The setuid sandbox has to go:\n\n- For each ""chroot me"" event, the current mechanism requires having previously started a setuid helper. This is not compatible with a more generic and universal Zygote. It is in conflict with the flexibility we want for Mojo.\n- chroot helpers are tied to new PID and network namespaces. Again, this conflicts with flexibility as network namespaces use a lot of kernel memory.\n- Shipping a setuid binary on Linux and on Chrome OS is bad for security.\n- Having to update a setuid executable on our bots when we want to make changes is problematic\n\nHopefully we can fix the following issues as well:\n- To be isolated from each other, renderers need to be marked as non dumpable. Since Breakpad needs to be able to ptrace() renderers, they become dumpable again on SIGSEGV.\nTo prevent a renderer from sending SIGSEGV to another renderer, we put in place an authentication mechanism which require a kernel fix (CVE-2011-1182). This fix has now regressed. Also see issue 169369.\n\nBoth seccomp-bpf and Yama can offer an alternate way to protect processes in the same PID namespace from each other.\n\n- Searching for the ""real pid"" of children under a new PID namespace is tremendously complicated and requires going through each process in /proc (which is itself much harder when the processes are not dumpable). We should investigate the cost of having one PID namespace per process as it would allow the parent to immediately know the real PID. It would also solve the ""dumpable"" issue neatly as processes wouldn\'t need to be non dumpable.\n\nPlans:\n\n- Use unprivileged namespaces (through CLONE_NEWUSER) when available. Hopefully this will be available by default with Ubuntu 14.04 LTS.\nI have made a proof-of-concept and it looks like it\'ll work.\nWith unprivileged namespaces processes could keep the CAP_SYS_CHROOT capability until the sandbox is fully engaged, which would solve a lot of the current issues.\n\n- Get CLONE_NEWUSER in Chrome OS with kernel 3.9+\n\n- Link Chromium against libcap2. If that\'s not possible, rewrite a small POSIX.1e library.\n\n- We may have to support the current setuid sandbox mechanism alongside the new mechanism until support for Ubuntu Precise is dropped. It\'s unfortunate as complexity is high.', '']",1
"['Issue 53193: HTMLMediaElement.canPlayType gives false positives in Chrome', 'When a codecs parameter is provided and recognized, and the MIME type is supported, canPlayType() always returns ""probably"". Even when the combination of the two makes little sense. Chrome should look at the combination of the two and only return ""probably"" when the combination is correct.\n\nFor example:\n\nv =document.createElement(\'video\');\nv.canPlayType(\'video/mp4\')\n-> maybe     // correct\n\nv=document.createElement(\'video\');\nv.canPlayType(\'video/mp4; codecs=""avc1.42E01E""\')\n-> probably     // correct\n\nv=document.createElement(\'video\');\nv.canPlayType(\'video/mp4; codecs=""theora""\')\n-> probably     // incorrect\n\nv=document.createElement(\'video\');\nv.canPlayType(\'video/ogg; codecs=""theora""\')\n-> probably     // correct\n\nv=document.createElement(\'video\');\nv.canPlayType(\'video/ogg; codecs=""avc1.42E01E""\')\n-> probably     // incorrect\n\nMore information:\nhttp://rakaz.nl/2010/06/problems-with-html5-video-codec-detection.html\nhttp://beta.html5test.com/testcases/video/', '']",1
"[""Issue 464171: Multiple canary's are failing due to kernel size limits"", 'Did a trybot change with no changes and the builder fails on the archive stage:\n\nhttp://chromegw.corp.google.com/i/chromiumos.tryserver/builders/beaglebone_servo-release/builds/18\n\n@@@STEP_FAILURE@@@\n16:38:26: ERROR: <class \'chromite.cbuildbot.failures_lib.BuildScriptFailure\'>: ./mod_image_for_recovery.sh failed (code=1)\nTraceback (most recent call last):\n  File ""/b/cbuild/internal_master/chromite/lib/parallel.py"", line 433, in _Run\n    self._task(*self._task_args, **self._task_kwargs)\n  File ""/b/cbuild/internal_master/chromite/cbuildbot/stages/artifact_stages.py"", line 318, in BuildAndArchiveAllImages\n    commands.BuildRecoveryImage(buildroot, board, image_dir, extra_env)\n  File ""/b/cbuild/internal_master/chromite/cbuildbot/commands.py"", line 1476, in BuildRecoveryImage\n    enter_chroot=True)\n  File ""/b/cbuild/internal_master/chromite/cbuildbot/commands.py"", line 117, in RunBuildScript\n    raise failures_lib.BuildScriptFailure(ex, cmd[0])\n  File ""/b/cbuild/internal_master/chromite/cbuildbot/commands.py"", line 117, in RunBuildScript\n    raise failures_lib.BuildScriptFailure(ex, cmd[0])\nBuildScriptFailure: ./mod_image_for_recovery.sh failed (code=1)\n\n\nAssigning to deputy.', '']",1
"['Issue 236206: Presubmit checking for Blink is very slow', ""depot_tools's presubmit check has an optimization where it only runs SCM operations on files that violate some style. Since blink style isn't chromium style, the style checker thinks that _every_ file violates something and runs SCM operations for every file. This is slow.\n\n\n\nI applied this patch to depot_tools (thanks to nick's suggestion), and it prints output for every file in a blink change:\n\ndepot_tools thakis$ svn diff\nIndex: presubmit_canned_checks.py\n===================================================================\n--- presubmit_canned_checks.py (revision 196798)\n+++ presubmit_canned_checks.py (working copy)\n@@ -257,6 +257,8 @@\n     if all(callable_rule(extension, line) for line in f.NewContents()):\n       continue  # No violation found in full text: can skip considering diff.\n \n+    print 'violation in', f.LocalPath()\n+\n     for line_num, line in f.ChangedContents():\n       if not callable_rule(extension, line):\n         errors.append(error_formatter(f.LocalPath(), line_num, line))\n\n\n\n\nWebKit thakis$ git cl upload -m rebase \nUsing 50% similarity for rename/copy detection. Override with --similarity.\n\nWARNING: Use -t or --title to set the title of the patchset.\nIn the near future, -m or --message will send a message instead.\nSee http://goo.gl/JGg0Z for details.\n\nLoaded authentication cookies from /Users/thakis/.codereview_upload_cookies\nRunning presubmit upload checks ...\nviolation in Source/WebKit/chromium/src/ChromeClientImpl.cpp\nviolation in Source/WebKit/chromium/src/ContextMenuClientImpl.cpp\nviolation in Source/WebKit/chromium/src/WebFrameImpl.cpp\nviolation in Source/WebKit/chromium/src/WebHelperPluginImpl.cpp\nviolation in Source/WebKit/chromium/src/WebPageSerializer.cpp\nviolation in Source/WebKit/chromium/src/WebPageSerializerImpl.cpp\nviolation in Source/WebKit/chromium/src/WebPluginContainerImpl.cpp\nviolation in Source/WebKit/chromium/src/WebSearchableFormData.cpp\nviolation in Source/WebKit/chromium/src/WebViewImpl.cpp\nviolation in Source/WebKit/chromium/src/mac/WebSubstringUtil.mm\nviolation in Source/core/accessibility/AXObjectCache.cpp\nviolation in Source/core/accessibility/AccessibilityImageMapLink.h\nviolation in Source/core/accessibility/AccessibilityListBox.cpp\nviolation in Source/core/accessibility/AccessibilityListBoxOption.cpp\nviolation in Source/core/accessibility/AccessibilityListBoxOption.h\nviolation in Source/core/accessibility/AccessibilityMenuListOption.cpp\nviolation in Source/core/accessibility/AccessibilityMenuListPopup.cpp\nviolation in Source/core/accessibility/AccessibilityProgressIndicator.cpp\nviolation in Source/core/accessibility/AccessibilityRenderObject.cpp\nviolation in Source/core/accessibility/AccessibilityScrollView.cpp\nviolation in Source/core/accessibility/AccessibilitySlider.cpp\nviolation in Source/core/accessibility/AccessibilityTable.cpp\nviolation in Source/core/css/CSSComputedStyleDeclaration.cpp\nviolation in Source/core/css/StyleResolver.cpp\nviolation in Source/core/dom/DOMImplementation.cpp\nviolation in Source/core/dom/Document.cpp\nviolation in Source/core/dom/Document.h\nviolation in Source/core/dom/DocumentStyleSheetCollection.cpp\nviolation in Source/core/dom/Element.cpp\nviolation in Source/core/dom/Element.h\nviolation in Source/core/dom/ElementRareData.h\nviolation in Source/core/dom/MouseEvent.cpp\nviolation in Source/core/dom/Node.cpp\nviolation in Source/core/dom/Range.cpp\nviolation in Source/core/dom/StyledElement.cpp\nviolation in Source/core/editing/ApplyBlockElementCommand.cpp\nviolation in Source/core/editing/ApplyStyleCommand.cpp\nviolation in Source/core/editing/ApplyStyleCommand.h\nviolation in Source/core/editing/BreakBlockquoteCommand.cpp\nviolation in Source/core/editing/CompositeEditCommand.cpp\nviolation in Source/core/editing/CreateLinkCommand.cpp\nviolation in Source/core/editing/DeleteSelectionCommand.cpp\nviolation in Source/core/editing/EditingStyle.cpp\nviolation in Source/core/editing/Editor.cpp\nviolation in Source/core/editing/EditorCommand.cpp\nviolation in Source/core/editing/FormatBlockCommand.cpp\nviolation in Source/core/editing/FrameSelection.cpp\nviolation in Source/core/editing/IndentOutdentCommand.cpp\nviolation in Source/core/editing/InsertLineBreakCommand.cpp\nviolation in Source/core/editing/InsertListCommand.cpp\nviolation in Source/core/editing/InsertParagraphSeparatorCommand.cpp\nviolation in Source/core/editing/ModifySelectionListLevel.cpp\nviolation in Source/core/editing/ReplaceNodeWithSpanCommand.cpp\nviolation in Source/core/editing/ReplaceSelectionCommand.cpp\nviolation in Source/core/editing/SpellChecker.cpp\nviolation in Source/core/editing/TextIterator.cpp\nviolation in Source/core/editing/UnlinkCommand.cpp\nviolation in Source/core/editing/VisiblePosition.cpp\nviolation in Source/core/editing/WrapContentsInDummySpanCommand.cpp\nviolation in Source/core/editing/htmlediting.cpp\nviolation in Source/core/editing/markup.cpp\nviolation in Source/core/html/BaseClickableWithKeyInputType.h\nviolation in Source/core/html/BaseMultipleFieldsDateAndTimeInputType.cpp\nviolation in Source/core/html/ColorInputType.cpp\nviolation in Source/core/html/FormAssociatedElement.cpp\nviolation in Source/core/html/HTMLAllCollection.cpp\nviolation in Source/core/html/HTMLAllCollection.h\nviolation in Source/core/html/HTMLAnchorElement.cpp\nviolation in Source/core/html/HTMLAnchorElement.h\nviolation in Source/core/html/HTMLAppletElement.h\nviolation in Source/core/html/HTMLAreaElement.cpp\nviolation in Source/core/html/HTMLAreaElement.h\nviolation in Source/core/html/HTMLBodyElement.cpp\nviolation in Source/core/html/HTMLBodyElement.h\nviolation in Source/core/html/HTMLButtonElement.h\nviolation in Source/core/html/HTMLCanvasElement.cpp\nviolation in Source/core/html/HTMLCanvasElement.h\nviolation in Source/core/html/HTMLCollection.cpp\nviolation in Source/core/html/HTMLDocument.cpp\nviolation in Source/core/html/HTMLElement.cpp\nviolation in Source/core/html/HTMLEmbedElement.cpp\nviolation in Source/core/html/HTMLFontElement.cpp\nviolation in Source/core/html/HTMLFontElement.h\nviolation in Source/core/html/HTMLFormControlElement.cpp\nviolation in Source/core/html/HTMLFormElement.cpp\nviolation in Source/core/html/HTMLFrameElement.cpp\nviolation in Source/core/html/HTMLFrameElement.h\nviolation in Source/core/html/HTMLFrameElementBase.cpp\nviolation in Source/core/html/HTMLFrameElementBase.h\nviolation in Source/core/html/HTMLFrameSetElement.cpp\nviolation in Source/core/html/HTMLFrameSetElement.h\nviolation in Source/core/html/HTMLImageElement.cpp\nviolation in Source/core/html/HTMLInputElement.cpp\nviolation in Source/core/html/HTMLInputElement.h\nviolation in Source/core/html/HTMLLabelElement.cpp\nviolation in Source/core/html/HTMLLegendElement.cpp\nviolation in Source/core/html/HTMLLinkElement.cpp\nviolation in Source/core/html/HTMLLinkElement.h\nviolation in Source/core/html/HTMLMapElement.cpp\nviolation in Source/core/html/HTMLMapElement.h\nviolation in Source/core/html/HTMLMarqueeElement.cpp\nviolation in Source/core/html/HTMLMarqueeElement.h\nviolation in Source/core/html/HTMLMediaElement.cpp\nviolation in Source/core/html/HTMLMediaElement.h\nviolation in Source/core/html/HTMLMenuElement.h\nviolation in Source/core/html/HTMLMeterElement.cpp\nviolation in Source/core/html/HTMLNameCollection.cpp\nviolation in Source/core/html/HTMLOListElement.h\nviolation in Source/core/html/HTMLObjectElement.cpp\nviolation in Source/core/html/HTMLObjectElement.h\nviolation in Source/core/html/HTMLOptGroupElement.cpp\nviolation in Source/core/html/HTMLOptGroupElement.h\nviolation in Source/core/html/HTMLOptionElement.cpp\nviolation in Source/core/html/HTMLOutputElement.h\nviolation in Source/core/html/HTMLPlugInImageElement.cpp\nviolation in Source/core/html/HTMLPlugInImageElement.h\n^C"", '']",1
"['Issue 480053: Need to make swarming work w/ GN', ""We're definitely at the point where we need to figure out how swarming will integrate w/ GN builds, so that we can start running swarmed tests from the GN bots.\n\nI had a brief discussion with maruel@ about this this afternoon, and will attempt to capture roughly what we discussed.\n\nBasically, these days, the way we run swarming on the bots is to batch-process all of the targets at once in a single build step (isolate tests) that runs *after* the compile has completed. That step takes a list of json files (one per target) and processes them all at once.\n\nThe json files contain the command line for each target and (I think?) a pointer to the .isolate files in question.\n\nBasically we need to have GN create the equivalent .isolate file and command lines at meta-build time, but we don't need to do any work at compile time. The isolate_tests step will then run as usual, though we may want to run a slightly different step in order to use a slightly different format instead of the .isolate format, since we need something much less complicated.\n\nLet's call the new format a 'gn_isolate' (I'm open to better name).\n\nAt meta-build time, we want GN to create a gn_isolate file that contains roughly the equivalent of the following, using base_unittests as an example:\n\n1) the path to the base_unittests executable\n2) the path to any shared libraries base_unittests depends on\n3) the path to any data files or data_deps base_unittests depends on\n4) the path to start the binary from (i.e., to use as the current working directory; not sure if this is needed?)\n5) the command line to run base_unittests\n\nWe can get 1) trivially. \n\nWe can get 2) from 'gn desc //out/Release //base:base_unittests deps --type=shared_library --as=output', though it looks like that command might also include data_deps shared libraries.\n\nWe can get any executable data_deps needed for 3) via a variant, with the same caveat. Although it looks like GN nominally has support for 'data' declarations, it's not clear if they are actually used anywhere today outside of GN unit test code (there seems to be one case, for tools/relocationpacker:relocation_packer_unittests), and it's not clear if that's actually exposed via 'gn desc'.\n\n5) does not exist in any current form.\n\nOf course, we also don't want to re-run GN a bunch of times in order to compute this data; it would be slow, and re-running GN has side effects.\n\nSo, we should figure out how to best extend GN to write this. One way would be to define a gn_isolate variable, and if it was set on a given target, have GN write a JSON file to the location specified by the variable. This would require some semi-hardcoded knowledge of what the contents of the file should be (the format of a gn_isolate).\n\nA slightly less hard-coded approach would be to define a new rule that could explicitly write the file (using write_file()), and add new functions that can extract the values from a target, e.g., add get_target_deps(), get_target_command_line(), etc., and then have the rule build up the contents of the file on the fly. I'm not sure if GN's string manipulation logic is strong enough to do this, however.\n\nSo, I'm inclined to start w/ the hard-coded approach, since the limitations described earlier mean that we'll probably need to change GN regardless.\n\nWhat do others think? Have I missed other requirements?"", '']",1
"['Issue 221264: Set reimage job timeout based on frequency of scheduling', ""We have three intervals at which tests can get scheduled:\n\n  1. Every build (roughly every 6 hours).\n  2. Nightly\n  3. Weekly\n\nFor all of these, the suite sets the reimage job timeout to be 4 hours.  This\nmeans that a reimage job will wait around trying to collect machines that the\ntests can run on for only four hours.  After the four hours, we abort the\nreimage job, and then we're likely to not be able to run the tests.\n\nFor running tests on every build, this makes sense, as it prevents backlog.\nHowever, one would expect to be able to once a week, queue up a week's worth of\nwork, and then let the system work its way through the work during the week.\nIf one looks at the graph of queued jobs, this roughly seems like how the\nsystem is used.  On Sunday, when we kick off weekly suites, we see a massive\nspike of tests, only to drop significantly thereafter (as all the reimage jobs\nget aborted).\n\nTherefore, we should set the reimage job timeout (and the scheduler's job\ntimeout) corresponding to how frequently the test is scheduled, so that we have\na day to work through things scheduled daily, and a week to work through things\nscheduled weekly (plus or minus some fuzzing/tuning)."", '']",1
"['Issue 39368: Make appcache work with workers.', ""There are two parts to this, dedicated workers vs shared workers.\n\nDedicated Workers\n* The worker resource itself (the script file) should be loaded thru the same \nappcache as its parent.\n* Subresource loads performed by the dedicated worker should also be loaded \nthru the same appcache as its parent.\n* The appcache scritpable interface need not be available in the decidated \nworker context (although nothing says it can't be made available there too).\n\nShared Workers\n* The worker resource should not be loaded thru the parents appcache. This case \nis much more like a subframe navigation than a subresource load.\n* Cache selection and the triggering of a cache update should be performed just \nas it is for frame navigations.\n* Subresource loads performed by the shared worker should go thru the selected \ncache for that shared worker (again just like for frames).\n* The scriptable interface needs to be available in the shared worker context."", '']",1
"['Issue 388515: Componentize AutocompleteProvider', ""AutocompleteProvider depends on:\n- Profile\n- bookmark_model / bookmark_model_factory\n- Profile's pref && pref_names\n\n# content/public/common/url_constant is a fake include"", '']",1
"['Issue 496048: WebRTC Chromium bots stopped reporting perf numbers at May 27', ""At May 27, the bots in in \nhttp://build.chromium.org/p/chromium.webrtc/waterfall\nhttp://build.chromium.org/p/chromium.webrtc.fyi/waterfall\nstarted getting errors like this when uploading perf data:\n\nDiscarding JSON, error:\nHTTPError: 400. Reponse: Invalid ID (revision) 332562; compared to previous ID 1432752178, it was larger or smaller by too much.\n\nWe haven't done any changes to the bots, so it seems the timestamps that was previously reported is no longer working.\nI've previously filed issue 469523 trying to address this, but it's blocked on issue 469764. Could we get this fixed so we can start reporting commit positions instead?\n\nI'm also interested in if there's a quick fix for this so we're not flying blind in the meantime!\n\nIt seems it won't help us by just changing timestamps -> commit positions since the graphs would be confused unless the existing data is first converted?"", '']",1
"['Issue 210822: daisy: get vboot up and running', 'Get verified boot up and running on Daisy.', '']",1
"['Issue 221103: daisy: scons failure building mali-drivers due to builder hardware switch', 'We\'re getting scons failures when building mali-drivers on the release builders for both spring and snow. I can build it just fine on my workstation. The error, -4, is kind of cryptic and I\'m not sure where to go with this.\n\nhttp://chromegw.corp.google.com/i/chromiumos.release/builders/daisy%20full%20release-R25-3428.B/builds/123/steps/cbuildbot/logs/stdio\n\n\nmali-drivers-0.45-r97: scons: *** [cmpbe/src/cmpbe_gles11_vertex/cmpbe_shader_pieces.h] Error -4\n...\nmali-drivers-0.45-r97: scons: building terminated because of errors.\nmali-drivers-0.45-r97:  * ERROR: media-libs/mali-drivers-0.45-r97 failed (compile phase):\nmali-drivers-0.45-r97:  *   escons failed.\nmali-drivers-0.45-r97:  * \nmali-drivers-0.45-r97:  * Call stack:\nmali-drivers-0.45-r97:  *     ebuild.sh, line   56:  Called src_compile\nmali-drivers-0.45-r97:  *   environment, line 3372:  Called escons \'-f\' \'bldsys/sconstruct\'\nmali-drivers-0.45-r97:  *   environment, line 1592:  Called die\nmali-drivers-0.45-r97:  * The specific snippet of code:\nmali-drivers-0.45-r97:  *       [[ ${ret} -ne 0 && ${EAPI:-0} -ge 4 ]] && die ""escons failed."";\nmali-drivers-0.45-r97:  * \nmali-drivers-0.45-r97:  * If you need support, post the output of \'emerge --info =media-libs/mali-drivers-0.45-r97\',\nmali-drivers-0.45-r97:  * the complete build log and the output of \'emerge -pqv =media-libs/mali-drivers-0.45-r97\'.\nmali-drivers-0.45-r97:  * This ebuild is from an overlay named \'daisy-private\': \'/home/chrome-bot/trunk/src/private-overlays/overlay-daisy-private/\'\nmali-drivers-0.45-r97:  * The complete build log is located at \'/build/daisy/tmp/portage/logs/media-libs:mali-drivers-0.45-r97:20130215-112309.log\'.\nmali-drivers-0.45-r97:  * The ebuild environment file is located at \'/build/daisy/tmp/portage/media-libs/mali-drivers-0.45-r97/temp/environment\'.\nmali-drivers-0.45-r97:  * S: \'/build/daisy/tmp/portage/media-libs/mali-drivers-0.45-r97/work/mali-drivers-0.45\'\nmali-drivers-0.45-r97: >>> Failed to emerge media-libs/mali-drivers-0.45-r97 for /build/daisy/, Log file:\nmali-drivers-0.45-r97: >>>  \'/build/daisy/tmp/portage/logs/media-libs:mali-drivers-0.45-r97:20130215-112309.log\'\nmali-drivers-0.45-r97: \nmali-drivers-0.45-r97:  * Messages for package media-libs/mali-drivers-0.45-r97 merged to /build/daisy/:\nmali-drivers-0.45-r97:  * ERROR: media-libs/mali-drivers-0.45-r97 failed (compile phase):\nmali-drivers-0.45-r97:  *   escons failed.\nmali-drivers-0.45-r97:  * \nmali-drivers-0.45-r97:  * Call stack:\nmali-drivers-0.45-r97:  *     ebuild.sh, line   56:  Called src_compile\nmali-drivers-0.45-r97:  *   environment, line 3372:  Called escons \'-f\' \'bldsys/sconstruct\'\nmali-drivers-0.45-r97:  *   environment, line 1592:  Called die\nmali-drivers-0.45-r97:  * The specific snippet of code:\nmali-drivers-0.45-r97:  *       [[ ${ret} -ne 0 && ${EAPI:-0} -ge 4 ]] && die ""escons failed."";\nmali-drivers-0.45-r97:  * \nmali-drivers-0.45-r97:  * If you need support, post the output of \'emerge --info =media-libs/mali-drivers-0.45-r97\',\nmali-drivers-0.45-r97:  * the complete build log and the output of \'emerge -pqv =media-libs/mali-drivers-0.45-r97\'.\nmali-drivers-0.45-r97:  * This ebuild is from an overlay named \'daisy-private\': \'/home/chrome-bot/trunk/src/private-overlays/overlay-daisy-private/\'\nmali-drivers-0.45-r97:  * The complete build log is located at \'/build/daisy/tmp/portage/logs/media-libs:mali-drivers-0.45-r97:20130215-112309.log\'.\nmali-drivers-0.45-r97:  * The ebuild environment file is located at \'/build/daisy/tmp/portage/media-libs/mali-drivers-0.45-r97/temp/environment\'.\nmali-drivers-0.45-r97:  * S: \'/build/daisy/tmp/portage/media-libs/mali-drivers-0.45-r97/work/mali-drivers-0.45\'\nmali-drivers-0.45-r97:', '']",1
"['Issue 246629: 7.1% regression in linux-release/idb_perf/OverallTestDuration/t at 203868:203889', 'Graphs:\nhttps://chromeperf.appspot.com/report?rev=203889&masters=ChromiumPerf&bots=linux-release&tests=idb_perf/OverallTestDuration/t\n\n\nMight be related to your change? Will submit a bisect job as well.', '']",1
"[""Issue 172706: GYP needs support for ninja's new 'pool' feature"", ""The new feature is documented here: https://github.com/martine/ninja/blob/master/doc/manual.asciidoc\n\nSyntax cheatsheet:\n\n-------------\npool MyAwesomePool\n  depth = 4\n\nrule link\n  ...\n  pool MyAwesomePool\n\nbuild heavy_object: compile heavy_object.cc\n  pool MyAwesomePool\n\nbuild library: link heavy_object\n   # uses MyAwesomePool automatically\n-------------\n\nIdeally, it should be possible to specify:\n  1. What pools exist, and their depths.\n  2. Pool for 'rule' actions in gyp\n  3. Pool for default rule actions in gyp (compile, link, etc.)\n  4. Pool for specific, tricky build items (i.e. really big compilation units (v8, I think?)).\n\nPossible starter idea for syntax:\n  * global 'concurrency_pools': { 'pool_name': { 'depth': <int> } }\n    * NOTE: it's an error in ninja to specify the same pool multiple times. This error condition should probably be lifted into gyp as well to provide feedback asap.\n  * 'concurrency_pool' on 'rule'  # for custom rules\n    * Error if pool D.N.E.?\n  * ??? Not sure how do address 3, 4 in list above"", '']",1
"['Issue 264611: Support multiple AudioProcessing modules for WebRtc media stream', 'Version: \nOS: ALL\n\n\nCurrently we only support one AudioProcessing module for one WebRtc VoiceEngine. This introduces a couple of problems, for example:\n# Supporting multiple microphones.\n# Different audio tracks might have different contrains.\n# When a peer connection has multiple audio tracks, the loggings are not correct in libjingle.\n\nThe correct fix to all the problem is that we should be able to have different AudioProcessing module to different audio tracks if they are using different sources or having different constrains.', '']",1
"['Issue 229740: Meta: Auto-generate indexed properties and named properties', 'Currently indexed property getters/setters and named property getters/setters are written manually in custom bindings and V8Collection.h. In addition, GenerateImplementationNamedPropertyGetter() in CodeGeneratorV8.pm is full of hacks. We should auto-generate them in a consistent manner.\n\nOur future world should be simple:\n\n[IndexedGetter] => indexed property getter is auto-generated\n[IndexedSetter] => indexed property setter is auto-generated\n[NamedGetter] => named property getter is auto-generated\n[NamedSetter] => named property setter is auto-generated\n[CustomIndexedGetter] => indexed property getter is written in custom binding\n[CustomIndexedSetter] => indexed property setter is written in custom binding\n[CustomNamedGetter] => named property getter is written in custom binding\n[CustomNamedSetter] => named property setter is written in custom binding', '']",1
"['Issue 155209: Impl-side painting for Android', 'To avoid checkerboarding and mask slow paint performance, we intend to move painting to happen on the compositor thread rather than the WebKit main thread.\n\nA rough outline of the design is here:\n\nhttps://sites.google.com/a/chromium.org/dev/developers/design-documents/impl-side-painting\n\nThis bug can serve as a public meta-bug for this work.', '']",1
"['Issue 225806: EnableTerminationOnHeapCorruption for 64 bit Mac', 'EnableTerminationOnHeapCorruption fails to patch malloc_error_break because LookUpMallocErrorBreak only has a 32-bit implementation. This should be fixed to also catch heap corruption with 64 bits.', '']",1
"[""Issue 160900: FileEntry objects returned from MediaGallery API don't support toURL() method."", 'What steps will reproduce the problem?\n1. Obtain a FileEntry object from MediaGallery API.\n2. Call toURL() on that object.\n\nWhat is the expected output?\nA file URL that can be used in img and video tags.\n\nWhat do you see instead?\nAn empty file URL.\n\nCopying the underlying file in the HTML5 filesystem obtained by webkitRequestFileSystem, and then calling toURL() on the new FileEntry instance works as expected.', '']",1
"['Issue 240113: Animated GIFs no longer consistently animate', 'UserAgent: Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/28.0.1500.5 Safari/537.36\n\nExample URL:\nhttp://imgur.com/gallery/9CMRK\n\nSteps to reproduce the problem:\n1. Open webpage with an animated GIF\n2. Stare at it while you wait for it to ""load""\n3. Realize it is not loading, refresh page, it works (maybe)!\n\nWhat is the expected behavior?\nGIF should animate 100% of the time\n\nWhat went wrong?\nStops animating/does not loop, or does not animate at all about 10% of the time.\n\nDoes it occur on multiple sites: Yes\n\nIs it a problem with a plugin? No \n\nDid this work before? Yes I\'ve noticed this issue for a month or two now\n\nDoes this work in other browsers? Yes Latest Firefox, IE\n\nChrome version: 28.0.1500.5  Channel: dev\nOS Version: 6.1 (Windows 7, Windows Server 2008 R2)\n\nSometimes Chrome likes to act up when it\'s been open for too long, or if I leave YouTube open for a while (yay flash!) so I often restart the browser when I am having these sorts of issues, and it often seems resolved. After opening a few different GIF albums, I realized that it is not a ""performance"" problem per se, but about 10% of the animated GIFs in any given album just don\'t animate. If I open the file in a new tab, it works fine but going back to the album it is still frozen. Sometimes GIFs will freeze after one full iteration and not loop.\n\nRefreshing a page often fixes the issue, but causes OTHER images in the album to stop working.', '']",1
"['Issue 442518: Need wrapper around cgpt to transparently handle off-device placement of the GPT', ""Forked from Issue 432611 (see comments #6, #8 and #9).\n\nThis wrapper will be run on the target. If running on NAND, the GPT is stored on the SPI NOR. If that't the case, the wrapper should flashrom read the GPT area from the NOR, use cgpt with the new --drive_size argument."", '']",1
"[""Issue 334996: Make sure the new Skia bitmap cache doesn't cause OOM"", 'See https://code.google.com/p/chromium/issues/detail?id=331832\n\nThe current ImageDecodingStore can store up to 128 discardable entries before it starts accounting memory usage. Memory usage is then limited to 32 MBytes.\nThis doesn\'t work very well with very large bitmaps. The problem is not that we end up committing too many pages sine the kernel does a good job at evicting unpinned ashmem but rather that we can end up fragmenting the address space which can lead to large mmap() failures (e.g. in v8).\n\nThe new Skia bitmap cache is going to be ""infinite"" if I understand correctly.\nI see a few ways to prevent OOM from happening (sorted by personal preference in descending order :)):\n\n- Make the new Skia bitmap cache have a high limit (e.g. 256 MBytes) but still low enough to allow other large mmap()s to succeed.\nIt could implement a full-fledged LRU cache to handle eviction or could even do something simpler that would probably be enough I suspect like keeping track of the last X (e.g. 32) accessed entries and only keep them (+ the entries currently being locked obviously) when cache memory usage exceeds the limit.\nI would expect this case to happen quite rarely (although this should be confirmed with experimentation) so I don\'t think we should heavily optimize for it (i.e. a full-fledged LRU cache might be overkill in my opinion).\nThe reason I also would like to have a limit for bitmaps is that bitmaps won\'t be the only thing we will be storing in discardable memory soon. My goal for this quarter is to use discardable memory for the resource cache in Blink. If we use so much ashmem (without necessarily needing it) for bitmaps then there is no chance that the resources in the Blink resource cache stay memory resident since they would only be accessed very early during page load (i.e. they would be the first candidates for eviction). We would need to have a way to pin them regularly to make sure that bitmaps don\'t kick them out.\nWorse than that, when unpinned ashmem gets evicted, all the unpinned subranges actually get evicted unfortunately. This is at least the behavior I could observe with this test program: https://chromiumcodereview.appspot.com/118323003/. Therefore we shouldn\'t trigger ashmem eviction too often if we want our caches to maintain a reasonable hit rate. An infinite cache would be much more likely to trigger ashmem eviction more often.\n\n- Make the ashmem allocator do an munmap() when a DiscardableMemory instance gets unlocked. There are four things I don\'t like with this:\n1) It\'s hiding memory usage (although one could argue that we shouldn\'t pay too much attention to evictable memory).\n2) We would have to do an mmap() whenever a DiscardableMemory instance gets locked and mmap() has very unpredictable performance on Android. In fact removing those mmap/munmap() calls in the initial DiscardableMemory refactoring CL caused a 5% improvement on the rasterize_and_record benchmark (which I was really not expecting TBH :)): https://code.google.com/p/chromium/issues/detail?id=317626\n3) Having DiscardableMemory::unlock() do an munmap() makes the use of DiscardableMemory::data() dangerously subtle. In particular it prevents the client from caching the pointer returned by data() which we don\'t/didn\'t specify at all in the API. And doing this munmap() also caused mysterious crashes since people were either using a junk pointer that would have been cached or accessing unmapped memory (e.g. because they were not doing a lock()) or even worse accessing random mapped memory. See https://code.google.com/p/chromium/issues/detail?id=322200 for instance.\n4) It wouldn\'t solve by itself the problem I brought up in the previous point about not kicking the Blink resources out of memory.', '']",1
"['Issue 237412: Replace run_measurement with run_benchmark', 'To replace test_info.json and metric_info.json, we make RunPerfTest.\n\nRunPerfTest has a list of PerformanceTests.\n\nPerformanceTest:\n   description of test\n   metrics it generates\n   benchmark object to runs\n   pageset to run\n\nMetricInfo is ~= the json, but maybe we make the PerfTestResults object require use of a MetricInfo.\n\nRunPerfTest uses the git command line approach, e.g RunPerfTest command <stuff for the command>\n\nRunPerfTest help\nRunPerfTest list-tests\nRunPerfTest run // runs all tests\nRunPerfTest run smoothness_benchmark\n\nRunPerfTest has very limited commandline options to discourage people from doing bot-level test setup (maybe you say --extra-test-args and it prints some scary warning)', '']",1
"['Issue 107744: Bookmarks getting reordered during sync (was: SC_SinkBMs10LevelDown failing consistently on win_sync trybots)', ""The final test assertion for these tests seems to fail very regularly.  \n\nI find it odd that we don't see any similar failures for the non-try win_sync bots.  It also isn't failing on any other platform than windows."", '']",1
"['Issue 234509: Implement Custom Elements', 'Custom Elements are described in this spec: <https://dvcs.w3.org/hg/webcomponents/raw-file/tip/spec/custom/index.html>\n\nThere was an initial implementation inherited from WebKit, but it is incomplete.\n\nCompleting the implementation requires a detailed reading of the spec, but at a high level, we need to:\n\n- Upgrade elements already in the document on registration (Issue 233775).\n- Implement the full set of callbacks.\n- Implement declarative syntax (the ""element element"").', '']",1
"[""Issue 263069: Shouldn't need commit to get resources back to main thread. Use a callback!"", 'See https://code.google.com/p/chromium/issues/detail?id=239290 for missing test coverage for this case.', '']",1
"['Issue 252329: Saved Devserver host attribute is overwritten by autoupdate_EndToEndTest', ""Recently this happened: https://code.google.com/p/chromium/issues/detail?id=252078\n\nI believe the reason it happened is because of #6:\n\n[paste]\n\nHmm.. I think the cl mentioned in #4 actually made it in. It looks like the autoupdate tests is overwriting the devserver url that we had hoped to save. So only the machines that ran the autoupdate_endtoend test, and that too only when they resolved wrong, failed eg: \n\nhttp://chromegw/i/chromeos/builders/x86-alex%20canary/builds/3722/steps/HWTest%20%5Bbvt%5D%20%5Bx86-alex%5D/logs/stdio\n\nsuite 3433067\ntry job 3433071\ntry job devserver url: devserver_url='http://172.22.50.205:8082'\n\nhost on which the autoupdate end to end job ran:\nhttp://cautotest/afe/#tab_id=view_host&object_id=chromeos2-row1-rack7-host11\n\nauend end to end: http://cautotest/afe/#tab_id=view_job&object_id=3433101\nit's devserver: 06/19 18:43:56.787 INFO |autoupdate:0218| triggering update via: /usr/bin/update_engine_client --check_for_update --omaha_url=http://172.17.40.27:43091/update\n\nthe failing test on the same DUT: http://cautotest/afe/#tab_id=view_job&object_id=3433209\n\nthe failing tests devserver: \n06/19 18:50:05.074 DEBUG|  ssh_host:0114| Running (ssh) 'wget --connect-timeout=15 --retry-connrefused --wait=5 -nv http://172.17.40.27:8082/static/archive/x86-alex-release/R29-4294.0.0/autotest/packages/client-autotest.tar.bz2 -O /usr/local/autotest/packages/client-autotest.tar.bz2'\n\nsimilar results for http://chromegw/i/chromeos/builders/link%20canary/builds/2361\n\n[/paste]\n\nI think what happens is we use the target_payload_uri to resolve the devserver in the end to end test, and previously we would have re-resolved with the image name in site_host but now we save the target_payload devserver overwriting the image name devserver.\n\nAlso filed: https://code.google.com/p/chromium/issues/detail?id=252326"", '']",1
"['Issue 423954: [telemetry] Create devtools_backend abstraction', 'DevtoolsBackend is a common set of methods for connecting to and communicating over the DevTools protocol. It will be used by both the Chrome browser (existing *BrowserBackend) and Android apps that have WebViews (new AndroidAppBackend).', '']",1
"['Issue 271836: All special license cases in licenses.py need to be folded back into the individual package sources', 'These need to be fixed for starters:\nPACKAGE_LICENSES = {\n  # One off licenses. Should we check in a custom LICENSE file in upstream?\n  \'dev-python/netifaces\': [\'netiface\'],\n  \'net-dialup/ppp\': [\'ppp-2.4.4\'],\n  \'sys-libs/ncurses\': [\'ncurses\'],\n\n  # BSD and MIT license authorship mapping.\n  # Ideally we should have a custom LICENSE file in the upstream source.\n  # TODO: BSD-2: bsdiff is missing a license file, add one upstream.\n  \'dev-util/bsdiff\': [\'BSD-bsdiff\'],\n  # TODO: libevent is missing a license file, add one upstream.\n  \'dev-libs/libevent\': [\'BSD-libevent\'],\n  # TODO: dhcpcd is missing a license file, (c) in README. Add one upstream.\n  \'net-misc/dhcpcd\': [\'BSD-dhcpcd\'],\n  # TODO: iputils is missing a license file, add one upstream.\n  \'net-misc/iputils\': [\'BSD-iputils\'],\n  # TODO: c-ares is missing a license file, add one upstream.\n  \'net-dns/c-ares\': [\'MIT-MIT\'],\n\n  # TODO: We should just check in a LICENSE file in all of these:\n  \'app-i18n/input-tools\': [\'BSD-Google\'],\n  \'app-i18n/nacl-mozc\': [\'BSD-Google\'],\n  \'app-i18n/ibus-mozc\': [\'BSD-Google\'],\n  \'media-plugins/o3d\': [\'BSD-Google\'],\n  \'dev-python/unittest2\': [\'BSD-Google\'],\n\n  # Fix ebuild multi license definitions when they define licenses that do\n  # not apply to us because we don\'t use the resulting binaries.\n\n  # Mesa ebuild says MIT and seems to omit LGPL-3 and SGI-B-2.0 mentioned in the\n  # docs directory? Either way, I had to create a text license file like so:\n  # mesa-9.1-r9/work/Mesa-9.1/docs$ lynx --dump license.html -nolist > license\n  \'media-libs/mesa\': [ \'MIT-Mesa\', \'LGPL-3\',\'SGI-B-2.0\' ],\n\n  # TODO: Ebuild seems to wrongfully say BSD + public-domain.\n  # I scanned the unpacked source with licensecheck and didn\'t find any BSD.\n  # FIXME: Do a second review and fix upstream gentoo package\n  \'sys-libs/timezone-data\': [ \'public-domain\' ],\n\n  # Ebuild only says \'LGPL-2.1\', but source disagrees. I\'ll include \'as-is\'\n  # to force reading files from the source (which states some parts are as-is).\n  # FIXME? Should the ebuild license be updated to match xz-4.999.9beta/COPYING?\n  \'app-arch/xz-utils\': [ \'public-domain\', \'as-is\', \'LGPL-2.1\', \'GPL-2\' ],\n\n\nThis is illegal:\nLICENSE=""Marvell International Ltd.""', '']",1
"['Issue 533457: Inconsistent error-handling between the two filter graph builders', 'There are two different code-paths for building DAGs for ""reference filters"" (AKA ""SVG filters""), and they handle ""errors"" in primitives differently.\n\nExamples:\n\nhttp://jsfiddle.net/rfz97vt6/5/ (feConvolveMatrix)\nhttp://jsfiddle.net/wrohgheu/2/ (feDiffuseLighting)\n\nThe ""SVG"" code-path errors out and renders nothing, while the other code-path (ReferenceFilterBuilder) skips the primitive (which would mean that the DAG could get a different shape due to failing name-lookups etc.)\n\nIn the spec, the most common way to handle ""fatal"" errors is to let the primitive produce ""transparent black"" - this also seems to be what Gecko does (at least in the cases I\'ve tested.) Optionally one could also fallback to initial values where they exist and yield a reasonable result. That should be an easy step two though if it\'s felt needed.', '']",1
"['Issue 22208: Support building with system sqlite', ""Chrome Version       : 4.0.212 svn r26343\nOS + version : Gentoo\nCPU architecture (32-bit / 64-bit): both\n\nWhat steps will reproduce the problem?\nRun gyp_chromium -f make build/all.gyp with -Duse_system_sqlite=1\n\nWhat is the expected result?\nCompilation completes successfully\n\nWhat happens instead?\nOn final linking:\nout/Release/obj/app/libapp_base.a(connection.o): In function\n`sql::Connection::Preload()':\nconnection.cc:(.text._ZN3sql10Connection7PreloadEv+0xcb): undefined\nreference to `sqlite3Preload'\nout/Release/obj/webkit/libwebcore.a(SQLiteFileSystemChromiumPosix.o): In\nfunction `(anonymous namespace)::chromiumOpen(sqlite3_vfs*, char const*,\nsqlite3_file*, int, int*)':\nSQLiteFileSystemChromiumPosix.cpp:(.text._ZN12_GLOBAL__N_112chromiumOpenEP11sqlite3_vfsPKcP12sqlite3_fileiPi+0x3a):\nundefined reference to `initUnixFile'\nSQLiteFileSystemChromiumPosix.cpp:(.text._ZN12_GLOBAL__N_112chromiumOpenEP11sqlite3_vfsPKcP12sqlite3_fileiPi+0xfd):\nundefined reference to `fillInUnixFile'\n\nFrom README.chromium these 3 functions are indeed new or modified from\nupstream sqlite, but as they are mangled in the upstream code, compilation\nfails when enabling use_system_sqlite (which disables compilation of\nmodified files, like os_unix.c)\n\nI'd like to provide a patch splitting/renaming these functions somewhere\neles in chromium code (should be easy, for example initUnixFile() is just a\none-liner call to memset()), but I don't know the coding guidelines that\napply in this case"", '']",1
"['Issue 371570: TLB perf counter events not supported on Haswell systems', 'R36\n\nNeed these for CWP to function properly', '']",1
"['Issue 564618: allocator: refactor and clean up build files', ""Context: [chromium-dev] Intent to clean up allocator dependencies in build files\n\nDesign doc: https://docs.google.com/document/u/1/d/1V77Kgp_4tfaaWPEZVxNevoD02wXiatnAv7Ssgr0hmjg/edit?usp=drive_web\n\nFrom the chromium-dev thread\n\nTL;DR\n- I am planning to clean up dependencies on allocator in (mostly gyp) build files.\n- I am NOT planning to introduce any behavioural change at this stage.\n- I would like to not break things while doing this (hence this mail).\nAttached to this mail there is a doc [1]. Shout loud if you have strong opinions or useful feedback.\n\nThe current situation of allocator in build files is a bit messed up, mainly for two reasons:\n1. In theory only executables should depend on allocator. In practice this is not the case today. Lot of violations, lot of TODOs in the codebase (cc-ing some of them).\n2. In GYP files the situation is really fragile: each target conditionally depends on allocator checking inconsistently for various build flags.\n\nAs a matter of facts it is extremely hard to reason and attempt any change and be sure to not break everything.\nSo the plan here is to (not) break everything upfront while attempting to not make any change.\n\nTogether with some members of my team, I am volunteering to cleanup the situation and bring it to a saner state.\nAt this stage I do not intend to add / remove any feature or behaviour, nor to change the existing state w.r.t allocator choices on the various platforms.\n\nWhy? We have some future plans* (mostly related with this [2] heap profiler project). Such plans are out of the scope of this discussion. Will start a separate discussion later, once we'll be in a better state.\n\nI am aware of the fact that allocator and its deps are a scary monster, but in all honesty, it seems to me extremely hard to attempt any change given the current situation. Hence this cleanup proposal. Given the amount of details involved we started a longer doc with an analysis of the problem and a proposal on how to clean it up.\n\nThe reason of this mail is that I feel there is the very high chance that, despite having spent a lot of time analyzing the situation, we might still be missing some use case or not thinking to something, which I would like to find out sooner rather than later.\n  \nThe doc is world-editable. Thanks in advance for your inputs."", '']",1
"['Issue 161834: Cache /proc/cpuinfo and make it available inside sandboxed renderers', 'Version: <Kenneth, what is the frequency?>\nOS: <please tell me it\'s not XP>\n\nWhat steps will reproduce the problem?\n1. On an ARM device, profile libvpx with the sandbox enabled and with it disabled (--no-sandbox).\n\nWhat is the expected output? What do you see instead?\nThe performance should be the same. Instead, it is much worse with the sandbox enabled.\n\nPlease use labels and text to provide additional information.\nThere are probably other ways to check if the NEON code path is being followed.\n\nEnabling neon in the .gyp file does not mean the NEON path _will_ be used. Instead, libvpx checks /proc/cpuinfo [1], which is not accessible from inside the sandbox. When the fopen fails, it falls back to the non-optimized code path.\n\nAdding ""VPX_SIMD_CAPS=0xf"" to the environment will override the check and allow the optimized path while inside the sandbox, but it\'s not a good long-term solution.\n\n[1] http://code.google.com/searchframe#OAMlx_jo-ck/src/third_party/libvpx/source/libvpx/vpx_ports/arm_cpudetect.c&exact_package=chromium&q=libvpx%20cpuinfo&type=cs&l=147', '']",1
"['Issue 98834: Have builder/tester setup for tryjobs, run test binaries in parallel on different slaves', ""Brings test run time from sum(t all binaries) to max(t all binaries) + time for pack & unpack.\n\nStoring and deleting test binaries is not completely trivial, but with the debug-info-less release bots, the test binaries at least aren't that huge.\n\n(Test execution jobs should always be prioritized over compilation jobs to make this work.)"", '']",1
"['Issue 197970: Build process should generate about:os-credits page containing licenses from third-party packages', ""Many of the open-source packages that we distribute in binary form have licenses that require that the licenses themselves be distributed alongside the binaries.  Some of these licenses (e.g. BSD-style) additionally require that a copyright notice identifying the package's owner be included.\n\nPortage is deficient in satisfying these requirements when shipping software in binary form.  Its ebuild files include a field that names a package's license, but the field is optional and may be outdated or incorrect.  Additionally, using stock versions of licenses fails to satisfy the aforementioned requirements for including copyright notices.\n\nI wrote a script that for each package in one of our images, downloads the package's source tarball and looks within it for several well-known license files (LICENSE, COPYING, etc.), eventually falling back to the license from the ebuild.  I've also done a bunch of manual inspection and hardcoding.  This script outputs the static HTML page that Chrome serves at about:os-credits.  I typically run it just before a new major release.\n\nWe should change this process so that individual engineers are responsible for ensuring that license information is correct whenever they add or update a package.  I believe that Chromium enforces this by requiring that the location of the license file for all third-party software be specified (note that it's a bit easier in their case since the third-party code is checked into the Chromium repo).  We should probably do something similar, and have the build process automatically generate the credits page based on the packages that it builds."", '']",1
"[""Issue 420515: Improve Oilpan's infrastructure"", ""This is a tracking bug for changes to improve Oilpan's infrastructure."", '']",1
"['Issue 210506: signer: reuse the first gsutil ls output for the factory tobesigned files', ""The chromeos-releases bucket is quite large and both gsutil ls searches for .tobesigned files is quite costly (3 to 5 minutes right now) \n\nWe should make:\n\nDEBUG:130312 20:09 Executing (Local): /usr/local/bin/gsutil/gsutil ls gs://xyz/*.tobesigned\n\nDEBUG:130312 20:09 Executing (Local): /usr/local/bin/gsutil/gsutil ls gs://xyz/*.tobefactorysigned\n\nBe something more like\ngsutil ls .... > /tmp/file\ngrep .tobesigned /tmp/file # don't use grep, use python this is pseudo code.\ngrep .tobefactorysigned /tmp/file"", '']",1
"['Issue 194456: Build bootable signed(NV boot ROM signature, not VBoot) firmware image for Tegra2 platforms', 'We need to sign the combination of the BCT + stub firmware to be placed in the stub section of the flash map.  This is accomplished using the cbootimage tool.  Then we construct a final firmware image using the pack_firmware_image tool.', '']",1
"['Issue 230018: [MP Chrome] Owner key loading and usage must be profile-aware', 'Currently, the Chrome OS device ""Owner"" keypair is loaded on-demand in the SessionManagerOperation class, which is used by the Chrome OS settings code.  This code calls into the OwnerKeyUtil class, which wraps a call to crypto::RSAPrivateKey::FindFromPublicKeyInfo().  This call is _not_ profile aware, which means that any user will be able to perform owner-restricted operations whenever the owner is signed in.\n\nNot only will this FindFromPublicKeyInfo() call need to be make profile-aware, but the settings code that calls it will need to be sure to pass in the correct contextual information.\n\nTossing to Nikita to make sure it\'s on the radar, but I don\'t know who should ultimately handle this.', '']",1
"['Issue 249502: Security: (Shared) (WebSQL) Worker races cause invalid pointers in DatabaseObserver::databaseClosed and DatabaseObserver::reportOpenDatabaseResult', 'VULNERABILITY DETAILS\nChrome crashes in DatabaseObserver::databaseClosed and DatabaseObserver::reportOpenDatabaseResult with an invalid pointer when multiple (random name) databases are opened while the script reloads (continuously) from multiple shared workers onmessage events.\n\nMany other trivial 0-ptr crashes like chromiumOpen, chromiumAccess and chromiumDelete can occur. All seem to be caused by worker races.\n\nIt is also possible that the script causes an invalid handle (stack corruption?) while reloading the worker (process). Without a debugger this can (probably) happen unnoticed.\n\nVERSION\nChrome Version: 27.0.1453.110 stable - 29.0.1538.0 continuous (trace)\nOperating System: Windows: XP SP3, 7 SP1\n\nREPRODUCTION CASE\nLaunch the added script\n\nFOR CRASHES, PLEASE INCLUDE THE FOLLOWING ADDITIONAL INFORMATION\nType of crash: worker\nCrash State: see added stack trace files', '']",1
"['Issue 414363: Cleanup seccomp-bpf and bpf_dsl', 'The sandbox/linux/seccomp-bpf and sandbox/linux/bpf_dsl directories could use some love:\n\n  - Lots of IWYU violations; e.g., .h files including other unneeded header files, .cc files implicitly depending on some headers including those other headers.\n  - Odd layering; e.g., the CodeGen and Trap classes shouldn\'t depend on ErrorCode, especially as bpf_dsl eventually replaces the need for ErrorCode.\n  - The ""policy compiler"" logic in SandboxBPF should be extracted out into a separate class so SandboxBPF can focus simply on the system calls needed to install a policy.', '']",1
"['Issue 194085: Build a single U-Boot binary for all Tegra2 based boards.', 'We would like to have a single U-Boot image that given a config file at run time (probably a FDT read along with U-Boot by the masked ROM from SPI) it can configure itself and run on any of our Tegra2 based targets.', '']",1
"[""Issue 195707: XKB cleanup after install doesn't belong in chromeos_startup"", 'Chrome OS Version  :  0.12.286.0\nChrome Version     :  N/A\nType of computer   :  any\n\nWhat steps will reproduce the problem?\n1. Read the source for /sbin/chromeos_startup\n  (see src/platform/init/chromeos_startup)\n\nWhat is the expected output? What do you see instead?\nThe script contains these lines:\n\n# Check if we need to run post install tasks. The tasks should be safe\n# to be run more than once, as we\'ll rerun the tasks in case the device\n# shuts down before completing the tasks, though it\'s unlikely to happen.\nINSTALL_COMPLETED=/mnt/stateful_partition/.install_completed\nif [ -f ""${INSTALL_COMPLETED}"" ]; then\n  # Remove XKB cache files, as the files may be incompatible after upgrade.\n  rm -f /var/lib/xkb/*.xkm\n\n  # This has to be done at the end of the block.\n  rm -f ""${INSTALL_COMPLETED}""\nfi\n\nThis isn\'t the best place for this code for several reasons:\n  * It clutters the boot time critical path with extra code, making\n    the code harder to evaluate for performance issues, and thus\n    harder to maintain.\n  * It is logically related to update, and not to boot.  As such it\n    probably better fits in chromeos-postinst.\n  * It is logically related to some similar code for post install\n    clean up (e.g. deletion of the ureadahead pack file) which\n    lives in chromeos-postinst.\n  * It adds yet another poop file to the uncontrolled list of\n    such beasts, which isn\'t the preferred direction.\n\nThe code appears to be trying to solve problems associated\nwith postinstall from USB; I don\'t believe it actually fixes that\nproblem, since /mnt/stateful_partition is actually no different\nfrom /var during USB postinstall.', '']",1
"['Issue 714231: Create a Press benchmark harness that simplifies the task of adding press benchmark & allows running all press benchmark in 1 step', 'The steps for adding a new press benchmark is pretty difficult:\n1) Add new Measurement class. Here you gonna define the logic of:\n  i) Trigger test run\n  ii) Wait for test run to finish\n  iii) Parse the test results from the press benchmark & translate it the results format that Telemetry understands.\n2) Create a benchmark that uses the Measurement class. In this benchmark you will also:\n  i) Create a PageSet instance that define all the tests to run in the benchmark. \n  ii) Create many Page instances for running sub tests in the press benchmark & add them the PageSet instance. Here, you may have some logic for navigating to each sub test in the press benchmark (example: https://cs.chromium.org/chromium/src/tools/perf/benchmarks/dromaeo.py?rcl=049ab8b91cb873da45755e6c678d153b7fc3d856&l=122)\n\nThose are two many boiler plate code & needless abstractions to go through whereas the essential business logic are just 3 things: creating the test URL, triggering test run, wait for test to finish, parse test results & translate to Telemetry results.\n\n\nTo simplify all of this, I propose that we create a new press benchmark harness that allows simplify the task of adding new press benchmark with simpler hooks for people to fill in.\n\nAnother requirement is that this press benchmark harness should also allow running all the press benchmarks in one step, i.e: ""tools/perf/run_benchmarks press_benchmarks"" (custom suite can be run with --tag-filter=.."". This is because of our initiative to remove the number of benchmark steps on the waterfall (issue 713327).', '']",1
"[""Issue 713517: parse_textproto doesn't parse text protobufs"", 'https://luci-logdog.appspot.com/v/?s=infra%2Fswarm%2Fchromium-swarm.appspot.com%2F35a27f775c76f911%2F%2B%2Fsteps%2FUncaught_Exception%2F0%2Flogs%2Fexception%2F0\n\nTraceback (most recent call last):\n  File ""/b/s/w/ir/kitchen-checkout/recipes/.recipe_deps/recipe_engine/recipe_engine/run.py"", line 316, in _new_run\n    recipe_result = recipe_script.run(api, properties)\n  File ""/b/s/w/ir/kitchen-checkout/recipes/.recipe_deps/recipe_engine/recipe_engine/loader.py"", line 81, in run\n    self.run_steps, properties, self.PROPERTIES, api=api)\n  File ""/b/s/w/ir/kitchen-checkout/recipes/.recipe_deps/recipe_engine/recipe_engine/loader.py"", line 592, in invoke_with_properties\n    **additional_args)\n  File ""/b/s/w/ir/kitchen-checkout/recipes/.recipe_deps/recipe_engine/recipe_engine/loader.py"", line 553, in _invoke_with_properties\n    return callable_obj(*props, **additional_args)\n  File ""/b/s/w/ir/kitchen-checkout/recipes/recipes/recipe_roll_tryjob.py"", line 90, in RunSteps\n    patches_raw, rietveld, issue, patchset, patch_project)\n  File ""/b/s/w/ir/kitchen-checkout/recipes/.recipe_deps/recipe_engine/recipe_engine/recipe_api.py"", line 578, in _inner\n    return func(*a, **kw)\n  File ""/b/s/w/ir/kitchen-checkout/recipes/recipe_modules/recipe_tryjob/api.py"", line 284, in run_tryjob\n    p: self._get_project_config(p) for p in all_projects}\n  File ""/b/s/w/ir/kitchen-checkout/recipes/recipe_modules/recipe_tryjob/api.py"", line 284, in <dictcomp>\n    p: self._get_project_config(p) for p in all_projects}\n  File ""/b/s/w/ir/kitchen-checkout/recipes/.recipe_deps/recipe_engine/recipe_engine/recipe_api.py"", line 578, in _inner\n    return func(*a, **kw)\n  File ""/b/s/w/ir/kitchen-checkout/recipes/recipe_modules/recipe_tryjob/api.py"", line 133, in _get_project_config\n    parsed = self.m.luci_config.parse_textproto(result[\'content\'].split(\'\\n\'))\n  File ""/b/s/w/ir/kitchen-checkout/recipes/.recipe_deps/recipe_engine/recipe_engine/recipe_api.py"", line 578, in _inner\n    return func(*a, **kw)\n  File ""/b/s/w/ir/kitchen-checkout/recipes/.recipe_deps/build/scripts/slave/recipe_modules/luci_config/api.py"", line 120, in parse_textproto\n    \'Could not understand line: <%s>\' % line) # pragma: no cover\nValueError: Could not understand line: <{>\n\n*deep breath*\n\nPlease just remove this hacky text protobuf parser and replace it with something sensible.  Next time you\'re thinking about writing your own text protobuf parser using regular expressions, please step away from the keyboard and reconsider your life choices.', '']",1
"['Issue 712208: sunspider failing on 6 builders', 'sunspider failing on 6 builders\n\nBuilders failed on: \n- Linux Perf: \n  https://build.chromium.org/p/chromium.perf/builders/Linux%20Perf\n- Win 10 Perf: \n  https://build.chromium.org/p/chromium.perf/builders/Win%2010%20Perf\n- Win 7 ATI GPU Perf: \n  https://build.chromium.org/p/chromium.perf/builders/Win%207%20ATI%20GPU%20Perf\n- Win 7 Intel GPU Perf: \n  https://build.chromium.org/p/chromium.perf/builders/Win%207%20Intel%20GPU%20Perf\n- Win 8 Perf: \n  https://build.chromium.org/p/chromium.perf/builders/Win%208%20Perf\n- Win Zenbook Perf: \n  https://build.chromium.org/p/chromium.perf/builders/Win%20Zenbook%20Perf', '']",1
"['Issue 690513: Move Chrome OS code back from AOSP', 'A bunch of Chrome OS code got moved into AOSP to support the Brillo project. As far as I\'m aware, the current plan is that most (all?) of that code will not be used in Brillo. We\'re carrying technical debt due to this, and moving this code back to Chrome OS repositories would make Chrome OS development easier.\n\nLooking in the aosp/ directory in a Chrome OS checkout, I think it may be possible to move the following back out of AOSP:\n\nexternal/dbus-binding-generator\nexternal/libbrillo <-- should also be renamed back to ""libchromeos""\nexternal/libchrome <-- possibly depended on by other AOSP code :-/\nexternal/libmojo\nsystem/connectivity/apmanager\nsystem/connectivity/shill\nsystem/firewalld\n\nI\'m not sure whether these are still needed by Brillo (or Android):\n\nexternal/minijail\nsystem/tpm\nsystem/update_engine\nsystem/webservd\n\nThere may be some dependencies from checked-in-but-unused Brillo code like the C++ portion of WeaveService.', '']",1
"['Issue 689696: Unify OutputSurfaces and centralize DisplayCompositor', ""services/ui/surfaces/display_compositor.cc is the thing that owns SurfaceManager in Mus currently and is a SurfaceObserver. It is informed when Surfaces are created and forwards that to the display compositor host (in Mus+Ash, that's the window server). DisplayCompositor also implements the mojom::DisplayCompositor interface that allows creating CompositorFrameSinks.\n\nDisplayCompositor is responsible for creating a cc::Display and an OutputSurface.\n\nWe should try to unify all this code across Chrome and Mus+Ash. In particular, Mus has partial implementations of DisplayOutputSurface and DisplayOutputSurfaceOzone. We should look into unifying those with BrowserCompositorOutputSurface and GpuBrowserCompositorOutputSurface maybe.\n\nAll this code should live in components/display_compositor. OffscreenCanvasCompositorFrameSinkProviderImpl should probably go away and be replaced by DisplayCompositor.\n\nIn Chrome, GpuProcessTransportFactory can own a DisplayCompositor."", '']",1
"['Issue 683247: smoothness.scrolling_tough_ad_cases failing on 9 builders', 'smoothness.scrolling_tough_ad_cases failing on 8 builders\n\nType: build-failure\n\nBuilders failed on: \n- Android Nexus5 Perf (1): \n  https://build.chromium.org/p/chromium.perf/builders/Android%20Nexus5%20Perf%20%281%29\n- Android Nexus5X Perf (1): \n  https://build.chromium.org/p/chromium.perf/builders/Android%20Nexus5X%20Perf%20%281%29\n- Android Nexus5X WebView Perf (1): \n  https://build.chromium.org/p/chromium.perf/builders/Android%20Nexus5X%20WebView%20Perf%20%281%29\n- Android Nexus6 Perf (1): \n  https://build.chromium.org/p/chromium.perf/builders/Android%20Nexus6%20Perf%20%281%29\n- Android Nexus6 WebView Perf (2): \n  https://build.chromium.org/p/chromium.perf/builders/Android%20Nexus6%20WebView%20Perf%20%282%29\n- Android Nexus7v2 Perf (1): \n  https://build.chromium.org/p/chromium.perf/builders/Android%20Nexus7v2%20Perf%20%281%29\n- Android Nexus9 Perf (1): \n  https://build.chromium.org/p/chromium.perf/builders/Android%20Nexus9%20Perf%20%281%29\n- Android One Perf (1): \n  https://build.chromium.org/p/chromium.perf/builders/Android%20One%20Perf%20%281%29', '']",1
"['Issue 681084: SiteSettings <site-list> inefficiencies', 'When the user navigates to a page showing site exceptions, for example chrome://md-settings/content/flash, there are three <site-list> instances on the page, one for each of allow, block and session-only.\n\nI discovered inneficiencies regarding how/when those three lists get populated:\n\n1) When a site exception is added/removed, all three <site-list> instances\n   re-render themselves, even if nothing changed in that list.\n2) All three instances query the browser (via a browserProxy) on their own and\n   get back the exact same info (a list of all site exceptions returned 3 times\n   instead of just once). Then each list iterates over that list and filters out\n   the exceptions that belong to other lists (the ""allow"" list will filter out\n   ""block"" and ""session-only"" etc).\n\nFor 1: It would be more efficient if only the things that changed re-render themselves.\n\nFor 2: The three lists already have a common parent element <category-setting-exceptions>. It would make more sense if the parent was making a single call to the browserProxy, split the returned exception list to three lists and pass those to its children respectively.', '']",1
"['Issue 677022: Resources with an `integrity` attribute cannot reuse preloaded resources', 'Chrome Version: M57\nOS: All\n\nWhat steps will reproduce the problem?\n(1) https://lodash.com\n(2) font-awesome.min.css is preloaded but not reused due to an `integrity` attribute\n(3)\n\nWe need to implement `integrity` for link elements. Spec issue at https://github.com/w3c/webappsec-subresource-integrity/issues/26', '']",1
"['Issue 669660: Create flag for single use VM in Swarming (ephemeral bot)', 'This is needed for destructive tests. For example, testing an installer or running partially trusted payload.\n\nThis requires integration with MP, a new flag, and improvement to the bot scheduling logic, then releasing the lease.', '']",1
"['Issue 571297: Pinch-zoom state no longer exposed to JavaScript, eg. via window.innerWidth/height', 'Steps to reproduce the problem:\n1. run ""javascript:alert(window.innerWidth);"" and get a value like ""800"" pixels\n2. zoom web page in or out to change size\n3. run the same JavaScript and value has not changed like in all previous WebViews\n\nWhat is the expected behavior?\nwindow.innerWidth should change on zoom as the content area dimensions have changed because of the zoom. That is, a 100px x 100px content area, after being zoomed out, should report bigger dimensions like 1000px x 1000px.\n\nWhat went wrong?\nwindow.innerWidth seems to report screen width or some other value, not taking into account zoom.\n\nDid this work before? Yes This worked in all previous WebView versions including previous dev channel release of System WebView and way back to Gingerbread and probably previous to that.\n\nChrome version: 48.0.2564.48  Channel: n/a\nOS Version: 5.1.1\nFlash Version: none\n\nI think this should be a very high priority. This will likely break many, many sites. Is there a workaround?', '']",1
"['Issue 569158:  Remove uses of deprecated APIs to drop iOS8 support', 'In addition to changing build/common.gypi, a whole bunch of deprecated API uses have to be removed.\nThis is an umbrella bug to track the bugs of removing uses of various deprecated APIs.', '']",1
"['Issue 557346: 13.7%-76.2% regression in startup.warm.blank_page at 359853:359883', 'See the link to graphs below.', '']",1
"['Issue 555914: Chrome canary/dev sends Accept-Header */*, disabling WebP', 'Version: 48.0.2563.0 (Official Build) canary (32-bit)\nOS: Windows 7 x64\n\nWhat steps will reproduce the problem?\n1. visit  http://output.jsbin.com/xepiyo/quiet\n2.\n3.\n\nWhat is the expected output? What do you see instead?\nIt should be ""I\'m a WebP"" (and is on 46.0.2490.80). It\'s ""I\'m a JPEG"" on 48.0.2560.0 and up.\n\nReported in the earlier bug to add image/webp to the accept header [1]. Verified on Windows and Linux desktop.\nThis may have something to do with the move to WKWebView in bling.\nThe default for general requests [2] and images [3] appear to be correct.\n\n\n[1] ""Modify Accept header to explicitly denote the image formats Chrome supports""\nhttps://code.google.com/p/chromium/issues/detail?id=169182#c59\n""""""\nChrome/48.0.2560.0 (current canary) is now sending ""Accept: */*"" for image requests.\n\nChrome/47.0.2526.58 (current beta) and stable builds are sending the expected ""Accept: image/webp,image/*,*/*;q=0.8"" header for image requests.\n\nThis breaks the WebP support I have deployed via content negotiation.\n\n\nNote that Chrome 48 is still claiming support for WebP when requesting web pages:\n""Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8""\n\nSo it\'s unclear why it\'s no longer sent for image requests?\n\n\n(I note that CSS requests now also use ""*/*"" rather than ""text/css,*/*;q=0.1"", so I guess this is a more general change (or side-effect) in Accept behaviour?)\n""""""\n\n[2] https://code.google.com/p/chromium/codesearch#chromium/src/content/renderer/render_frame_impl.cc&l=267\n[3] https://code.google.com/p/chromium/codesearch#chromium/src/third_party/WebKit/Source/core/fetch/ImageResource.cpp&l=321', '']",1
"['Issue 553078: webRequest API strips objects in URLs', 'UserAgent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/48.0.2558.0 Safari/537.36\n\nSteps to reproduce the problem:\n1. Install attached extension\n2. Go to https://reddit.com\n3. Inspect URL requests on background page\n\nWhat is the expected behavior?\nAn URL requested by Reddit (//www.redditmedia.com/ads/display/300x250#{""keywords"": ""-reddit.com,loggedout"", ""origin"": ""https://www.reddit.com""}) should be reported as  https://www.redditmedia.com/ads/display/300x250#{""keywords"": ""-reddit.com,loggedout"", ""origin"": ""https://www.reddit.com""} by webRequest API.\n\nWhat went wrong?\nReddit requests an iframe with URL //www.redditmedia.com/ads/display/300x250#{""keywords"": ""-reddit.com,loggedout"", ""origin"": ""https://www.reddit.com""} but webRequest API reports that URL as www.redditmedia.com/ads/display/300x250#\n\nWebStore page: \n\nDid this work before? Yes Works on 46.0.2490.80 (64-bit) stable branch\n\nChrome version: 48.0.2558.0  Channel: canary\nOS Version: OS X 10.11.2\nFlash Version: Shockwave Flash 20.0 r0\n\n//www.redditmedia.com/ads/display/300x250#{""keywords"": ""-reddit.com,loggedout"", ""origin"": ""https://www.reddit.com""} is a source of iframe with ID ""ad_main"".', '']",1
"['Issue 500991: Clean up Daemon command-line flags', 'This is necessary so that we can delay parameter processing until D-Bus objects have been initialized.  This will be useful in the chrome-dbus transition.', '']",1
"['Issue 483646: Telemetry value system cleanup', 'Not all values are deserializable right now; in particular TraceValue is problematic.\n\nIn crrev.com/1118593002 I introduce a hack based on FromDict to base HTML output on chart JSON. At present, unless we explicitly ignore TraceValues while building the HTML results (which is the current workaround), this crashes, because chart JSON contains TraceValues where the old Buildbot results on which HTML was based did not.\n\nIn crrev.com/1120693003 I have uploaded a smoke test that guarantees that all values support deserialization; the goal of this bug will be to make that test pass.', '']",1
"['Issue 469362: [AiS] layout info text properly with RTL and LTR languages', 'Version: <Kenneth, what is the frequency?>\nOS: Those that use Views (linux and windows)\n\nThe current Answers in Suggest concatenates the strings in a non-RTL friendly way.  The solution to this bug will be to allow layout of the message, Info and Status (three parts of an Answer in Suggest) to be lain out in RTL and LTR friendly ways.', '']",1
"['Issue 468240: Incremental marking of object groups and implicit references', 'Blink and V8 need to cooperate to correctly collect DOM wrappers: if a DOM wrapper is no longer reachable from JavaScript alone, but can be reached by walking the DOM tree from another reachable wrapper, it must not be garbage collected. This is currently implemented by assigning groups to wrappers: all wrappers belonging to the same DOM tree form one group, and they can only die together.\n\nThe downside of this approach is that the group building can take arbitrarily long (depending on the size of the DOM trees), and that garbage collection has to atomically run to completion once group building is done, as any modification of the DOM trees would potentially invalidate the grouping. This currently causes pauses of about 40ms on smoothness.top_25_smooth on desktop.\n\nWe want to address both issues by implementing incremental marking support for DOM trees: We\'d re-use the Oilpan infrastructure for tracing objects to walk the DOM tree, and use a separate marking bit (so Oilpan\'s GC won\'t be constrained by this). To be able to incrementally mark the DOM trees, we will need a write barrier (or actually, a deletion barrier) on the ""parent"" pointer of DOM nodes: nodes discovered during tracing, newly allocated nodes, and nodes caught through the deletion barrier would get marked.\n\nI\'m pretty confident that it is possible to implement this without regressing performance, as the number of deletion barriers we\'ll insert is limited. Instead, I expect that this change will decrease pause times due to GC a lot. We hope to get down the atomic pause to less than 1ms on top_25_smooth.\n\nWe\'d also gain implementation experience with incremental marking of oilpan objects, which will help us to plan further steps for improving oilan\'s GC in the future.', '']",1
"['Issue 465878: [Chromoting] Webapp refactoring', 'The Chromoting webapp has accumulated a bit of ""technical debt"" (aka: ""cruft"") and needs a bit of refactoring to make the code more manageable and to facilitate adding new features and more tests.\n\nThis is the tracking bug for the refactoring and cleanup tasks.', '']",1
"['Issue 439084: Hosted apps: ""the app is currently unreachable"" for hosted app fatal network errors', 'I tried to open a google docs link today and got an error message saying that ""the app is currently unreachable"".  I had a bunch of other docs open, so this was a mystery.  Unfortunately, since this isn\'t the standard web error page, I couldn\'t figure out what was going on.  I eventually pieced it together and discovered that the doc was on chromium.org and my cookies were in a weird state that was triggering a ""too many redirects"" network error.  Ignoring the cookie issue, I think that the app network error page for hosted apps isn\'t adding any value any more.  When we were trying to put hosted apps in special containers and hide some of the web rough edges, it made a bit more sense, but now that hosted apps are basically bookmarks in tabs, I think this just adds more confusion.  I suggest that we remove the custom error page for hosted apps.', '']",1
"[""Issue 438959: Regression: Page scrolling is not working after exiting the fullscreen of the video on 'www.wipro.com'."", ""Chrome Version: 41.0.2238.0 (Official Build) dev 89500901a470788feedfaaac6e1e66804e9f70b9-refs/heads/master@{#306584} 64 bit\nOS: Mac\n\nWhat steps will reproduce the problem?\n1. Launch chrome and navigate to http://www.wipro.com\n2. Click on the 'Wipro video' and then scroll the page \n3. Click on 'Fullscreen' button and Click on 'Exit Fullscreen' button.\n4. Try to scroll the page using mouse scroll and observe.\n\nActual: Page does not scroll down after step 3.\n\nExpected: Page should scroll down.\n\nThis is regression issue broken in 'M 40 and below is narrow bisect:\nhttps://chromium.googlesource.com/chromium/src/+log/571b18256a44c782c1ac0c12bcaf13a73c0c497c..7d5dbab6a68510344f18d4a8895157172ab5e307?pretty=fuller&n=100\n\nBlink bisect:\nhttp://build.chromium.org/f/chromium/perf/dashboard/ui/changelog_blink.html?url=/trunk&range=183553%3A183552\n\nSuspecting: r299168 ?\n\nCould you please help to reassign this bug if your change is not the cause for this issue.\n\nNote: Issue is not reproducible on other browser like Firefox."", '']",1
"[""Issue 435757: PageTest's DidRunTest doesn't fit into user_story_runner's model"", 'Recently, I move the page_test.DidRunTest(browser, results) call from page_runner (which is user_story_runner now) to shared_page_state.TearDown method (https://codereview.chromium.org/721443005/).\n\nThis changes the behavior of how DidRunTest is called subtly. Previously, this method is guaranteed to be called only once after all the pages are run since it\'s in the last final block of page_runner::Run(). The landed patch makes it possible for this to be called more than once, if some unhandlable exception is ever thrown and the shared_page_state is TearDown() and restarted again.\n\n3 perf tests that override DidRunTest() are:\n\ndom_perf: uses DidRunTest() to gather page statistic across multiple page runs. (do not use browser instance at all)\n\npeacekeeper: uses DidRunTest() to gather page statistic across multiple page runs. (do not use browser instance at all)\n\npage_cycler: uses DidRunTest() to gather io metrics of the browser across multiple page runs. \n\nThe page_cycler case is the case that prevents me from keeping page_test.DidRunTest() in page_runner\'s final block since it requires the browser instance, which is not available in the general shared_user_story_state model. This case does show a flaw in the previous page run model: if the browser is ever restarted due to crash during page cycler test, the io metrics we get from the last browser instance is used as a summary statistics for all page runs, and this is *wrong*.\n\nSo this ""hack"" can be addressed by:\n1) Ignoring the summary metrics added by page_test.DidRunTest() if the browser/app instance is ever restarted.\n\n2) Change page_test.DidRunTest(browser, results) --> page_test.DidRunTest(platform, results), forcing that page tests to only compute platform based metrics for multiple user story runs.', '']",1
"['Issue 418199: Enable CORS for chrome://resources', 'CORS headers is not sent for resources hosted on ""chrome://resources"" which makes impossible to import (with <link rel=""import"" .../>) HTML files from ""chrome://resources"" to other ""chrome://*"" WebUI pages.\nThis should be fixed.', '']",1
"['Issue 410702: HTTP Nowhere content setting.', 'Perhaps we should add a content setting (or command-line flag?) which disables HTTP connections entirely for users who choose to do such a thing.\n\nChris, Ryan, would you approve CLs that snuck such a feature in without asking anyone who might say no? (I kid! (But really.)) :)', '']",1
"['Issue 410668: Need chromium API to do X.509 certificate chain checking outside of SSL/TLS', 'The Cast V2 device authentication protocol requires senders to verify that the certificate presented by the receiver chains to the Cast Root CA through one or more ICAs whose certs are conveyed in the protocol. Other checks, including expiry, basic constraints, possibly certificate policy, as mandated by the PKIX spec are also needed.\n\nCurrently, this is supported correctly by the Android and iOS sender SDKs, because the OS/development infrastructure on which they are based supports the necessary APIs. It is thus necessary only to ""bake in"" the Cast Root CA. However the Chrome sender code used by the Cast extension has to have all the ICA public keys and fingerprints baked, and does a single level signature validation as the validity check. This will not be manageable as the Cast ecosystem is expanded to include many other devices. \n\nI have discussed this briefly with rsleevi, and apparently there is already some intention to add such an API in chromium, but it is not a high priority right now. I can offer some cycles to assist in the implementation to try to make this happen sooner.', '']",1
"['Issue 402086: [Android WebView] Limit upload shared memory size like chrome', 'The in-process context currently uses a static 16mb of buffer size for uploads. Make it configurable and pick a reasonable value for android webview.', '']",1
"['Issue 402072: Redesign the CrasAudioHandler.', ""Currently the CrasAudioHandler has grown organically, resulting in code that is rigid, mismatched to our current requirements and generally hacky. \n\nWe need to get rid of this technical debt and redesign this code along with changes in Cras.\n\nA few things that we need to keep in mind as we redesign this,\n\n.) We may have multiple input/output devices active.\n.) Input/Output streams should be able to go to specific devices.\n.) Input gain isn't always a continuous value but rather a distinct set of steps.\n\nMore points may be added to this as we discuss this further."", '']",1
"['Issue 402027: Blink needs a Time/Clock type', ""Blink needs a Time/Clock type\n\nRight now we use doubles in many places, but sometimes they're seconds and sometimes they're ms.  We should have separate types for these so that the compiler can help us.\n\nI expect both the scheduler and animation could benifit from this."", '']",1
"[""Issue 392406: Regression: On pressing 'cmd+shft+B' the webpage overlapped on to the half portion of 'Bookmark bar' and flickering is observe on to the webpage"", ""Chrome Version       :  38.0.2084.0 (Official Build 281479)\nOS :  Mac\n\nWhat steps will reproduce the problem?\n1) Launch chrome, open NTP, press 'cmd+shft+B' and Observe the 'Bookmark bar'.\n\nWhat is the expected result?\nOn pressing 'cmd+shft+B' the webpage should not overlapped on to the 'Bookmark bar' and page should not flicker.\n\nWhat happens instead?\nOn pressing 'cmd+shft+B' the webpage overlapped on to the half portion of 'Bookmark bar' and flickering is observe on to the webpage.\n\nThis is a Regression issue broken in 'M-38' and will provide the bisect info soon."", '']",1
"[""Issue 376039: UseCounter doesn't work in shared workers and service workers"", '1. Open any page using openDatabase or openDatabaseSync in a worker.\n2. Open chrome://histograms/WebCore.FeatureObserver\n3. Search for 313 or 314 row\n\nExpected: There are a row for 313 or 314\nActual: none.\n\nRoot cause:\nvoid UseCounter::count(const ExecutionContext* context, Feature feature)\n{\n    if (!context || !context->isDocument())\n        return;\n    count(*toDocument(context), feature);\n}', '']",1
"['Issue 370696: Navigation Transitions', ""We should implement Navigation Transitions behind a flag so that developers can try it out. This'll also get something concrete in place to start the conversation with other browsers.\n\nAPI: https://docs.google.com/a/chromium.org/document/d/17jg1RRL3RI969cLwbKBIcoGDsPwqaEdBxafGNYGwiY4/edit?pli=1#"", '']",1
"['Issue 336155: drive: Make folder shortcut mount-path independent.', 'Version: R34 ToT\n\nFiles.app\'s ""folder shortcut"" feature saves and syncs the shortcut in the form of path like ""drive/root/foo/bar"". The path to Drive root was fixed to ""drive"" in the past. However, to support multi-profile cross file copying, we need to assign different path to different profile\'s Drive folder (bug 336123).\n\nHence, we need a way to map between the two path formats. Per offline discussion with +yoshiki and +hirono, the plan is to:\n* Keep using ""drive/root/..."" path in the storage.\n* When the path is loaded from the storage, replace ""drive"" with the path retrievable from VolumeManager.\n\nLogic: the path may be synced to old version clients, so we want to keep backward compatibility.\nLogic: it gives freedom to the path format in background. For example, we can use device-dependent hash ID.\n\nWhat steps will reproduce the problem?\n(Preparation for smooth migration to multi-profiles. There won\'t be any user-visible change.)', '']",1
"['Issue 322042: Entering /foo in omnibox tries to load file:///foo', 'App Version (from ""Chrome Settings > About Chrome""): M31 on AppStore, up to ToT as of fe154de\niOS Version: iOS 6, iOS 7\nDevice: iPhone, iPad\n\nSteps to reproduce:\n- In the omnibox, type ""/foo""\n- The first autocompletion item is file:///foo\n- Tap Return.\n\nObserved behavior: \n- The app tries to load file:///foo\n\nExpected behavior: \nfile:// shouldn\'t be supported and presented in the autocompletion results.\n\nFrequency: \n<number of times you were able to reproduce> 5/5', '']",1
"['Issue 319558: NaCl is incompatible with python 2.7 on Windows in part due to importing third_party\\python_26', 'Running nacl_integration with python 2.7.5 breaks it.\nAll Windows builders on http://build.chromium.org/p/client.nacl/waterfall are red at runhooks stage.\n\n--- CUT HERE ---\n________ running \'e:\\b\\depot_tools\\python275_bin\\python.exe native_client/build/gyp_nacl\' in \'E:\\b\\build\\slave\\xp-newlib-opt\\build\'\nUpdating projects from gyp files...\nThe system cannot find the path specified.\ngyp: Call to \'""call ../native_client/tools/win_py.cmd"" ../native_client/build/test_build.py -i --arch=ia32 --name=hello_world --tools=newlib\' returned exit status 1. while loading dependencies of native_client\\build\\all.gyp while trying to load native_client\\build\\all.gyp\nError: Command e:\\b\\depot_tools\\python275_bin\\python.exe native_client/build/gyp_nacl returned non-zero exit status 1 in E:\\b\\build\\slave\\xp-newlib-opt\\build\n--- CUT HERE ---\n\nWork items:\n- Remove references to third_party\\python_26\n- Stop overriding PATH', '']",1
"['Issue 311404: LayoutTests should use surfaces/display compositor', ""When delegated rendering is enabled, the code we have to read the pixel data for the test comes back with a black square. This broke layout tests on windows in r228225, but of course we didn't notice because we don't run the pixel tests under Aura :).\n\nTurning off delegated rendering when running in dump-render-tree mode works around this for now, but we should probably figure out why it's not working and fix that."", '']",1
"['Issue 297774: paygen: add unit tests for handling of test images', ""I've managed to sneak in a few changes to paygen's codebase that go untested in the unittest code that corresponds to the module incorporating the changes. This includes:\n\n1- Testing the discovery of test images (UnsignedTestArchive) and payloads.\n\n2- Testing different combinations of payload skipping flags.\n\nI'd like to payback the technical debt soon and so assigning priority/iteration accordingly. pcovell/sosa, feel free to adjust as you see fit."", '']",1
"['Issue 272349: NaCl process reports the wrong PID to the browser on Linux', ""The NaCl process (started from nacl_loader) will report the wrong PID to the browser.\n\nThis is most likely due to not playing nice with the setuid sandbox.\n\nIn turn, this can cause trouble when trying to get the process' exit status. The Zygote having no knowledge of the process, it'll always return TERMINATION_STATUS_NORMAL_TERMINATION (see line ~216 in zygote_linux.cc)."", '']",1
"['Issue 269304: File tasks and file handlers stuff is a big ball of mud', 'Stuff in c/b/chromeos/extensions/file_manager/file_tasks.h and file_manager_util.h is a big ball of mess. Extremely complicated and no one fully understands. Full of technical debt.\n\nThis area needs to be reworked significantly.', '']",1
"[""Issue 263063: Do not block on the browser's main thread during window resize"", ""Version: M28, but basically everything\nOS: Mac, possibly others\n\nWhat steps will reproduce the problem?\n1. Open poster circle in two windows\n2. Rapidly resize one of the windows\n\nWhat is the expected output? What do you see instead?\nBoth windows will have janky animation during the resize. This is because the browser's main thread is being blocked during resize (and during paint), waiting for a frame of the right size to come in from the renderer.\n\nInstead of this, we should just defer the resize message until the resized frame comes in.\n\nIn addition to having better performance, this will simplify a lot of code (e.g, where we wait for new frames to come in during the display code...)."", '']",1
"['Issue 259961: Pinned HTTPS and non-pinned HTTPS should be treated as separate as far as mixed-scripting is concerned.', ""A script sourced from http from a httpS page won't run anymore in Chrome.\n\nIt's a security measure to prevent mixed scripting since it essentially makes httpS moot.\n\nThere is a more insidious form of mixed-scripting: non pinned httpS vs pinned httpS.\n\nWe should also treat this as a form of mixed scripting."", '']",1
"['Issue 248509: -29.2% regression in chromium-rel-mac7-gpu-intel/spaceport/Score at 205354:205374', 'Graphs:\nhttps://chromeperf.appspot.com/report?rev=205374&masters=ChromiumPerf&bots=chromium-rel-mac7-gpu-intel&tests=spaceport/Score\n\n\nbisect job coming shortly.', '']",1
"['Issue 243948: Write client-side automated integration tests for Locally Managed Users.', 'Write client-side automated integration tests for the policies and functionality created for Locally Managed Users feature. Prefer browsertests, if possible, so they could be run in BVT. Otherwise, write as AutoTests.\n\nAutomated test(s) are required for Go/NoGo review, before new feature can be approved for release in R29.', '']",1
"['Issue 226903: Remove custom bindings for Clipboard::types()', 'Clipboard::types() currently returns a ListHashSet<String> of types in the clipboard, which requires custom bindings to convert it to a DOM array. In addition, the DOM array is currently buggy and returns null when types is empty (see issue 226785).\n\nThe original patch in WebKit was landed twice and reverted twice due to build breaks on Chromium. The third attempt to land it failed when concerns about compatibility were raised; on some WebKit ports, switching to Vector<String> could potentially cause duplicate entries to appear in types.\n\nNow that this can no longer occur, I propose that we just change the return type and remove the custom bindings code.', '']",1
"['Issue 222171: Add automated tests for new client-side functionality in support of Echo SKU/Time-based Offers', 'Need automated integration-level tests on Chrome OS device for the following new features:\n221555: Get HWID from device and send it to echo server if server requires so.\n220472: Get the OOBE timestamp\n221807: Make device activation month more obscure', '']",1
"['Issue 220083: Use USB-controlled power strip to emulate AC/DC switching', ""Some EC and battery functions need AC/DC switch. In order to automate these tests (we don't have yet), we need an USB-controlled power strip. Via servo, we can emulate AC plug/unplug.\n\nWe need to investigate the possible setup and add the related tests."", '']",1
"['Issue 217854: Refactor server/site_wlan_*.py', ""This group of scripts is relied upon to manipulate the DUT during WiFi tests, which means they're critical for a number of important integration tests, and we will want to use them for the new test cases we're writing for the interop lab.\n\nUnfortunately, these scripts do not conform to Google Python style, or autotest Python style.   They have no unit tests.  They rely on executing one another and parsing the resultant output.  This all makes them brittle, hard to maintain, and hard to expand.  The only way to test them while working with them is to copy to a device and manually poke at it, or run groups of end-to-end wifi tests.\n\nThis technical debt must be repaid in order to allow us to move more quickly in the future.\n\nTriage values are a strawman."", '']",1
"['Issue 211435: Clean up technical debt in portage_utilities.py.', ""Clean up technical debt in portage_utilities.py. \n\n1. Use shell=False where possible.\n2. Use cwd=dir instead of 'cd' inside the command.\n3. Move project checks from GetCommitId into GetSourcePath.\n4. Accept srcdir as input for GetCommitId, instead of calling GetSourcePath.\n5. Clean up ancient TODOs."", '']",1
"['Issue 209162: Proxy resolution service in Chrome should not use a D-Bus signal to return the result', ""The proxy resolution service in Chrome is implemented as follows:\n\n1) update_engine calls ResolveNetworkProxy method on Chrome\n2) Chrome immediately returns an empty response\n3) Chrome soon returns the real result as a D-Bus signal\n\nInstead of using a signal this way, we should just return the result from the method asynchronously. Hopefully, asynchronous method return can be easily done using Chrome's d-bus library.\n\nTo fix this, we should both change chrome and update_engine as follows:\n\n1) Chrome exports a new method like ResolveProxyInfo, that returns the result asynchronously\n2) update_engine is changed to use the new method asynchronously\n3) Once the migration is done, we should remove the old method in Chrome"", '']",1
"['Issue 195766: Remove non-deferred 2D canvas code.', 'Deferred 2D canvas rendering (released in M23) has stabilized.  Time to get rid of some technical debt by cleaning out the old code path. The motivation is to avoid having to maintain this code path as Canvas2DLayerBridge get re-architected to use MailBoxes (for ubercompositor support).\n\nWe need to\na) Remove the ""disable deferred 2d canvas"" lab/switch from chromium.\nb) get rid of the associated cruft in WebKit (ImageBuffer, Canvas2DLayerBridge)', '']",1
"['Issue 176592: SPDY: Implement per-session flow control', 'See http://lists.w3.org/Archives/Public/ietf-http-wg/2013JanMar/0393.html', '']",1
"['Issue 176139: Unify/cleanup page_test_runner and multipage_benchmark_runner', 'They are dupes of each other. Duping was done to expedite @kbr request. Merge & unify to remove technical debt.', '']",1
"['Issue 175024: Refactor state-tracking logic in SyncScheduler', 'The current SyncScheduler stores much of its information in SyncSessionJob and SyncSession instances, whose ownership must be carefully managed.  This is dangerous, since we can create serious bugs if we mess up.  See issue 165561, for example.\n\nThis also makes it difficult to fix certain bugs, since we end up throwing away information at the end of a sync cycle.  See issue 155296, for example.\n\nIt should be possible to move the data that is currently owned or referenced by transient posted tasks into the longer-lived SyncScheduler.  This will greatly reduce the possibility of certain memory bugs and allow us to hold on to more state following a successful sync cycle.', '']",1
"['Issue 164098: Get rid of OperationRegistry', 'IMHO, OperationRegistry is yet another technical debt we should pay off.\n\nIf I understand right, OperationRegistry is used for two things:\n\n1) UI features like showing notifications (original purpose)\n2) Cancellation all requests at shutdown (additional feature?)\n\nAs for 1), DriveScheduler is a better place to get progress of updates.\n\nAs for 2), client code should manage pending requests if they want to cancel them, rather than all operations go through OperationRegistry.\n\nkinaba@, is my understanding correct?', '']",1
"['Issue 160570: Samba network storage support', 'Ability to connect to and browse remote SMB shares.', '']",1
"['Issue 159847: Investigate removing --gc-sections for the Android build', ""From chat with torne:\n\nhas anyone tried to make libchromeview.so build without linker GC?\nthe linker GC is likely to be leaving code we don't actually use behind all over the place, because of references via vtables and the like\nif we can get it to build cleanly without garbage collection (by ifdef'ing/etc the files that we don't want all of) then the resulting GCed size will likely decrease even more\ndue to transitive dependencies of that code being removed"", '']",1
"['Issue 148816: Enable virtual viewport pinch-zoom', 'This issue is for tracking the progress of the chromium side of the compositor changes to enable a pinch-zoom path that does not use a CSS transformation.\n\nHigh level summary:\n - Explained best by this demo.  Set the mode to pin to outer. http://www/~johnme/clank/position-fixed/prototype/\n - Implementation strategy:  https://docs.google.com/a/google.com/document/d/109AJe6VifVwDQZ-belLMKz5Yjq7kK0FC2aI21445S0k/edit\n\nThis issue was initially tracked on a webkit change: https://bugs.webkit.org/show_bug.cgi?id=93292', '']",1
"['Issue 135626: Textures missing in animations on www.apple.com/iphone', 'With accelerated animations enabled, if you cycle through the animations, you will see the phones animate in with missing textures.', '']",1
"['Issue 134405: Replace base::PlatformFileError with GDataFileError', 'Version: ToT\nOS: Chrome\n\nCurrently, GDataCache and GDataFileSystem are reporting errors with base::PlatformFileError.\nThis should be replaced with GDataErrorCode since base::PlatformFileError can not describe network error (e.g. lost connection).', '']",1
"[""Issue 93674: Bookmarks in a folder can't be right-clicked or drag-and-dropped"", ""Google Chrome : 15.0.859.0 (Official Build 97584) canary\nOS: Mac OS X\n\n\nWhat steps will reproduce the problem?\n1. Put a bookmark into a folder on the bookmarks bar.\n2. Try to right click the bookmark. Try to drag and drop the bookmark out of the folder.\n\nWhat is the expected result?\nRight click should show context menu. Drag and drop should drag and drop.\n\n\nWhat happens instead?\nRight click does the same as left click. Dragging a bookmark does nothing.\n\n---\nI guess I should point out this works fine in ordinary Chrome, but only seems to be a problem in canary. I wasn't sure if I was allowed to submit bug reports for the canary build since I know it's supposed to be a bit buggy but I didn't see anything that says don't do it. Apologies if I'm wrong though."", '']",1
"['Issue 90843: Extension-provided content scripts should execute, even when JavaScript is otherwise blocked.', 'It would be useful for extensions like NoScript to be able to inject JavaScript that can be executed in the context of a page even when JavaScript is otherwise disabled on that page (per content settings, for example).', '']",1
"['Issue 61632: OSX: input type file causes browser action popup to close.', 'Chrome Version       : 8.0.552.23 dev\nURLs (if applicable) : N/A\nOther browsers tested: N/A\n\nOS Version: Mac OS X 10.6.4\n\nWhat steps will reproduce the problem?\n1. Install the attached extension on a Mac.\n2. Click at the browser action and then try to choose a file.\n\nWhat is the expected result?\nThe <input type=""file""> should open the file browser and let you choose a file.\n\nWhat happens instead?\nThe file browser opens for just a moment then both the browser action and the file browser are automatically closed.', '']",1
"['Issue 46654: Extension sync should include Greasemonkey scripts', 'Chrome Version       : 6.0.438.0 (49912)\n\nWhat steps will reproduce the problem?\n1. Click on a greasemonkey script to install it (say, from userscripts.org)\n2. Enable extension sync\n\nWhat is the expected result?\nGreasemonkey scripts get synced identically to extensions.\n\nWhat happens instead?\nThey get ignored by the sync engine.', '']",1
"['Issue 43780: Backup sockets should be moved into TCPConnectJob', 'Windows takes three second to recover from a lost TCP syn packet.  \nCurrently, we start a new ConnectJob from ClientSocketPoolBaseHelper if it \nlooks like a TCP syn packet is lost.  Instead we should start a new connect \nwithin TCPConnectJob.', '']",1
"['Issue 1751: Add support for Metalink XML Download Description Format', ""Product Version      : 0.2.149.29\nURLs (if applicable) : http://www.metalinker.org/\nOther browsers tested:\nAdd OK or FAIL after other browsers where you have tested this issue:\n     Safari 3: FAIL\n    Firefox 3: FAIL\n         IE 7: FAIL\n\nWhat steps will reproduce the problem?\n1. Download a .metalink, such as http://www.metalinker.org/samples/OOo/OOo_2.4.1_Win32Intel_install_en-\nUS.exe.metalink\n\nWhat is the expected result?\n\nThe download agent parses the XML file and uses a resource URL to start the \ndownload. The partial file checksums can be used to detect errors during or \nafter the download. If a server goes down during the transfer, backup URLs \ncan be switched over to. All this is done transparently for the person at \nthe browser with no interaction required.\n\nWhat happens instead?\n\nThe .metalink file is downloaded but not processed and the files referred \nto in the .metalink are not downloaded.\n\nPlease provide any additional information below. Attach a screenshot if \npossible.\n\nMetalink is currently used by around 35 programs, mostly download programs, \ndownload managers, FTP clients, & web browsers. It's currently used by \nmostly open source projects like OpenOffice.org, openSUSE, Ubuntu, Fedora, \ncURL, and others. For most people to take advantage of Metalink, it needs \nto be included in browsers. \n\nChromium could be the first open source browser to add support. Metalinks \ngive more definite information about a download, which should be more \nconducive to searching.\n\nhttp://en.wikipedia.org/wiki/Metalink\nhttp://www.metalinker.org/"", '']",1
"['Issue 657299: Replace `Android Page Info > Details` with Security panel bullet points', 'Design doc: https://docs.google.com/document/d/1oYEKqoL-tKC1EwOmoYrT5TCBttQ9eCK9q2TfyC8uneA/edit#heading=h.au203bjfkch0\n\nAndroid Page Info has a ""Details"" link that goes to a popup view based on the old desktop connection tab (which is gone since April:  Issue 421248 ).\n\nThe Android implementation requires us to leave a bunch of technical debt lying around in the WebsiteSettings code. This has gotten in the way of seemingly unrelated feature work, like Issue 646201 (Implement colored security summary).\nIn addition, the Android strings are also unmaintained, and the popup even still uses the old Material/mobile icons (we\'ve done a good job of keeping it intact!).\n\nThe Security panel overview bullets do a much better job of breaking down and explaining the security state. In addition, we have done a good job of keeping them very simple [1]:\n- A summary string\n- A description string.\n- A boolean describing whether to show a button that opens the certificate viewer for the current page.\n\nSo, I think that we should show these on Android instead.\n\nHowever, there are two complications:\n- The description of mixed content is synthesized in DevTools. However, we can probably figure out a simplified explanation to show instead.\n- The strings are not localized, and the TLS connection description is assembled using a template that assumes English grammar. However, I can think of some pretty easy ways to adapt our implementation for localization.\n\nestark@, do you foresee any additional problems?\n\n[1] https://cs.chromium.org/chromium/src/content/public/browser/security_style_explanation.h?q=struct+SecurityStyleExplanation&sq=package:chromium&l=19&dr=CSs', '']",1
"['Issue 657148: Update Page Info on Android to match Desktop Material Page Info', '(1) Update strings per this doc:\nhttps://docs.google.com/document/d/1wMKbWsXKHzTT1e_UZkI1jtHrCCcVsNTX18P6db-y6RU/edit\n\n(2) Add colored title summary per this doc: https://docs.google.com/document/d/1wMKbWsXKHzTT1e_UZkI1jtHrCCcVsNTX18P6db-y6RU/edit', '']",1
"['Issue 647809: Composited table cells with collapsed borders have incorrect visual rect.', 'UserAgent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.11; rv:48.0) Gecko/20100101 Firefox/48.0\n\nSteps to reproduce the problem:\n1. Go to http://codepen.io/anon/pen/NRAaYq/ using Chrome  55.0.2862.0 canary (64-bit) on Mac\n2. View the output of the codepen\n3. Click on the button in the output to see the problem go away and return\n\nWhat is the expected behavior?\nSome of the table rows do not properly display the table cell borders. Some rows do. It seems to repeat in a pattern in my app. In the codepen example the borders just stop displaying a few rows into the table.\n\nWhat went wrong?\nThere is something about how the overflow CSS property on one of the wrapper elements is interacting with the table. When the overflow property on the wrapper is ""visible"" it works fine, when it is ""auto"" the borders get messed up. There may be some interaction with flex styling as well.\n\nDid this work before? Yes It works fine in the stable Chrome release 53.0.2785.116 (64-bit)\n\nChrome version:  55.0.2862.0 canary (64-bit)  Channel: canary\nOS Version: OS X 10.11\nFlash Version: Shockwave Flash 23.0.0.162', '']",1
"[""Issue 640060: chromium-checkins@ doesn't receive emails about git commits from commitsentry"", 'See https://groups.google.com/a/chromium.org/forum/#!forum/chromium-checkins\nNo new commit notifications after August 20.\n\nVery similar to Issue 561094.', '']",1
"[""Issue 617065: Hashes in 'report-only' don't report."", 'We should follow up on https://codereview.chromium.org/2020223002 by refactoring hash support such that report-only and enforce mode correctly allow/report matching blocks.', '']",1
"['Issue 601657: Video capture timestamps are not valid TimeTicks values, causing problems downstream in the media stack', 'Bugs 529949 and 549744 were resolved by making implementation changes that broke the video frame ""reference clock"" timestamps.  These changes wrapped the timestamps from the capture device into fake base::TimeTicks values.  This is an abstraction violation, since TimeTicks values are always interpreted relative to the system clock.\n\nBug 597034, and likely bug 587553, track problems caused by the bad timestamps.  In bug 597034, a workaround was needed because the video frame reference timestamps were bogus.  That was a band-aid solution to the real underlying problem.\n\nThe correct solution to the original problem is that BOTH the relative timestamp (from the capture device driver) and the reference clock timestamp (TimeTicks::Now()) need to be passed through the video stack, as each is necessary for different purposes:\n\n1. The capture device timestamps (which should be set in media::VideoFrame::set_timestamp()) are needed to communicate the media duration/rate of the video frames for smooth playout.\n\n2. The reference timestamps (from TimeTicks::Now()) are needed for the purposes of resolving Audio/Video synchronization via a common reference clock.  The reference timestamp is allowed to be a little ""noisy"" because it is only being used to align the playout of the separate audio and video streams.  In other words, it is used as a target or an ""ideal"" playout time, but never as an exact presentation time.', '']",1
"['Issue 592444: cronettestinstrumentation is very flaky', 'cronettestinstrumentation is very flaky on Android Cronet Data Reduction Proxy Builder.\n\nThis looks like a xmas tree:\nhttps://uberchromegw.corp.google.com/i/chromium.android/builders/Android%20Cronet%20Data%20Reduction%20Proxy%20Builder?numbuilds=200\n\nAt least the following are flaky:\n- BidirectionalStreamTest#testReadAndWrite\n- CronetSampleTest#testLoadUrl\n- CronetUrlRequestContextTest#testRequestFinishedListenerFailedRequest\n- CronetUrlRequestContextTest#testShutdownAfterError\n- CronetUrlRequestTest#testFailures\n\nAssigning to Misha for triage.', '']",1
"['Issue 583289: [Tracking] NTP refactoring', ""This is a tracking bug for the NTP refactoring, with the ultimate goal of getting rid of the remote NTP.\n\nDesign doc: go/ntp-refactor\n\nSteps:\n- Achieve feature parity between the local NTP and the remote one.\n- Switch to the local NTP by default.\n- Remove the remote NTP.\n\nGoals:\n- Reduce technical debt/maintenance burden - unify implementations and simplify overall architecture.\n- Corollary: Ease the development of new NTP features (Popular Sites, Zine) on desktop.\n- Possibly improve NTP performance (page load time).\n\nI'll file separate bugs for the individual features that the local NTP needs to support."", '']",1
"['Issue 419201: chromeos-install called from cros flash --install uses the host architecture and not the DUT architecture', ""When chromeos-install is run, it uses uname to determine what architecture it's running on to decide whether it's on x86 and needs to install the MBR to enable syslinux, or it's on ARM and needs to not install the MBR to avoid squashing vboot non-volatile storage.\n\nBefore we moved from image_to_usb.sh to cros flash, there was an option to specify the architecture which would get passed on to chromeos-install. If that option wasn't used, it would default to x86 if x86 was in the board name and use ARM otherwise. That was a correct check briefly a long time ago, but otherwise would incorrect pick ARM.\n\nNow that we've moved to cros flash, we no longer have a mechanism to force what architecture we're on. chromeos-install is left to figure it out on its own, and when it calls uname it will detect the host architecture, not the DUT architecture.\n\nI suspect that the --arch option to image_to_usb.sh might not have been used since it wasn't missed when we switched to cros flash. That would have defaulted us to ARM, where now we're going to more often always default to x86, unless someone is doing development on some really beefy ARM device.\n\nWhat I'd really like to see is some mechanism that lets us treat the MBR properly without guessing based on the architecture. That would help us remove more architecture dependence, and also break the fragile assumption that x86 systems need to install the MBR and ARM systems don't. As a matter of fact, ARM systems have started storing their non-volatile data in the EC, so not all ARM systems need to preserve the MBR.\n\nOne possible place to record how to treat the MBR would be the partition managing script created by cgpt.py."", '']",1
"['Issue 121673: Hook up Web Audio API with WebRTC for audio processing', 'Goal is to come up with a design that allows us to hook up the WebAudio API with WebRTC so that rendered audio in WebRTC can be modified using all the cool stuff in WebAudio.', '']",1
"['Issue 348033: WebGLRenderingContext.idl should use implements and not inherits', 'We currently have:\n\ninterface WebGLRenderingContext : WebGLRenderingContextBase {\n};\n\nThis does not match the spec and it adds one more empty object to the prototype chain. We should use implements.\n\nWebGLRenderingContext implements WebGLRenderingContextBase;\n\nThis way we do not add the extra empty object.', '']",1
"['Issue 429450: BoringSSL: De-fang renegotiation logic', ""Filing this as a braindump:\n\nNow that we have some renego tests in the pipeline, we should think about de-fanging BoringSSL's renegotiation logic. It's currently wrapped up in the record layer and extremely complex. (See ssl3_read_internal, ssl3_read_bytes, in_handshake, and what in_read_app_data = 2 means.) The other issue is that temporary state pertaining to the current handshake is not well-separated from the current connection state. That needs to get better-organized anyway, but we can also try to simplify renegotiation inself.\n\nLosing it altogether is probably not going to be an option for the foreseeable future, so let's de-fang it and only bother with one case: client support for HTTP servers which renegotiate (presumably for client auth) after reading the HTTP request and before reading the HTTP response. This case is much simpler: renego only happens at a quiet point[*] in the application protocol, so handshake and application data cannot interleave. So, let's see if we can:\n\n1. Remove DTLS renegotiation support altogether. We have no need for it and retransmit/reordering adds more complexity to the mix. \n\n2. Remove all support for renegotiation on the server side altogether. I can imagine cleaner server halves too, but we may not need to bother. Unexpected ClientHellos from the client are fatal, APIs to send HelloRequests are removed.\n\n3. Forbid application/handshake interleavings. If a handshake is in progress, application data records are fatal. This removes in_read_app_data = 2. This assumes the server does not send application data between HelloRequest and the handshake completing.\n\n4. Remove APIs for the client to initiate renegotiation. (Alternatively, keep them there, but because of 3, it'll require that the consumer know this is a quiet point in the protocol.)\n\n5. Move in_handshake/SSL_in_init triggers in ssl3_read_bytes and ssl3_write_bytes up to a higher level, so there's no need to care about re-entrancy in the first place. Wire that higher level up appropriately so that a HelloRequest received when application data is expected translates to driving the handshake. (Either at the higher level or maybe even require the caller do it.)\n\n6. With the handshake triggers moved to a higher level, clean up the False Start logic. Current logic relies on SSL_cutthrough_complete re-querying all the False Start conditions to re-derive whether False Start occurred. It then checks in_read_app_data so that it only lies to ssl3_write_bytes' handshake escape and not ssl3_read_bytes' to let SSL_write through. This will remove the last consumer of in_read_app_data and remove that state. This may be possible to do in advance of the others. (Probably at the expense of adding state to track whether we did False Start.)\n\n7. Investigate what else in_handshake is needed for. Uses, like in_read_app_data, are querying what functions are on the stack and thus difficult to reason about.\n\n\n[*] From the perspective of the client. From the perspective of the server, if clients supported HTTP/1.1 pipelining (which we don't and probably won't given HTTP/2), the server may see app data between HelloRequest and ClientHello. It would have to buffer those (unbounded size) requests before beginning the ClientHello."", '']",1
"['Issue 428051: AssertionError while creating a mini branch', 'Command:\n\ncbuildbot branch-util --local --branch-name=stabilize-6412.B --version=6412.0.0 --force-create\n\n\nError:\n\n@@@STEP_FAILURE@@@\n13:09:12: ERROR: Traceback (most recent call last):\n  File ""/usr/local/google/chromeos/chromite/cbuildbot/stages/generic_stages.py"", line 379, in Run\n    self.PerformStage()\n  File ""/usr/local/google/chromeos/chromite/cbuildbot/stages/branch_stages.py"", line 476, in PerformStage\n    self._FixUpManifests(repo_manifest)\n  File ""/usr/local/google/chromeos/chromite/cbuildbot/stages/branch_stages.py"", line 334, in _FixUpManifests\n    included_manifests = self._UpdateManifest(manifest_path)\n  File ""/usr/local/google/chromeos/chromite/cbuildbot/stages/branch_stages.py"", line 238, in _UpdateManifest\n    manifest_path=manifest_path)\n  File ""/usr/local/google/chromeos/chromite/lib/git.py"", line 709, in Cached\n    obj = cls(root, manifest_path=manifest_path)\n  File ""/usr/local/google/chromeos/chromite/lib/git.py"", line 538, in __init__\n    manifest_include_dir=manifest_include_dir)\n  File ""/usr/local/google/chromeos/chromite/lib/git.py"", line 373, in __init__\n    self._RunParser(source)\n  File ""/usr/local/google/chromeos/chromite/lib/git.py"", line 383, in _RunParser\n    self._FinalizeAllProjectData()\n  File ""/usr/local/google/chromeos/chromite/lib/git.py"", line 644, in _FinalizeAllProjectData\n    Manifest._FinalizeAllProjectData(self)\n  File ""/usr/local/google/chromeos/chromite/lib/git.py"", line 414, in _FinalizeAllProjectData\n    self._FinalizeProjectData(path_data)\n  File ""/usr/local/google/chromeos/chromite/lib/git.py"", line 652, in _FinalizeProjectData\n    Manifest._FinalizeProjectData(self, attrs)\n  File ""/usr/local/google/chromeos/chromite/lib/git.py"", line 426, in _FinalizeProjectData\n    assert remote in self.remotes\nAssertionError\n\n************************************************************\n** Finished Stage BranchUtil - Tue, 28 Oct 2014 13:09:12 -0700 (PDT)\n************************************************************', '']",1
"['Issue 300153: Device Locks up when idle for a while', 'Stumpy on R30\n\nHere is what I often encounter, about 2 times per day:\n\n- I have my machine up w/ my usual tabs/windows (~10 term windows, 2 gmails, gcal, a couple gdocs, a couple code review windows, couple bugs). Machine is set to let display sleep, but not sleep itself.\n- lock screen\n- go away for a while. display sleeps.\n- return to computer, mouse/keyboard won\'t work. display won\'t wake.\n- look and see power LED is lit.\n- hold down power button to force shutdown; press to startup\n- log in\n- see ""chrome shutdown unexpectedly"" notice and restore tabs.\n\nFWIW, I have swap disabled, celeron, 4GiB RAM.\n\nderat@: You are seeing something similar, right?\nscottz@: Do you have the ability to try to repro something like this in a lab?\nI will be attempting to collect logs and notice if anything suspicious is happening on my stumpy.\n\nAssigning to scott to try to repro.', '']",1
"['Issue 317911: Servo: Refactor code from Autotest to Hdctools', ""Part of the big FAFT rework is we need to refactor Servo code from Autotest to Hdctools.\n\nThe big reason for this is we're starting to have servo version specific code in Autotest and this should be in HDCTools.\n\ncrbug.com/268534 is an example of this. It should be solved by moving this code to hdctools and make the servo version specific code be hidden there.\n\nThen the autotest code should call the code in hdctools, most likely over the xmlrpclib interface it currently uses.\n\nI would start by taking that bug and moving the code into hdctools (and if you want add the servo specific stuff as well).\n\n\nNext is the much bigger move of everything from server/server/cros/servo.py to hdctools. This class should become servo_client.py and call the respective methods to where you move them in hdctools.\n\nBoth of these refactors will be similar code changes so you can do them at the same time. The tricky part will be coming up with where in hdctools to put the code and make sure all the methods can still be called as expected.\n\nAssigning to Yusuf but Richard and I will help guide him through this and help with reviewing.\n\n\n\n@Richard, if you know anything else that should be moved over please add details here."", '']",1
"['Issue 17174: Theora block-level quant not supported', ""Chrome Version       : 3.0.193.1 Chrome Win32   3.0.195 (195.0) Chromium OS X\nURLs (if applicable) : http://people.xiph.org/~tterribe/tmp/sign_irene_cif-3qi.ogg\n\nBlock-level quant isn't used in any released encoder, but I'm told Thusnelda will be using it Real \nSoon Now. Anyway, support was added in ffmpeg r18986 and merged into ffmpeg-mt on May 31 in 94985fa. So it's just a matter of upgrading the libavcodec binaries shipped with Chrome/Chromium \nbinaries."", '']",1
"['Issue 125225: Domui process can be ptraced from a compromised renderer leading to sandbox escape, take 2', 'It turns out that ""https://code.google.com/p/chromium/issues/detail?id=74763"" is not fixed anymore.\n\nWe made the check more tight:\n\nhttp://git.kernel.org/?p=linux/kernel/git/torvalds/linux-2.6.git;a=commit;h=da48524eb20662618854bb3df2db01fc65f3070c\n\nBut it was then relaxed:\n\nhttp://git.kernel.org/?p=linux/kernel/git/torvalds/linux-2.6.git;a=commit;h=243b422af9ea9af4ead07a8ad54c90d4f9b6081a\n\nUnfortunately, breakpad trusts SI_USER:\n\nhttp://code.google.com/searchframe#I3UcDWKuRYs/trunk/src/client/linux/handler/exception_handler.cc&l=338\n\nI didn\'t notice at the time the check was relaxed that kill() uses SI_USER, not SI_TKILL and that it would be an issue.\n\nThere are two ways to fix this:\n\n1. a new kernel patch to prevent SI_USER spoofing\n2. a breakpad patch where we only trust TKILL signals (i.e. signals sent by either tkill or tgkill)\n\nSince tgkill doesn\'t allow to send a signal to a whole thread group, I don\'t think that (2) can work.\n\nI\'ll look into (1)\n\nhttps://lkml.org/lkml/2011/3/28/482', '']",1
"['Issue 181671: Create a policy to disable DNS-hijack checks in enterprise', ""Customer is requesting that there be a policy to disable DNS hijack checks. (which is done by sending random DNS queries to see if anyone resolves it)\n\nUse case: Chrome's use of random hostnames may be triggering a system/networking bug which is documented here crbug/174242. This is impacting other infrastructure on the network. Customer wants a way to disable it while they investigate this issue. If no option is provided they may have to abandon the use of chrome."", '']",1
"['Issue 368298: Implement native accessibility support for out-of-process iframes', 'We need to nest one BrowserAccessibilityManager in another.', '']",1
"['Issue 390618: Tracking bug for supporting loading *.so libraries directly from the APK', 'This is a tracking bug for a feature of Chrome for Android which is motivated by reducing transmission size and size on the device.\nTo save transmission size the lib*.so is stored in the APK file uncompressed, doing this makes much smaller deltas with previous versions.\nTo save disk space the lib*.so is opened directly from its position in the APK file (using the crazy linker), this saves having both a compressed and uncompressed version of the library on the device.\n\nMore information (and numbers) here:\n\ngo/clank-apk-update-faq\n\nThe feature is turned on for clank (Chrome.apk) by setting:\nclank_load_library_from_zip_file = 1 in clank.gyp', '']",1
"['Issue 402172: create a generic python testing framework', ""We have a bunch of test steps that are based around python unit tests or otherwise use python:\n\n- webkit_tests (run-webkit-tests)\n- webkit_python_tests (test-webkitpy)\n- mojo_python_tests\n- telemetry_unittests\n- telemetry_perf_unittests\n- mini_installer_unittests\n\n(and of course the regular telemetry perf tests).\n\nIn order to implement support for things like retrying failed tests, uploading data to the flakiness dashboard, etc. we end up having to duplicate a lot of logic into each harness.\n\nIt would be better if we had a common framework we could just reuse and extend as needed. \n\nI'm filing this bug to track the effort to create such a framework.\n\nOne can imagine even extending this framework for other uses (e.g., to drive gtest-based tests to implement proper sharding, unify the code for handling failures, etc., actually use for telemetry perf tests, etc.), but I don't consider that part of the initial effort.\n\nI intended to land the tooling in the buildtools repo, so that we can reuse it across multiple repos (chromium, build, blink, perhaps others if need be).\n\nI actually have an open-sourced project that was roughly based on webkitpy's test harness that I will use as the basis for this: https://github.com/dpranke/typ . I just need to extend that to handle the JSON results logic and a couple other things, and we should be fine."", '']",1
"['Issue 239363: Hover effects in views should not be invoked when mouse events are disabled', 'views should not receive mouse events when the mouse is disabled\n(including synthesized events)', '']",1
"['Issue 466768: Design a new audio extension API getDeviceInfo to pass a stable/persisted device id string.', 'This is a feature request from hotrod app. Hotrod app needs to have a stable device id string to identify the same kind of audio device across the hot plug device reboot. In the current system, chrome receive a device id and device name string from cras and pass them to hotrod. They are not stable across the hot plugs and device reboot. \n\nIn general, we need to get some support from cras to pass a stable device id string that is stable/persisted across the hot plugs and device reboot. Once we have that, chrome audio extension will add a new API getDeviceInfo to pass this information to the hotrod app.\n\nFor more details about the stable/persisted device id string discussion. \nSee design doc: Design: Stabilize hotrod audio device names.\nhttps://docs.google.com/document/d/13ZwCIzpp99kAW5G4wOCj73vjsOE7ce_2DeOSB1MBRmw/edit#heading=h.bvqf18flsh3f\n\nAnd ""Redesign Audio Extension API""\nhttps://docs.google.com/document/d/1YFFLwX4mcKJyuAsZB13GhDid0MEt0QguKX0AxgvBoko/edit#heading=h.ng2jd1z39umd\n\nDiscussion from mnilsson@:\nIn fairness, and for the hotrod use case, I think it is less of a problem for audio devices. It\'s unlikely that the user is going to have multiple identical, say, headsets that can be mixed up. Jabras will be enabled in a group. For video, it\'s more sensitive that the right camera is selected. But I\'m mostly thinking of future proofing the API in general, and having a stable set of identifiers across alsa/chrome versions, so that presented/persisted names don\'t change. A USB identifier would be great for persisting (hat tip tures) and a sequential number would be acceptable, although there are some gotchas with that too, see some thoughts here: https://docs.google.com/document/d/13ZwCIzpp99kAW5G4wOCj73vjsOE7ce_2DeOSB1MBRmw/edit#heading=h.6opa6gfi9lab', '']",1
"['Issue 165048: System-level Chrome should auto-launch post user-level Chrome self-destruction.', ""Version: r172002\nOS: All Windows.\n\nWhat steps will reproduce the problem?\n1. Install user-level Chrome.\n2. Install system-level Chrome (on this user or another user).\n3. Launch user-level Chrome.\n\nWhat is the expected output?\nUser-level Chrome self-destructs and launches system-level Chrome.\n\nWhat do you see instead?\nUser-level Chrome self-destructs. The user then needs to launch system-level Chrome by hand.\n\n\nThe intention of the user was clearly to launch Chrome in the first place so there is no reason why we shouldn't do this.\n\nFurthermore: as of M24, we install missing per-user shortcuts (pointing them to the system-level install) post self-destruct and on First Run (to cover various scenarios); this can be annoying if Chrome self-destructs and creates shortcuts (some of which the user deletes because he doesn't want them); then the user launches system-level Chrome (which creates al those shortcuts again...); auto-launching system-level Chrome immediately after self-destruct makes it hard for the user to delete some shortcuts in between and have them re-created after!"", '']",1
"['Issue 465458: Starting a thread is janky', 'Code which calls base::Thread::Start() or base::Thread::StartWithOptions() can be janky.\n\nStarting a base::Thread involves creating a platform thread, and then blocking until the thread has started executing.\n\nThis has been identified as the cause of jank on IO thread in issue 454983, and I expect it is likely contributing jank elsewhere on the IO and UI thread.\n\nThe thread start jank seems to be worse on Windows than other platforms.\n\nSome possible solutions to this problem:\n\n * Return from base::Thread::StartWithOptions() without waiting for the thread to started. Callers expect the thread to have a usable MessageLoop they can post to, so some refactoring would be required to provide a working MessageLoop before the thread has started.\n\n * Or do nothing as is currently the case and allow base::Thread to be janky. Require callers to move thread creation to a background thread if they care about this jank.\n\n * Expose different flavors of thread starting -- one that waits for the thread to start, another that returns right away, letting callers pick which behavior they want.', '']",1
"['Issue 431863: Remove src/ui and x11 dependencies from src/chromeos/ime', 'There should not be any src/ui or x11 dependencines in src/chromeos.\n\nWe should move the dependent code to src/ui/chromeos, or to a component.', '']",1
"[""Issue 451499: We should have some 'null build' trybots to ensure that the null build doesn't derail"", ""It doesn't look we have some trybots that ensure that the null build doesn't derail (i.e. calling 'ninja -C out\\Release chrome' twice in a row should always be a noop).\n\nIf we do have such bots, then they missed this bug: https://codereview.chromium.org/873773002/\n\nWe should have one bot per config that we officially support.\n\nWe could also do this on every existing builder by calling compile twice (the second time with the '-d explain' arguments)."", '']",1
"['Issue 195008: Need ""crossystem"" support on ARM platforms', 'Currently we are moving all ACPI/GPIO and other hardware (platform) related stuff into the ""crossystem"" command, and it works fine on x86.\n\nWe need it to work on ARM platforms, too.', '']",1
"['Issue 197070: Disable config-protect in chroot or at least reduce the scope of it', '>>> Emerging (1 of 1) chromeos-base/autotest-private-0.2.1-r34 from chromeos-overlay for /build/x86-alex/\n * Package:    chromeos-base/autotest-private-0.2.1-r34\n * Repository: chromeos-overlay\n * USE:        autotest buildcheck elibc_glibc kernel_linux tests_desktopui_PageCyclerTests tests_factory_Keyboard tests_factory_Leds tests_hardware_Components tests_platform_PDFSupport tests_security_BundledCRXPermissions tests_suite_Factory tests_suite_HWQual tests_suite_Official tests_suites userland_GNU x86\n * FEATURES:   sandbox splitdebug userpriv usersandbox\n>>> Unpacking source...\n * GIT update -->\n *    repository:               ssh://git@gitrw.chromium.org:9222//autotest-private\nFailed to add the host to the list of known hosts (/home/chronos/user/.ssh/known_hosts).\nFrom ssh://gitrw.chromium.org:9222//autotest-private\n * branch            HEAD       -> FETCH_HEAD\n *    at the commit:            c6029fd174301035994faac633eab8991e351c1b\n *    commit:                   45a796842c555f1d51d78abb097ffaf0f4005d8a\n *    branch:                   master\n *    storage directory:        ""/var/lib/portage/distfiles-target/git-src/autotest-private""\nCloning into /build/x86-alex/tmp/portage/chromeos-base/autotest-private-0.2.1-r34/work/autotest-private-0.2.1...\ndone.\n\n\nA workaround for this (in the case where we\'re ./build_packages and would hang there waiting for interactive) would be to disable StrictHostKeyChecking, however the above warning still happens.\n\nMy name isn\'t chronos!', '']",1
"['Issue 321462: Web IDL: Add support for dictionary', ""Web IDL dictionaries (fixed set of keyvalue pairs) are useful,\nparticularly for Web Animations.\nhttp://www.w3.org/TR/WebIDL/#idl-dictionaries\n\nThey are currently not supported, instead using Dictionary, which is just a generic dictionary (arbitrary key).\n\nThis is a substantial amount of work, and will be easier to do once the bindings rewrite into Python is done.\n\nAlan, initially assigning to you, as you've expressed interest; feel free to release, and I may grab in future."", '']",1
"['Issue 182054: Implement and integrate verified boot kernel level baseline support', 'Finalize the post-firmware verified boot design and implement the\nappropriate solution.', '']",1
"['Issue 403031: Eliminate dependence on the vblock in the stateful partition.', ""There are scripts which depend on a normal vblock for the current kernel being in the stateful partition. We're working on having a kernel signed with normal keys available in the image in slot B all the time so that that separate vblock is no longer necessary.\n\nThe existing scripts should be updated so that they no longer use that vblock, and then we'll no longer need to generate it."", '']",1
"[""Issue 116317: Switch NaCl's PPAPI Proxy to use Chrome IPC and its IPC-based Proxy."", ""Replace NaCl's SRPC-based PPAPI Proxy with the Chrome-IPC based Proxy. This will involve several steps.\n\n1) Modify Chrome and the built-in NaCl plugin to open an IPC channel to the NaCl sandbox process.\n2) Modify the NaCl sandbox process to connect to a Chrome-IPC channel for PPAPI, and translate the platform-specific IPC format to the platform-independent NaCl format.\n3) Build enough of Chrome in the untrusted tool chain to get the plugin-side of the IPC proxy running in the sandbox.\n4) Modify GYP so 'actions' can do source exclusions, so we can reuse source file lists from trusted targets (rather than duplicate them and have to keep them in sync.)"", '']",1
"['Issue 73751: Support memory allocations that can fail', 'We have a handful of bugs that are all caused by our behavior to crash on OOM:\n\n1) Our TypedArray API for JS is supposed to throw an exception on overlarge allocations, not kill your renderer\nhttp://code.google.com/p/chromium/issues/detail?id=42342\n\n2) The system file picker dialog can use an image decoding library (for displaying icons) that tests for NULL back from a malloc (this one takes out your whole browser)\nhttp://code.google.com/p/chromium/issues/detail?id=51286\n\n3) Flash 10.2 can call into some nVidia support code that appears to expect to get NULL back from a malloc\nhttp://code.google.com/p/chromium/issues/detail?id=68942\n\nIn the first two cases, the callers are explicitly calling a special ""try malloc"" API, distinct from malloc in that it indicates the caller\'s promise that it will check the return value.  (In the third case I\'m not certain of the cause of the bug.)\n\nI personally don\'t know a whole lot about our memory allocation goop, but it seems we ought to be able to fix cases 1 and 2 because they\'re going through a special malloc code path already.', '']",1
"['Issue 132765: Extension icons need a HiDPI story', ""Browser actions have a single image associated with them ( http://code.google.com/chrome/extensions/browserAction.html ). For HiDPI, there should be a way to set a 2x image too (and for win8, maybe 1.4x and 1.8x?)\n\nExtension team, what's the plan here?\n\n\n\n(apologies if there's a bug for this already; I couldn't find one.)"", '']",1
"['Issue 334951: recover_duts can kill a device during a temporary network outage (such as with power_SuspendStress) that autoserve would tolerate', 'Moving the discussion from https://chromium-review.googlesource.com/#/c/181851/ here since it seems to be more controversial than I thought.\n\njrbarnette@ wrote:\n---------------------------------------------------\n> There\'s no bug filed for this change: Do you have actual data indicating that this is actually necessary? I have concerns about this change, and it would be good to understand the trade-offs that are available.\n> I\'m a bit dubious about the asserted 12 minute timeout for ssh in autoserv. In any event, I\'ve never seen such a thing in the code. Do we have any empirical evidence for that behavior?\n> The claim that recover_duts runs once every 30 minutes is wrong; it runs once every 10 minutes, with the first run 5 minutes after boot. I don\'t think that will by itself cause a failure; recover_duts waits for ethernet.hook, so we won\'t have cases of two instances of the hook running in parallel.\n> I\'m a bit leery of increasing the timeout, generally. We do have cases where DUTs go down, and this script recovers them. With this change, the time until we can detect and fix a problem jumps from a minimum of 6 to a minimum of 20 minutes. That\'ll reduce throughput in the lab during outages.\n---------------------------------------------------\n\n\nI only stumbled upon a single example of this happening here: http://cautotest/afe/#tab_id=view_job&object_id=7335991\nI\'m sure we could find more if we looked for them, but it\'s a little hard to aggregate since there are so many things that can cause unexpected reboots in this test. It\'s definitely rare, which I think makes it even worse.\n\nI think I got the ""12 minutes"" from beeps (maybe from #4 in issue 221785), although I don\'t quite remember. After almost a year of getting nowhere on that autoserv SSH timeout issue, I decided to make the most out of what we have and extend power_SuspendStress to 8 minutes recently... I hope we can get at least that working reliably (it has been for now as far as autoserv is concerned, I think) so that we might have the eventual chance of getting some useful, stable S2R stress tests.\n\nYou\'re right about the 10 minutes, I don\'t know where I confused that. I agree that it shouldn\'t be a problem (even if it did run in parallel somehow).\n\nI understand that this is increasing the timeout by quite a bit, but on the other hand I think maintenance tools like recover_duts shouldn\'t interfere with otherwise valid and passing tests (especially since this is such a rare race condition). I don\'t know how often recover_duts actually triggers in the lab during a day... will 15 minutes really be such a big deal? We could try to find a different solution (e.g. have tests temporarily disable recover_duts), but that would be more complicated to implement and bring its own set of problems (and the next guy who writes a test that disables the network for a minute will once again get surprised by extremely rare, hard to debug failures due to this).', '']",1
"['Issue 118: Content-Disposition filename parameters are sometimes percent-unescaped', ""Product Version      : 0.2.149.27 (1583)\nURLs (if applicable) :\nhttp://greenbytes.de/tech/tc2231/#attwithfnrawpctenca\nhttp://greenbytes.de/tech/tc2231/#attwithfnrawpctenclong\n\nOther browsers tested:\nAdd OK or FAIL after other browsers where you have tested this issue:\n     Safari 3: OK\n    Firefox 3: OK \n         IE 7: FAIL\n\nSee URLs.\n\nWhat is the expected result?\n\nFilename parameter should be used as-is (no percent-decoding/UTF-8 unescaping)\n\nWhat happens instead?\n\nFilename parameter get's decoded.\n\n\nPlease provide any additional information below. Attach a screenshot if\npossible.\n\nSee applicable specification, e.g. RFC 2616, the MIME specs, and RFC 2183.\n\nSee also test suite at <http://greenbytes.de/tech/tc2231/>"", '']",1
"['Issue 267773: [Meta bug] Replace android_commands.py', 'Currently, android_commands.py and the underlying adb_interface.py is a mess and it is difficult to reason about the timeouts when running various commands, what exceptions the user of the method will receive, whether a command is retried and how many times. Also, the logging of commands should be made consistent.', '']",1
"['Issue 103304: Split ui/gfx into its own target', 'Clients depending on ui/gfx for things like gfx::Rect end up pulling in a lot more than they need (net/, v8/, etc...)\n\nWe should be able to break it into its own target, however ben@ noticed a few gotchas:\n\n""""""\nSadly, there is a circular dependency with ui/base. It may be possible to break this... it looks like it\'s mostly ResourceBundle in the NativeTheme code. If NativeTheme could move to ui/base that might work.\n\nAlso, ui/gfx/compositor, ui/gfx/surface and ui/gfx/gl should move up to ui.\n""""""', '']",1
"['Issue 221857: RTC interrupts do not cause a suspend abort late in the kernel suspend path', 'When the kernel suspends with a primed /sys/power/wakeup_count, it should abort the suspend at any time if it receives an RTC wake alarm. There should be no possible race condition where the wake alarm is lost without either aborting the suspend or resuming right afterwards. This does not work reliably in current ToT builds (seen on Snow and Link for now).\n\nSteps to reproduce:\n\n1. Modify the kernel to include a sufficient delay (e.g. 5 seconds) during the device suspend stage, such as at the end of drivers/base/power/main.c:dpm_suspend().\n2. echo `cat /sys/power/wakeup_count ` > /sys/power/wakeup_count ; echo +3 > /sys/class/rtc/rtc0/wakealarm ; powerd_suspend\n\nExpected output:\nThe kernel aborts the suspend or resumes immediately.\n\nActual output:\nThe device suspends and stays suspended.\n\nHitting the keyboard or touchpad during the delay causes a wakeup as expected, so this seems to be specific to the RTC.', '']",1
"['Issue 290399: offsetWidth sometimes returning incorrect values in Chrome 30 (regression)', 'UserAgent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/30.0.1599.28 Safari/537.36\n\nExample URL:\nhttp://jsfiddle.net/qEgEh/1/\n\nSteps to reproduce the problem:\n1. Highlight any cell in the main table\'s left column in dev inspector (e.g. the one containing ""100"")\n2. On page, highlighted box shows width 32, metrics in devtools shows width 32, and a separate ""ruler"" extension shows width 32\n\nWhat is the expected behavior?\nThat element\'s offsetWidth also returns 32\n\nWhat went wrong?\noffsetWidth is dramatically under the actual value, with offsetWidth of 22 in this case. Off by arbitrary amounts in other cases (e.g. upper-right cell and the one beneath it differ by 1px).\n\nThe provided test case is a much smaller subset of the HTML we had before that still highlights the error.\n\n(Aside: we discovered this because of a behavior change in our UI code that calls Closure\'s goog.style.getBorderBoxSize, which just uses the offset* values).\n\nDoes it occur on multiple sites: N/A\n\nIs it a problem with a plugin? No \n\nDid this work before? Yes Chrome 29\n\nDoes this work in other browsers? Yes Chrome 29, FF 23\n\nChrome version: 30.0.1599.28  Channel: beta\nOS Version: \nFlash Version: Shockwave Flash 11.8 r800', '']",1
"['Issue 281689: Bring PPB_VideoDecoder interface out of Dev', ""For Chromoting's plugin to move to [P]NaCl, we need high-performance VP8 decode, which isn't currently possible in [P]NaCl due to lack of support for SIMD instructions.\n\nInstead, we'd like to expose Chrome's VP8/9 decode capability via the PPB_VideoDecoder interface."", '']",1
"['Issue 346198: Switch WebRTC bots to recipes', 'The recipes are the new way of having buildbot logic kept on the slave side, which enables a lot of flexibility and avoid buildbot master restarts to apply changes.\n\nToday, only our Android APK trybots are using recipes. All our buildbots in WebRTC should use the framework.\n\nSee https://chromium.googlesource.com/chromium/tools/build/+/master%5E/scripts/slave/README.recipes.md for a recipes introduction.', '']",1
"['Issue 346626: Enable Android x64 Build', 'Steps to reproduce the problem:\nWe may encounter several issues to build Chromium for Android x64. \n\nWhat is the expected behavior?\n\nWhat went wrong?\nCurrent chromium only supports Android ia32 build, and we need some fixes before we can support Android x64.\n\nDid this work before? N/A \n\nChrome version: 33.0.1712.4  Channel: n/a\nOS Version: \nFlash Version: Shockwave Flash 11.9 r900', '']",1
"['Issue 456494: Enable microdumps for Android WebView', 'So far they worked fine for Chrome.\nTime for the next stage: WebView', '']",1
"['Issue 238899: Race condition between AE check and tlsdate on devices without CMOS battery can cause AE failures.', 'We noticed a pattern of AE failures on lenovo devices which we believe are related to a race condition which I\'ll explain below.\n\n1) Lenovo devices don\'t have cmos batteries\n2) Which means it can\'t keep time if the regular battery drains or is disconnected\n3) If the battery drains during shipping... or if the device goes through recovery (which explicitly requests users to disconnect battery) then the device doesn\'t have correct time at startup\n4) When the system boots up it does a few different things... two of this are\n    a) Run tlsdate to fetch latest time\n    b) Check if AE is enabled\n5) If (b) goes out before (a) succeeds, (b) will fail.\n6) See below: ""-8181"" is an SSL certificate expiry error which is consistent with this theory.\n7) error ""2"" I suspect is ""DM_STATUS_REQUEST_INVALID""\n8) Complete logs from on of the devices is attached at : https://drive.google.com/a/google.com/folderview?id=0Bx12NVyIouI0QUhUY2I2ZW1vTGM&usp=sharing\n\n--------------------\n[1433:1443:0214/063326:ERROR:gpu_watchdog_thread.cc(201)] The GPU process hung. Terminating after 10000 ms.\n[3583:3583:0214/065747:ERROR:nss_util.cc(490)] Error initializing NSS with a persistent database (sql:/etc/fake_root_ca/nssdb): NSS error code: -8174\nXlib:  extension ""XFree86-VidModeExtension"" missing on display "":0.0"".\n[1387:4345:0214/065759:ERROR:cert_verify_proc_nss.cc(783)] CERT_PKIXVerifyCert for www.google.com failed err=-8181\n[1387:1387:0214/065800:ERROR:eula_screen.cc(64)] No manifest found.\n[1387:4345:0214/065801:ERROR:cert_verify_proc_nss.cc(783)] CERT_PKIXVerifyCert for m.google.com failed err=-8181\n[1387:1387:0214/065801:ERROR:auto_enrollment_client.cc(247)] Auto enrollment error: 2\n[1387:4346:0214/065801:ERROR:cert_verify_proc_nss.cc(783)] CERT_PKIXVerifyCert for clients4.google.com failed err=-8181\n[1387:4346:0214/065806:ERROR:cert_verify_proc_nss.cc(783)] CERT_PKIXVerifyCert for clients3.google.com failed err=-8181\n[1387:1430:0507/162648:ERROR:plugin_data_remover_impl.cc(263)] ClearSiteData returned error\n---------------------', '']",1
"['Issue 240592: Implement HTML Imports', '(See go/owp-launch-guide for an overview)\n\nChange description:\nTracking bug to HTML Imports implementation: https://dvcs.w3.org/hg/webcomponents/raw-file/tip/spec/imports/index.html\n\nChanges to API surface:\n- HTMLLinkElement\n- new Import object\n\nPublic standards discussion: public-webapps\n\nSupport in other browsers: current (expected)\nInternet Explorer: N/A\nFirefox: Likely: https://hacks.mozilla.org/2013/05/speed-up-app-development-with-x-tag-and-web-components/\nSafari: N/A', '']",1
"['Issue 309687: Add firmware version to metadata.json', ""For FSI builds in particular, the TPMs want to know the firmware version, EC and BIOS.  We'd like to get this added to the metadata.json version information."", '']",1
"['Issue 329616: GlobalShortcutListener refinements', ""In https://codereview.chromium.org/60353008, we uncovered some targets for changes that can improve the overall GlobalShortcutListener design. These changes were out of scope for that change and review, but it was agreed that follow-ups should address them.\n\nhttps://codereview.chromium.org/60353008#msg34:\n\nDiscussing the lazy instance used to implement Instance(), which was determined to be overkill because this code is single-threaded:\n\n> I would advise changing the other-platform implementations if they also have the\n> single-threaded property and a CHECK to enforce it.\n\nThe other platforms can follow the model adopted by the new Mac implementation, where a thread CHECK assertion is present, and the instance pointer is saved in a local static pointer. #includes of lazy_instance.h can be removed.\n\nhttps://codereview.chromium.org/60353008#msg38:\n\nWith respect to thread CHECK assertions like this:\n\n> This\n> kind of CHECK/DCHECK should also be on other public methods exposed by this\n> class, to assert that consumers of this API are doing the right thing. Id even\n> put one in the destructor, although based on what youve told me, the destructor\n> in this codes current form will never be called.\n>\n> This kind of CHECK should also be on as the non-static private (or\n> should-be-private per my previous comment) methods of this class that are the\n> targets of system callbacks, On[Hot]KeyEvent and OnMediaKeyEvent, to assert that\n> interactions with the system libraries are working exactly as you expect. Since\n> this class isnt thread-safe, I think these assertions would be a smart idea.\n\nThis advice should be carried to the other platform implementations.\n\nhttps://codereview.chromium.org/60353008#msg42:\n\n> 1. Lets move Start/StopListening into the private: section in the base class\n> and all implementation subclasses. That addresses this API problem.\n>\n> 2. Lets also move Register/UnregisterAccelerator into the public: section in\n> the implementation subclasses. Right now, its public: in the base, but private:\n> in the subclasses, even though the private platform-specific implementations are\n> actually the public entry point in each case, accessed through the public base,\n> which is virtual. I was confused for a while when I saw that these functions,\n> which are obviously supposed to be the public API, were marked private in the\n> implementation, and I wondered just how anyone would actually ever manage to\n> register an accelerator, until I read the base class. It seems kind of silly\n> that if you hold a GlobalShortcutListener* which is really implemented as\n> GlobalShortcutListener*, you can call RegisterAccelerator, but if you hold a\n> GlobalShortcutListenerMac* directly, you cant.\n\nhttps://codereview.chromium.org/60353008#msg52:\n\nReferring to brokenness around multiple key registrations\n\n> So then the answer is the implementations are all broken but it doesnt\n> currently matter because theres only one client and only one observer.\n> Thats fine until someone wants to add another client.\n\nAdditional context from https://codereview.chromium.org/60353008#msg49:\n\n> Right, the problem isnt in RegisterAccelerator, its in UnregisterAccelerator.\n>\n> The Windows and X11 implementations (the only other subclasses that arent just\n> stubs) seem to share this problem. None of the implementation subclasses\n> actually track that multiple observers registered for a single accelerator, so\n> the first time one of them tries to unregister from the accelerator, it stops\n> being watched entirely.\n>\n> I also dont see anything in the base class or the implementation subclasses\n> that distinguishes between media keys and non-media accelerators. Nothing seems\n> to enforce the behavior of allowing multiple observers for a media key but not\n> for a non-media accelerator. All subclass RegisterAccelerator implementations\n> have the comment that says that its explicitly OK to allow an\n> already-registered shortcut because of media keys, but there doesnt seem to be\n> anything that checks that non-media keys dont get multiple observers\n> registered. ExtensionCommandsGlobalRegistry, currently the only caller, does\n> have a DCHECK for this to make sure that its clients behave correctly, but since\n> GlobalShortcutListener exposes its interface publicly to the entire application,\n> its way too easy for someone else to come along as a client of that interface,\n> successfully register an observer for an already-watched non-media accelerator,\n> and never have any warning that theyre doing anything wrong.\n\nThis should be resolved so that other future users of this API dont trigger bugs. There arent currently any problems with this behavior because ExtensionCommandsGlobalRegistry is the only caller, but if there were other callers, this would break. The correct solution here will depend on the desired semantics in the GlobalShortcutListener implementations. It may choose to be more general than what is allowed by ExtensionCommandsGlobalRegistry (for example by allowing multiple registrants for all accelerators) or may choose to be more specific to only solve current needs (for example by allowing only one registrant for any accelerator, including media keys, because the client ExtensionCommandsGlobalRegistry deals with multiple extensions listening to the same media key). Taking the second approach and making the implementations solve only current needs is attractive because it will probably result in a net reduction in code size, because GlobalShortcutListener wont have to implement the same multiple-observer logic that it currently purports to (although its currently broken).\n\nFinnur also stated in  https://codereview.chromium.org/60353008#msg53:\n\n> Yes. As I recall, the GlobalShortcut* classes shouldn't need to worry about\n> whether there is one target or many targets for the shortcut that was struck.\n> Their job is to make it easy to listen for a particular shortcut and have that\n> event delivered to the observers.\n\nwhich may help you decide which way to resolve this problem."", '']",1
"['Issue 568388: [MD] Make sure correct theme provider is used in incognito browser windows', ""in light of https://codereview.chromium.org/1492423003/ it matters whether the theme provider is retrieved for incognito profile p or original profile p'. Make sure we always do the correct thing so |otr| in ThemeService::GetColor is always what you'd expect."", '']",1
"['Issue 222484: Daisy : External keyboard not working after idle suspend/resume plugged in USB 2.0 port', ""Version: 26.0.1410.40\nOS: ChromeOs: 3701.62.0\n\nWhat steps will reproduce the problem?\n1. Connect external keyboard on USB2.0 port.\n2. Wait for device to suspend by keeping it idle.\n3. Resume the device.\n\nWhat is the expected output? What do you see instead?\nThe external keyboard should work.\nThe external keyboard doesn't work. Unplugging and plugging back works.\nIf the external keyboard is plugged into USB3.0 port then it works.\n\nPlease use labels and text to provide additional information.\nLogs in the next update."", '']",1
"['Issue 206928: Crash: kernel-cgroup_task_migrate-CC9AAB51', 'Chrome OS Version  :  1412.7.0\nChrome Version     :  17.0.963.2\nType of computer   :  Cr-48\nNetwork info       :  Ethernet\n\nPlease specify Area-* of the system to which this bug/feature applies (add\nthe label below).\n\nWhat steps will reproduce the problem?\n1.Open any webpage.\n2.Ctrl + shift then ctrl + w immediately\n\nWhat do you see instead?\nKernel crash.\n\nHow frequently does this problem reproduce? Many times.\n\nPlease provide any additional information below.\n\nCrash URL : http://crash/reportdetail?reportid=6622c11a9889ff8c', '']",1
"['Issue 403726: Reuse AppWindow code for athena and app_shell', 'To support app.window API on athena and app_shell, we should make AppWindow (or a part of it) independent of chrome.\nOnce AppWindow becomes chrome-free, it can be used from athena and app_shell to replace ShellAppWindow.\n\nPlan A: AppWindow stays in apps/\n 1. Add a new chrome-free target under apps/ (say, apps_core)\n 2. Remove chrome dependencies from AppWindow and all classes we need.\n 3. Move these classes from apps to apps_core. (files are not moved, just changing gyp)\n\nPlan B: Move AppWindow to extensions/\n[According to issue 388893, there is a motivation to move code from apps/ to extensions/]\n 1. Remove chrome dependencies from AppWindow and all classes we need.\n 2. Move these classes from apps to extensions. (files are moved between directories, namespace is also changed)\n\nWhich way do you think is better? Or, is there any other better way?\noshima, benwells, WDYT?', '']",1
